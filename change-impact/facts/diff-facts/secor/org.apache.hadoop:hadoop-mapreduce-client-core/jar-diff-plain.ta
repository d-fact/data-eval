Update org.apache.hadoop.filecache.DistributedCache org.apache.hadoop.filecache.DistributedCache
Delete org.apache.hadoop.mapred.AuditLogger.Constants org.apache.hadoop.mapred.AuditLogger.Constants
Delete org.apache.hadoop.mapred.AuditLogger.Keys org.apache.hadoop.mapred.AuditLogger.Keys
Delete org.apache.hadoop.mapred.AuditLogger org.apache.hadoop.mapred.AuditLogger
Update org.apache.hadoop.mapred.BackupStore.BackupRamManager org.apache.hadoop.mapred.BackupStore.BackupRamManager
Update org.apache.hadoop.mapred.BackupStore.FileCache org.apache.hadoop.mapred.BackupStore.FileCache
Update org.apache.hadoop.mapred.BackupStore.MemoryCache org.apache.hadoop.mapred.BackupStore.MemoryCache
Update org.apache.hadoop.mapred.BackupStore org.apache.hadoop.mapred.BackupStore
Update org.apache.hadoop.mapred.BackupStore.<init>(Configuration,TaskAttemptID) org.apache.hadoop.mapred.BackupStore.<init>(Configuration,TaskAttemptID)
Update org.apache.hadoop.mapred.BackupStore.write(DataInputBuffer,DataInputBuffer) org.apache.hadoop.mapred.BackupStore.write(DataInputBuffer,DataInputBuffer)
Update org.apache.hadoop.mapred.BackupStore.mark() org.apache.hadoop.mapred.BackupStore.mark()
Update org.apache.hadoop.mapred.BackupStore.reset() org.apache.hadoop.mapred.BackupStore.reset()
Update org.apache.hadoop.mapred.BackupStore.hasNext() org.apache.hadoop.mapred.BackupStore.hasNext()
Update org.apache.hadoop.mapred.BackupStore.next() org.apache.hadoop.mapred.BackupStore.next()
Update org.apache.hadoop.mapred.BackupStore.nextValue() org.apache.hadoop.mapred.BackupStore.nextValue()
Update org.apache.hadoop.mapred.BackupStore.nextKey() org.apache.hadoop.mapred.BackupStore.nextKey()
Update org.apache.hadoop.mapred.BackupStore.reinitialize() org.apache.hadoop.mapred.BackupStore.reinitialize()
Update org.apache.hadoop.mapred.BackupStore.exitResetMode() org.apache.hadoop.mapred.BackupStore.exitResetMode()
Update org.apache.hadoop.mapred.BackupStore.getOutputStream(int) org.apache.hadoop.mapred.BackupStore.getOutputStream(int)
Update org.apache.hadoop.mapred.BackupStore.updateCounters(int) org.apache.hadoop.mapred.BackupStore.updateCounters(int)
Update org.apache.hadoop.mapred.BackupStore.clearMark() org.apache.hadoop.mapred.BackupStore.clearMark()
Update org.apache.hadoop.mapred.BackupStore.clearSegmentList() org.apache.hadoop.mapred.BackupStore.clearSegmentList()
Delete org.apache.hadoop.mapred.BackupStore.access$400() org.apache.hadoop.mapred.BackupStore
Update org.apache.hadoop.mapred.BackupStore.access$500(BackupStore) org.apache.hadoop.mapred.BackupStore.access$500(BackupStore)
Update org.apache.hadoop.mapred.BackupStore.access$600(BackupStore) org.apache.hadoop.mapred.BackupStore.access$600(BackupStore)
Update org.apache.hadoop.mapred.BackupStore.access$700(BackupStore) org.apache.hadoop.mapred.BackupStore.access$700(BackupStore)
Update org.apache.hadoop.mapred.BackupStore.<clinit>() org.apache.hadoop.mapred.BackupStore.<clinit>()
Delete org.apache.hadoop.mapred.BackupStore.LOG : Log org.apache.hadoop.mapred.BackupStore
Update org.apache.hadoop.mapred.BasicTypeSorterBase org.apache.hadoop.mapred.BasicTypeSorterBase
Update org.apache.hadoop.mapred.BufferSorter org.apache.hadoop.mapred.BufferSorter
Update org.apache.hadoop.mapred.CleanupQueue.PathCleanupThread org.apache.hadoop.mapred.CleanupQueue.PathCleanupThread
Update org.apache.hadoop.mapred.CleanupQueue.PathCleanupThread.run() org.apache.hadoop.mapred.CleanupQueue.PathCleanupThread.run()
Update org.apache.hadoop.mapred.CleanupQueue.PathDeletionContext org.apache.hadoop.mapred.CleanupQueue.PathDeletionContext
Update org.apache.hadoop.mapred.CleanupQueue org.apache.hadoop.mapred.CleanupQueue
Delete org.apache.hadoop.mapred.CleanupQueue.LOG : Log org.apache.hadoop.mapred.CleanupQueue
Update org.apache.hadoop.mapred.Clock org.apache.hadoop.mapred.Clock
Update org.apache.hadoop.mapred.ClusterStatus.BlackListInfo org.apache.hadoop.mapred.ClusterStatus.BlackListInfo
Update org.apache.hadoop.mapred.ClusterStatus org.apache.hadoop.mapred.ClusterStatus
Update org.apache.hadoop.mapred.Counters.1 org.apache.hadoop.mapred.Counters.1
Update org.apache.hadoop.mapred.Counters.Counter org.apache.hadoop.mapred.Counters.Counter
Update org.apache.hadoop.mapred.Counters.CountersExceededException org.apache.hadoop.mapred.Counters.CountersExceededException
Update org.apache.hadoop.mapred.Counters.FrameworkGroupImpl org.apache.hadoop.mapred.Counters.FrameworkGroupImpl
Update org.apache.hadoop.mapred.Counters.FSGroupImpl org.apache.hadoop.mapred.Counters.FSGroupImpl
Update org.apache.hadoop.mapred.Counters.GenericGroup org.apache.hadoop.mapred.Counters.GenericGroup
Update org.apache.hadoop.mapred.Counters.Group org.apache.hadoop.mapred.Counters.Group
Update org.apache.hadoop.mapred.Counters.GroupFactory.1 org.apache.hadoop.mapred.Counters.GroupFactory.1
Update org.apache.hadoop.mapred.Counters.GroupFactory org.apache.hadoop.mapred.Counters.GroupFactory
Update org.apache.hadoop.mapred.Counters org.apache.hadoop.mapred.Counters
Delete org.apache.hadoop.mapred.Counters.log(Log) org.apache.hadoop.mapred.Counters
Update org.apache.hadoop.mapred.CumulativePeriodicStats org.apache.hadoop.mapred.CumulativePeriodicStats
Update org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser
Delete org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser.LOG : Log org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser
Update org.apache.hadoop.mapred.FileAlreadyExistsException org.apache.hadoop.mapred.FileAlreadyExistsException
Update org.apache.hadoop.mapred.FileInputFormat.1 org.apache.hadoop.mapred.FileInputFormat.1
Update org.apache.hadoop.mapred.FileInputFormat.2 org.apache.hadoop.mapred.FileInputFormat.2
Update org.apache.hadoop.mapred.FileInputFormat.Counter org.apache.hadoop.mapred.FileInputFormat.Counter
Update org.apache.hadoop.mapred.FileInputFormat.MultiPathFilter org.apache.hadoop.mapred.FileInputFormat.MultiPathFilter
Update org.apache.hadoop.mapred.FileInputFormat.NodeInfo org.apache.hadoop.mapred.FileInputFormat.NodeInfo
Update org.apache.hadoop.mapred.FileInputFormat org.apache.hadoop.mapred.FileInputFormat
Update org.apache.hadoop.mapred.FileInputFormat.<init>() org.apache.hadoop.mapred.FileInputFormat.<init>()
Update org.apache.hadoop.mapred.FileInputFormat.setMinSplitSize(long) org.apache.hadoop.mapred.FileInputFormat.setMinSplitSize(long)
Update org.apache.hadoop.mapred.FileInputFormat.getSplits(JobConf,int) org.apache.hadoop.mapred.FileInputFormat.getSplits(JobConf,int)
Update org.apache.hadoop.mapred.FileInputFormat.computeSplitSize(long,long,long) org.apache.hadoop.mapred.FileInputFormat.computeSplitSize(long,long,long)
Update org.apache.hadoop.mapred.FileInputFormat.getBlockIndex(BlockLocation[],long) org.apache.hadoop.mapred.FileInputFormat.getBlockIndex(BlockLocation[],long)
Update org.apache.hadoop.mapred.FileInputFormat.setInputPaths(JobConf,String) org.apache.hadoop.mapred.FileInputFormat.setInputPaths(JobConf,String)
Update org.apache.hadoop.mapred.FileInputFormat.addInputPaths(JobConf,String) org.apache.hadoop.mapred.FileInputFormat.addInputPaths(JobConf,String)
Update org.apache.hadoop.mapred.FileInputFormat.setInputPaths(JobConf,Path[]) org.apache.hadoop.mapred.FileInputFormat.setInputPaths(JobConf,Path[])
Update org.apache.hadoop.mapred.FileInputFormat.addInputPath(JobConf,Path) org.apache.hadoop.mapred.FileInputFormat.addInputPath(JobConf,Path)
Update org.apache.hadoop.mapred.FileInputFormat.getPathStrings(String) org.apache.hadoop.mapred.FileInputFormat.getPathStrings(String)
Update org.apache.hadoop.mapred.FileInputFormat.getInputPaths(JobConf) org.apache.hadoop.mapred.FileInputFormat.getInputPaths(JobConf)
Update org.apache.hadoop.mapred.FileInputFormat.sortInDescendingOrder(List) org.apache.hadoop.mapred.FileInputFormat.sortInDescendingOrder(List)
Update org.apache.hadoop.mapred.FileInputFormat.getSplitHosts(BlockLocation[],long,long,NetworkTopology) org.apache.hadoop.mapred.FileInputFormat.getSplitHosts(BlockLocation[],long,long,NetworkTopology)
Update org.apache.hadoop.mapred.FileInputFormat.getSplitHostsAndCachedHosts(BlockLocation[],long,long,NetworkTopology) org.apache.hadoop.mapred.FileInputFormat.getSplitHostsAndCachedHosts(BlockLocation[],long,long,NetworkTopology)
Update org.apache.hadoop.mapred.FileInputFormat.identifyHosts(int,Map) org.apache.hadoop.mapred.FileInputFormat.identifyHosts(int,Map)
Update org.apache.hadoop.mapred.FileInputFormat.fakeRacks(BlockLocation[],int) org.apache.hadoop.mapred.FileInputFormat.fakeRacks(BlockLocation[],int)
Update org.apache.hadoop.mapred.FileInputFormat.<clinit>() org.apache.hadoop.mapred.FileInputFormat.<clinit>()
Delete org.apache.hadoop.mapred.FileInputFormat.LOG : Log org.apache.hadoop.mapred.FileInputFormat
Update org.apache.hadoop.mapred.FileOutputCommitter org.apache.hadoop.mapred.FileOutputCommitter
Update org.apache.hadoop.mapred.FileOutputCommitter.<init>() org.apache.hadoop.mapred.FileOutputCommitter.<init>()
Update org.apache.hadoop.mapred.FileOutputCommitter.getOutputPath(JobContext) org.apache.hadoop.mapred.FileOutputCommitter.getOutputPath(JobContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.getOutputPath(TaskAttemptContext) org.apache.hadoop.mapred.FileOutputCommitter.getOutputPath(TaskAttemptContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.getWrapped(JobContext) org.apache.hadoop.mapred.FileOutputCommitter.getWrapped(JobContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.getWrapped(TaskAttemptContext) org.apache.hadoop.mapred.FileOutputCommitter.getWrapped(TaskAttemptContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext,Path) org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext,Path)
Update org.apache.hadoop.mapred.FileOutputCommitter.isRecoverySupported(JobContext) org.apache.hadoop.mapred.FileOutputCommitter.isRecoverySupported(JobContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.recoverTask(TaskAttemptContext) org.apache.hadoop.mapred.FileOutputCommitter.recoverTask(TaskAttemptContext)
Update org.apache.hadoop.mapred.FileOutputCommitter.<clinit>() org.apache.hadoop.mapred.FileOutputCommitter.<clinit>()
Delete org.apache.hadoop.mapred.FileOutputCommitter.LOG : Log org.apache.hadoop.mapred.FileOutputCommitter
Update org.apache.hadoop.mapred.FileOutputFormat.Counter org.apache.hadoop.mapred.FileOutputFormat.Counter
Update org.apache.hadoop.mapred.FileOutputFormat org.apache.hadoop.mapred.FileOutputFormat
Update org.apache.hadoop.mapred.FileSplit org.apache.hadoop.mapred.FileSplit
Update org.apache.hadoop.mapred.FixedLengthInputFormat org.apache.hadoop.mapred.FixedLengthInputFormat
Update org.apache.hadoop.mapred.FixedLengthRecordReader org.apache.hadoop.mapred.FixedLengthRecordReader
Update org.apache.hadoop.mapred.ID org.apache.hadoop.mapred.ID
Update org.apache.hadoop.mapred.IFile.Reader org.apache.hadoop.mapred.IFile.Reader
Update org.apache.hadoop.mapred.IFile.Writer org.apache.hadoop.mapred.IFile.Writer
Update org.apache.hadoop.mapred.IFile org.apache.hadoop.mapred.IFile
Delete org.apache.hadoop.mapred.IFile.access$000() org.apache.hadoop.mapred.IFile
Delete org.apache.hadoop.mapred.IFile.LOG : Log org.apache.hadoop.mapred.IFile
Update org.apache.hadoop.mapred.IFileInputStream org.apache.hadoop.mapred.IFileInputStream
Delete org.apache.hadoop.mapred.IFileInputStream.LOG : Log org.apache.hadoop.mapred.IFileInputStream
Update org.apache.hadoop.mapred.IFileOutputStream org.apache.hadoop.mapred.IFileOutputStream
Update org.apache.hadoop.mapred.IFileOutputStream.close() org.apache.hadoop.mapred.IFileOutputStream.close()
Update org.apache.hadoop.mapred.IndexCache.1 org.apache.hadoop.mapred.IndexCache.1
Update org.apache.hadoop.mapred.IndexCache.IndexInformation org.apache.hadoop.mapred.IndexCache.IndexInformation
Update org.apache.hadoop.mapred.IndexCache org.apache.hadoop.mapred.IndexCache
Delete org.apache.hadoop.mapred.IndexCache.LOG : Log org.apache.hadoop.mapred.IndexCache
Update org.apache.hadoop.mapred.IndexRecord org.apache.hadoop.mapred.IndexRecord
Update org.apache.hadoop.mapred.InputFormat org.apache.hadoop.mapred.InputFormat
Update org.apache.hadoop.mapred.InputSplit org.apache.hadoop.mapred.InputSplit
Update org.apache.hadoop.mapred.InputSplitWithLocationInfo org.apache.hadoop.mapred.InputSplitWithLocationInfo
Update org.apache.hadoop.mapred.InvalidFileTypeException org.apache.hadoop.mapred.InvalidFileTypeException
Update org.apache.hadoop.mapred.InvalidInputException org.apache.hadoop.mapred.InvalidInputException
Update org.apache.hadoop.mapred.InvalidJobConfException org.apache.hadoop.mapred.InvalidJobConfException
Update org.apache.hadoop.mapred.JobACLsManager org.apache.hadoop.mapred.JobACLsManager
Delete org.apache.hadoop.mapred.JobACLsManager.LOG : Log org.apache.hadoop.mapred.JobACLsManager
Update org.apache.hadoop.mapred.JobClient.1 org.apache.hadoop.mapred.JobClient.1
Update org.apache.hadoop.mapred.JobClient.10 org.apache.hadoop.mapred.JobClient.10
Update org.apache.hadoop.mapred.JobClient.11 org.apache.hadoop.mapred.JobClient.11
Update org.apache.hadoop.mapred.JobClient.12 org.apache.hadoop.mapred.JobClient.12
Update org.apache.hadoop.mapred.JobClient.13 org.apache.hadoop.mapred.JobClient.13
Update org.apache.hadoop.mapred.JobClient.14 org.apache.hadoop.mapred.JobClient.14
Update org.apache.hadoop.mapred.JobClient.15 org.apache.hadoop.mapred.JobClient.15
Update org.apache.hadoop.mapred.JobClient.16 org.apache.hadoop.mapred.JobClient.16
Update org.apache.hadoop.mapred.JobClient.2 org.apache.hadoop.mapred.JobClient.2
Update org.apache.hadoop.mapred.JobClient.3 org.apache.hadoop.mapred.JobClient.3
Update org.apache.hadoop.mapred.JobClient.4 org.apache.hadoop.mapred.JobClient.4
Update org.apache.hadoop.mapred.JobClient.5 org.apache.hadoop.mapred.JobClient.5
Update org.apache.hadoop.mapred.JobClient.6 org.apache.hadoop.mapred.JobClient.6
Update org.apache.hadoop.mapred.JobClient.7 org.apache.hadoop.mapred.JobClient.7
Update org.apache.hadoop.mapred.JobClient.8 org.apache.hadoop.mapred.JobClient.8
Update org.apache.hadoop.mapred.JobClient.9 org.apache.hadoop.mapred.JobClient.9
Update org.apache.hadoop.mapred.JobClient.NetworkedJob org.apache.hadoop.mapred.JobClient.NetworkedJob
Update org.apache.hadoop.mapred.JobClient.TaskStatusFilter org.apache.hadoop.mapred.JobClient.TaskStatusFilter
Update org.apache.hadoop.mapred.JobClient org.apache.hadoop.mapred.JobClient
Update org.apache.hadoop.mapred.JobClient.<init>() org.apache.hadoop.mapred.JobClient.<init>()
Update org.apache.hadoop.mapred.JobClient.<init>(JobConf) org.apache.hadoop.mapred.JobClient.<init>(JobConf)
Update org.apache.hadoop.mapred.JobClient.<init>(Configuration) org.apache.hadoop.mapred.JobClient.<init>(Configuration)
Update org.apache.hadoop.mapred.JobClient.init(JobConf) org.apache.hadoop.mapred.JobClient.init(JobConf)
Update org.apache.hadoop.mapred.JobClient.<init>(InetSocketAddress,Configuration) org.apache.hadoop.mapred.JobClient.<init>(InetSocketAddress,Configuration)
Update org.apache.hadoop.mapred.JobClient.close() org.apache.hadoop.mapred.JobClient.close()
Update org.apache.hadoop.mapred.JobClient.getFs() org.apache.hadoop.mapred.JobClient.getFs()
Update org.apache.hadoop.mapred.JobClient.submitJob(String) org.apache.hadoop.mapred.JobClient.submitJob(String)
Update org.apache.hadoop.mapred.JobClient.submitJob(JobConf) org.apache.hadoop.mapred.JobClient.submitJob(JobConf)
Update org.apache.hadoop.mapred.JobClient.submitJobInternal(JobConf) org.apache.hadoop.mapred.JobClient.submitJobInternal(JobConf)
Update org.apache.hadoop.mapred.JobClient.getJobUsingCluster(JobID) org.apache.hadoop.mapred.JobClient.getJobUsingCluster(JobID)
Update org.apache.hadoop.mapred.JobClient.getJob(JobID) org.apache.hadoop.mapred.JobClient.getJob(JobID)
Update org.apache.hadoop.mapred.JobClient.getJob(String) org.apache.hadoop.mapred.JobClient.getJob(String)
Update org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobID) org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobID)
Update org.apache.hadoop.mapred.JobClient.getTaskReports(JobID,TaskType) org.apache.hadoop.mapred.JobClient.getTaskReports(JobID,TaskType)
Update org.apache.hadoop.mapred.JobClient.getMapTaskReports(String) org.apache.hadoop.mapred.JobClient.getMapTaskReports(String)
Update org.apache.hadoop.mapred.JobClient.getReduceTaskReports(JobID) org.apache.hadoop.mapred.JobClient.getReduceTaskReports(JobID)
Update org.apache.hadoop.mapred.JobClient.getCleanupTaskReports(JobID) org.apache.hadoop.mapred.JobClient.getCleanupTaskReports(JobID)
Update org.apache.hadoop.mapred.JobClient.getSetupTaskReports(JobID) org.apache.hadoop.mapred.JobClient.getSetupTaskReports(JobID)
Update org.apache.hadoop.mapred.JobClient.getReduceTaskReports(String) org.apache.hadoop.mapred.JobClient.getReduceTaskReports(String)
Update org.apache.hadoop.mapred.JobClient.displayTasks(JobID,String,String) org.apache.hadoop.mapred.JobClient.displayTasks(JobID,String,String)
Update org.apache.hadoop.mapred.JobClient.getClusterStatus() org.apache.hadoop.mapred.JobClient.getClusterStatus()
Update org.apache.hadoop.mapred.JobClient.arrayToStringList(TaskTrackerInfo[]) org.apache.hadoop.mapred.JobClient.arrayToStringList(TaskTrackerInfo[])
Update org.apache.hadoop.mapred.JobClient.arrayToBlackListInfo(TaskTrackerInfo[]) org.apache.hadoop.mapred.JobClient.arrayToBlackListInfo(TaskTrackerInfo[])
Update org.apache.hadoop.mapred.JobClient.getClusterStatus(boolean) org.apache.hadoop.mapred.JobClient.getClusterStatus(boolean)
Update org.apache.hadoop.mapred.JobClient.jobsToComplete() org.apache.hadoop.mapred.JobClient.jobsToComplete()
Update org.apache.hadoop.mapred.JobClient.getAllJobs() org.apache.hadoop.mapred.JobClient.getAllJobs()
Update org.apache.hadoop.mapred.JobClient.runJob(JobConf) org.apache.hadoop.mapred.JobClient.runJob(JobConf)
Update org.apache.hadoop.mapred.JobClient.monitorAndPrintJob(JobConf,RunningJob) org.apache.hadoop.mapred.JobClient.monitorAndPrintJob(JobConf,RunningJob)
Update org.apache.hadoop.mapred.JobClient.getTaskLogURL(TaskAttemptID,String) org.apache.hadoop.mapred.JobClient.getTaskLogURL(TaskAttemptID,String)
Update org.apache.hadoop.mapred.JobClient.getConfiguration(String) org.apache.hadoop.mapred.JobClient.getConfiguration(String)
Update org.apache.hadoop.mapred.JobClient.getTaskOutputFilter(JobConf) org.apache.hadoop.mapred.JobClient.getTaskOutputFilter(JobConf)
Update org.apache.hadoop.mapred.JobClient.setTaskOutputFilter(JobConf,JobClient$TaskStatusFilter) org.apache.hadoop.mapred.JobClient.setTaskOutputFilter(JobConf,JobClient$TaskStatusFilter)
Update org.apache.hadoop.mapred.JobClient.getCounter(Counters,String,String) org.apache.hadoop.mapred.JobClient.getCounter(Counters,String,String)
Update org.apache.hadoop.mapred.JobClient.getDefaultMaps() org.apache.hadoop.mapred.JobClient.getDefaultMaps()
Update org.apache.hadoop.mapred.JobClient.getDefaultReduces() org.apache.hadoop.mapred.JobClient.getDefaultReduces()
Update org.apache.hadoop.mapred.JobClient.getSystemDir() org.apache.hadoop.mapred.JobClient.getSystemDir()
Update org.apache.hadoop.mapred.JobClient.isJobDirValid(Path,FileSystem) org.apache.hadoop.mapred.JobClient.isJobDirValid(Path,FileSystem)
Update org.apache.hadoop.mapred.JobClient.getStagingAreaDir() org.apache.hadoop.mapred.JobClient.getStagingAreaDir()
Update org.apache.hadoop.mapred.JobClient.getJobQueueInfo(QueueInfo) org.apache.hadoop.mapred.JobClient.getJobQueueInfo(QueueInfo)
Update org.apache.hadoop.mapred.JobClient.getJobQueueInfoArray(QueueInfo[]) org.apache.hadoop.mapred.JobClient.getJobQueueInfoArray(QueueInfo[])
Update org.apache.hadoop.mapred.JobClient.getRootQueues() org.apache.hadoop.mapred.JobClient.getRootQueues()
Update org.apache.hadoop.mapred.JobClient.getChildQueues(String) org.apache.hadoop.mapred.JobClient.getChildQueues(String)
Update org.apache.hadoop.mapred.JobClient.getQueues() org.apache.hadoop.mapred.JobClient.getQueues()
Update org.apache.hadoop.mapred.JobClient.getJobsFromQueue(String) org.apache.hadoop.mapred.JobClient.getJobsFromQueue(String)
Update org.apache.hadoop.mapred.JobClient.getQueueInfo(String) org.apache.hadoop.mapred.JobClient.getQueueInfo(String)
Update org.apache.hadoop.mapred.JobClient.getQueueAclsForCurrentUser() org.apache.hadoop.mapred.JobClient.getQueueAclsForCurrentUser()
Update org.apache.hadoop.mapred.JobClient.getDelegationToken(Text) org.apache.hadoop.mapred.JobClient.getDelegationToken(Text)
Update org.apache.hadoop.mapred.JobClient.renewDelegationToken(Token) org.apache.hadoop.mapred.JobClient.renewDelegationToken(Token)
Update org.apache.hadoop.mapred.JobClient.cancelDelegationToken(Token) org.apache.hadoop.mapred.JobClient.cancelDelegationToken(Token)
Update org.apache.hadoop.mapred.JobClient.main(String[]) org.apache.hadoop.mapred.JobClient.main(String[])
Update org.apache.hadoop.mapred.JobClient.<clinit>() org.apache.hadoop.mapred.JobClient.<clinit>()
Update org.apache.hadoop.mapred.JobConf org.apache.hadoop.mapred.JobConf
Update org.apache.hadoop.mapred.JobConf.<init>() org.apache.hadoop.mapred.JobConf.<init>()
Update org.apache.hadoop.mapred.JobConf.<init>(Class) org.apache.hadoop.mapred.JobConf.<init>(Class)
Update org.apache.hadoop.mapred.JobConf.<init>(Configuration) org.apache.hadoop.mapred.JobConf.<init>(Configuration)
Update org.apache.hadoop.mapred.JobConf.<init>(Configuration,Class) org.apache.hadoop.mapred.JobConf.<init>(Configuration,Class)
Update org.apache.hadoop.mapred.JobConf.<init>(String) org.apache.hadoop.mapred.JobConf.<init>(String)
Update org.apache.hadoop.mapred.JobConf.<init>(Path) org.apache.hadoop.mapred.JobConf.<init>(Path)
Update org.apache.hadoop.mapred.JobConf.<init>(boolean) org.apache.hadoop.mapred.JobConf.<init>(boolean)
Update org.apache.hadoop.mapred.JobConf.getCredentials() org.apache.hadoop.mapred.JobConf.getCredentials()
Update org.apache.hadoop.mapred.JobConf.setCredentials(Credentials) org.apache.hadoop.mapred.JobConf.setCredentials(Credentials)
Update org.apache.hadoop.mapred.JobConf.getJar() org.apache.hadoop.mapred.JobConf.getJar()
Update org.apache.hadoop.mapred.JobConf.setJar(String) org.apache.hadoop.mapred.JobConf.setJar(String)
Update org.apache.hadoop.mapred.JobConf.getJarUnpackPattern() org.apache.hadoop.mapred.JobConf.getJarUnpackPattern()
Update org.apache.hadoop.mapred.JobConf.setJarByClass(Class) org.apache.hadoop.mapred.JobConf.setJarByClass(Class)
Update org.apache.hadoop.mapred.JobConf.getLocalDirs() org.apache.hadoop.mapred.JobConf.getLocalDirs()
Update org.apache.hadoop.mapred.JobConf.deleteLocalFiles() org.apache.hadoop.mapred.JobConf.deleteLocalFiles()
Update org.apache.hadoop.mapred.JobConf.deleteLocalFiles(String) org.apache.hadoop.mapred.JobConf.deleteLocalFiles(String)
Update org.apache.hadoop.mapred.JobConf.getLocalPath(String) org.apache.hadoop.mapred.JobConf.getLocalPath(String)
Update org.apache.hadoop.mapred.JobConf.getUser() org.apache.hadoop.mapred.JobConf.getUser()
Update org.apache.hadoop.mapred.JobConf.setUser(String) org.apache.hadoop.mapred.JobConf.setUser(String)
Update org.apache.hadoop.mapred.JobConf.setKeepFailedTaskFiles(boolean) org.apache.hadoop.mapred.JobConf.setKeepFailedTaskFiles(boolean)
Update org.apache.hadoop.mapred.JobConf.getKeepFailedTaskFiles() org.apache.hadoop.mapred.JobConf.getKeepFailedTaskFiles()
Update org.apache.hadoop.mapred.JobConf.setKeepTaskFilesPattern(String) org.apache.hadoop.mapred.JobConf.setKeepTaskFilesPattern(String)
Update org.apache.hadoop.mapred.JobConf.getKeepTaskFilesPattern() org.apache.hadoop.mapred.JobConf.getKeepTaskFilesPattern()
Update org.apache.hadoop.mapred.JobConf.setWorkingDirectory(Path) org.apache.hadoop.mapred.JobConf.setWorkingDirectory(Path)
Update org.apache.hadoop.mapred.JobConf.getWorkingDirectory() org.apache.hadoop.mapred.JobConf.getWorkingDirectory()
Update org.apache.hadoop.mapred.JobConf.setNumTasksToExecutePerJvm(int) org.apache.hadoop.mapred.JobConf.setNumTasksToExecutePerJvm(int)
Update org.apache.hadoop.mapred.JobConf.getNumTasksToExecutePerJvm() org.apache.hadoop.mapred.JobConf.getNumTasksToExecutePerJvm()
Update org.apache.hadoop.mapred.JobConf.getInputFormat() org.apache.hadoop.mapred.JobConf.getInputFormat()
Update org.apache.hadoop.mapred.JobConf.setInputFormat(Class) org.apache.hadoop.mapred.JobConf.setInputFormat(Class)
Update org.apache.hadoop.mapred.JobConf.getOutputFormat() org.apache.hadoop.mapred.JobConf.getOutputFormat()
Update org.apache.hadoop.mapred.JobConf.getOutputCommitter() org.apache.hadoop.mapred.JobConf.getOutputCommitter()
Update org.apache.hadoop.mapred.JobConf.setOutputCommitter(Class) org.apache.hadoop.mapred.JobConf.setOutputCommitter(Class)
Update org.apache.hadoop.mapred.JobConf.setOutputFormat(Class) org.apache.hadoop.mapred.JobConf.setOutputFormat(Class)
Update org.apache.hadoop.mapred.JobConf.setCompressMapOutput(boolean) org.apache.hadoop.mapred.JobConf.setCompressMapOutput(boolean)
Update org.apache.hadoop.mapred.JobConf.getCompressMapOutput() org.apache.hadoop.mapred.JobConf.getCompressMapOutput()
Update org.apache.hadoop.mapred.JobConf.setMapOutputCompressorClass(Class) org.apache.hadoop.mapred.JobConf.setMapOutputCompressorClass(Class)
Update org.apache.hadoop.mapred.JobConf.getMapOutputCompressorClass(Class) org.apache.hadoop.mapred.JobConf.getMapOutputCompressorClass(Class)
Update org.apache.hadoop.mapred.JobConf.getMapOutputKeyClass() org.apache.hadoop.mapred.JobConf.getMapOutputKeyClass()
Update org.apache.hadoop.mapred.JobConf.setMapOutputKeyClass(Class) org.apache.hadoop.mapred.JobConf.setMapOutputKeyClass(Class)
Update org.apache.hadoop.mapred.JobConf.getMapOutputValueClass() org.apache.hadoop.mapred.JobConf.getMapOutputValueClass()
Update org.apache.hadoop.mapred.JobConf.setMapOutputValueClass(Class) org.apache.hadoop.mapred.JobConf.setMapOutputValueClass(Class)
Update org.apache.hadoop.mapred.JobConf.getOutputKeyClass() org.apache.hadoop.mapred.JobConf.getOutputKeyClass()
Update org.apache.hadoop.mapred.JobConf.setOutputKeyClass(Class) org.apache.hadoop.mapred.JobConf.setOutputKeyClass(Class)
Update org.apache.hadoop.mapred.JobConf.getOutputKeyComparator() org.apache.hadoop.mapred.JobConf.getOutputKeyComparator()
Update org.apache.hadoop.mapred.JobConf.setOutputKeyComparatorClass(Class) org.apache.hadoop.mapred.JobConf.setOutputKeyComparatorClass(Class)
Update org.apache.hadoop.mapred.JobConf.setKeyFieldComparatorOptions(String) org.apache.hadoop.mapred.JobConf.setKeyFieldComparatorOptions(String)
Update org.apache.hadoop.mapred.JobConf.getKeyFieldComparatorOption() org.apache.hadoop.mapred.JobConf.getKeyFieldComparatorOption()
Update org.apache.hadoop.mapred.JobConf.setKeyFieldPartitionerOptions(String) org.apache.hadoop.mapred.JobConf.setKeyFieldPartitionerOptions(String)
Update org.apache.hadoop.mapred.JobConf.getKeyFieldPartitionerOption() org.apache.hadoop.mapred.JobConf.getKeyFieldPartitionerOption()
Update org.apache.hadoop.mapred.JobConf.getCombinerKeyGroupingComparator() org.apache.hadoop.mapred.JobConf.getCombinerKeyGroupingComparator()
Update org.apache.hadoop.mapred.JobConf.getOutputValueGroupingComparator() org.apache.hadoop.mapred.JobConf.getOutputValueGroupingComparator()
Update org.apache.hadoop.mapred.JobConf.setCombinerKeyGroupingComparator(Class) org.apache.hadoop.mapred.JobConf.setCombinerKeyGroupingComparator(Class)
Update org.apache.hadoop.mapred.JobConf.setOutputValueGroupingComparator(Class) org.apache.hadoop.mapred.JobConf.setOutputValueGroupingComparator(Class)
Update org.apache.hadoop.mapred.JobConf.getUseNewMapper() org.apache.hadoop.mapred.JobConf.getUseNewMapper()
Update org.apache.hadoop.mapred.JobConf.setUseNewMapper(boolean) org.apache.hadoop.mapred.JobConf.setUseNewMapper(boolean)
Update org.apache.hadoop.mapred.JobConf.getUseNewReducer() org.apache.hadoop.mapred.JobConf.getUseNewReducer()
Update org.apache.hadoop.mapred.JobConf.setUseNewReducer(boolean) org.apache.hadoop.mapred.JobConf.setUseNewReducer(boolean)
Update org.apache.hadoop.mapred.JobConf.getOutputValueClass() org.apache.hadoop.mapred.JobConf.getOutputValueClass()
Update org.apache.hadoop.mapred.JobConf.setOutputValueClass(Class) org.apache.hadoop.mapred.JobConf.setOutputValueClass(Class)
Update org.apache.hadoop.mapred.JobConf.getMapperClass() org.apache.hadoop.mapred.JobConf.getMapperClass()
Update org.apache.hadoop.mapred.JobConf.setMapperClass(Class) org.apache.hadoop.mapred.JobConf.setMapperClass(Class)
Update org.apache.hadoop.mapred.JobConf.getMapRunnerClass() org.apache.hadoop.mapred.JobConf.getMapRunnerClass()
Update org.apache.hadoop.mapred.JobConf.setMapRunnerClass(Class) org.apache.hadoop.mapred.JobConf.setMapRunnerClass(Class)
Update org.apache.hadoop.mapred.JobConf.getPartitionerClass() org.apache.hadoop.mapred.JobConf.getPartitionerClass()
Update org.apache.hadoop.mapred.JobConf.setPartitionerClass(Class) org.apache.hadoop.mapred.JobConf.setPartitionerClass(Class)
Update org.apache.hadoop.mapred.JobConf.getReducerClass() org.apache.hadoop.mapred.JobConf.getReducerClass()
Update org.apache.hadoop.mapred.JobConf.setReducerClass(Class) org.apache.hadoop.mapred.JobConf.setReducerClass(Class)
Update org.apache.hadoop.mapred.JobConf.getCombinerClass() org.apache.hadoop.mapred.JobConf.getCombinerClass()
Update org.apache.hadoop.mapred.JobConf.setCombinerClass(Class) org.apache.hadoop.mapred.JobConf.setCombinerClass(Class)
Update org.apache.hadoop.mapred.JobConf.getSpeculativeExecution() org.apache.hadoop.mapred.JobConf.getSpeculativeExecution()
Update org.apache.hadoop.mapred.JobConf.setSpeculativeExecution(boolean) org.apache.hadoop.mapred.JobConf.setSpeculativeExecution(boolean)
Update org.apache.hadoop.mapred.JobConf.getMapSpeculativeExecution() org.apache.hadoop.mapred.JobConf.getMapSpeculativeExecution()
Update org.apache.hadoop.mapred.JobConf.setMapSpeculativeExecution(boolean) org.apache.hadoop.mapred.JobConf.setMapSpeculativeExecution(boolean)
Update org.apache.hadoop.mapred.JobConf.getReduceSpeculativeExecution() org.apache.hadoop.mapred.JobConf.getReduceSpeculativeExecution()
Update org.apache.hadoop.mapred.JobConf.setReduceSpeculativeExecution(boolean) org.apache.hadoop.mapred.JobConf.setReduceSpeculativeExecution(boolean)
Update org.apache.hadoop.mapred.JobConf.getNumMapTasks() org.apache.hadoop.mapred.JobConf.getNumMapTasks()
Update org.apache.hadoop.mapred.JobConf.setNumMapTasks(int) org.apache.hadoop.mapred.JobConf.setNumMapTasks(int)
Update org.apache.hadoop.mapred.JobConf.getNumReduceTasks() org.apache.hadoop.mapred.JobConf.getNumReduceTasks()
Update org.apache.hadoop.mapred.JobConf.setNumReduceTasks(int) org.apache.hadoop.mapred.JobConf.setNumReduceTasks(int)
Update org.apache.hadoop.mapred.JobConf.getMaxMapAttempts() org.apache.hadoop.mapred.JobConf.getMaxMapAttempts()
Update org.apache.hadoop.mapred.JobConf.setMaxMapAttempts(int) org.apache.hadoop.mapred.JobConf.setMaxMapAttempts(int)
Update org.apache.hadoop.mapred.JobConf.getMaxReduceAttempts() org.apache.hadoop.mapred.JobConf.getMaxReduceAttempts()
Update org.apache.hadoop.mapred.JobConf.setMaxReduceAttempts(int) org.apache.hadoop.mapred.JobConf.setMaxReduceAttempts(int)
Update org.apache.hadoop.mapred.JobConf.getJobName() org.apache.hadoop.mapred.JobConf.getJobName()
Update org.apache.hadoop.mapred.JobConf.setJobName(String) org.apache.hadoop.mapred.JobConf.setJobName(String)
Update org.apache.hadoop.mapred.JobConf.getSessionId() org.apache.hadoop.mapred.JobConf.getSessionId()
Update org.apache.hadoop.mapred.JobConf.setSessionId(String) org.apache.hadoop.mapred.JobConf.setSessionId(String)
Update org.apache.hadoop.mapred.JobConf.setMaxTaskFailuresPerTracker(int) org.apache.hadoop.mapred.JobConf.setMaxTaskFailuresPerTracker(int)
Update org.apache.hadoop.mapred.JobConf.getMaxTaskFailuresPerTracker() org.apache.hadoop.mapred.JobConf.getMaxTaskFailuresPerTracker()
Update org.apache.hadoop.mapred.JobConf.getMaxMapTaskFailuresPercent() org.apache.hadoop.mapred.JobConf.getMaxMapTaskFailuresPercent()
Update org.apache.hadoop.mapred.JobConf.setMaxMapTaskFailuresPercent(int) org.apache.hadoop.mapred.JobConf.setMaxMapTaskFailuresPercent(int)
Update org.apache.hadoop.mapred.JobConf.getMaxReduceTaskFailuresPercent() org.apache.hadoop.mapred.JobConf.getMaxReduceTaskFailuresPercent()
Update org.apache.hadoop.mapred.JobConf.setMaxReduceTaskFailuresPercent(int) org.apache.hadoop.mapred.JobConf.setMaxReduceTaskFailuresPercent(int)
Update org.apache.hadoop.mapred.JobConf.setJobPriority(JobPriority) org.apache.hadoop.mapred.JobConf.setJobPriority(JobPriority)
Update org.apache.hadoop.mapred.JobConf.getJobPriority() org.apache.hadoop.mapred.JobConf.getJobPriority()
Update org.apache.hadoop.mapred.JobConf.setJobSubmitHostName(String) org.apache.hadoop.mapred.JobConf.setJobSubmitHostName(String)
Update org.apache.hadoop.mapred.JobConf.getJobSubmitHostName() org.apache.hadoop.mapred.JobConf.getJobSubmitHostName()
Update org.apache.hadoop.mapred.JobConf.setJobSubmitHostAddress(String) org.apache.hadoop.mapred.JobConf.setJobSubmitHostAddress(String)
Update org.apache.hadoop.mapred.JobConf.getJobSubmitHostAddress() org.apache.hadoop.mapred.JobConf.getJobSubmitHostAddress()
Update org.apache.hadoop.mapred.JobConf.getProfileEnabled() org.apache.hadoop.mapred.JobConf.getProfileEnabled()
Update org.apache.hadoop.mapred.JobConf.setProfileEnabled(boolean) org.apache.hadoop.mapred.JobConf.setProfileEnabled(boolean)
Update org.apache.hadoop.mapred.JobConf.getProfileParams() org.apache.hadoop.mapred.JobConf.getProfileParams()
Update org.apache.hadoop.mapred.JobConf.setProfileParams(String) org.apache.hadoop.mapred.JobConf.setProfileParams(String)
Update org.apache.hadoop.mapred.JobConf.getProfileTaskRange(boolean) org.apache.hadoop.mapred.JobConf.getProfileTaskRange(boolean)
Update org.apache.hadoop.mapred.JobConf.setProfileTaskRange(boolean,String) org.apache.hadoop.mapred.JobConf.setProfileTaskRange(boolean,String)
Update org.apache.hadoop.mapred.JobConf.setMapDebugScript(String) org.apache.hadoop.mapred.JobConf.setMapDebugScript(String)
Update org.apache.hadoop.mapred.JobConf.getMapDebugScript() org.apache.hadoop.mapred.JobConf.getMapDebugScript()
Update org.apache.hadoop.mapred.JobConf.setReduceDebugScript(String) org.apache.hadoop.mapred.JobConf.setReduceDebugScript(String)
Update org.apache.hadoop.mapred.JobConf.getReduceDebugScript() org.apache.hadoop.mapred.JobConf.getReduceDebugScript()
Update org.apache.hadoop.mapred.JobConf.getJobEndNotificationURI() org.apache.hadoop.mapred.JobConf.getJobEndNotificationURI()
Update org.apache.hadoop.mapred.JobConf.setJobEndNotificationURI(String) org.apache.hadoop.mapred.JobConf.setJobEndNotificationURI(String)
Update org.apache.hadoop.mapred.JobConf.getJobLocalDir() org.apache.hadoop.mapred.JobConf.getJobLocalDir()
Update org.apache.hadoop.mapred.JobConf.getMemoryForMapTask() org.apache.hadoop.mapred.JobConf.getMemoryForMapTask()
Update org.apache.hadoop.mapred.JobConf.setMemoryForMapTask(long) org.apache.hadoop.mapred.JobConf.setMemoryForMapTask(long)
Update org.apache.hadoop.mapred.JobConf.getMemoryForReduceTask() org.apache.hadoop.mapred.JobConf.getMemoryForReduceTask()
Update org.apache.hadoop.mapred.JobConf.getDeprecatedMemoryValue() org.apache.hadoop.mapred.JobConf.getDeprecatedMemoryValue()
Update org.apache.hadoop.mapred.JobConf.setMemoryForReduceTask(long) org.apache.hadoop.mapred.JobConf.setMemoryForReduceTask(long)
Update org.apache.hadoop.mapred.JobConf.getQueueName() org.apache.hadoop.mapred.JobConf.getQueueName()
Update org.apache.hadoop.mapred.JobConf.setQueueName(String) org.apache.hadoop.mapred.JobConf.setQueueName(String)
Update org.apache.hadoop.mapred.JobConf.normalizeMemoryConfigValue(long) org.apache.hadoop.mapred.JobConf.normalizeMemoryConfigValue(long)
Update org.apache.hadoop.mapred.JobConf.findContainingJar(Class) org.apache.hadoop.mapred.JobConf.findContainingJar(Class)
Update org.apache.hadoop.mapred.JobConf.getMaxVirtualMemoryForTask() org.apache.hadoop.mapred.JobConf.getMaxVirtualMemoryForTask()
Update org.apache.hadoop.mapred.JobConf.setMaxVirtualMemoryForTask(long) org.apache.hadoop.mapred.JobConf.setMaxVirtualMemoryForTask(long)
Update org.apache.hadoop.mapred.JobConf.getMaxPhysicalMemoryForTask() org.apache.hadoop.mapred.JobConf.getMaxPhysicalMemoryForTask()
Update org.apache.hadoop.mapred.JobConf.setMaxPhysicalMemoryForTask(long) org.apache.hadoop.mapred.JobConf.setMaxPhysicalMemoryForTask(long)
Update org.apache.hadoop.mapred.JobConf.deprecatedString(String) org.apache.hadoop.mapred.JobConf.deprecatedString(String)
Update org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation() org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation()
Update org.apache.hadoop.mapred.JobConf.<clinit>() org.apache.hadoop.mapred.JobConf.<clinit>()
Delete org.apache.hadoop.mapred.JobConf.LOG : Log org.apache.hadoop.mapred.JobConf
Delete org.apache.hadoop.mapred.JobConf.DEFAULT_LOG_LEVEL : Level org.apache.hadoop.mapred.JobConf
Update org.apache.hadoop.mapred.JobConfigurable org.apache.hadoop.mapred.JobConfigurable
Update org.apache.hadoop.mapred.JobContext org.apache.hadoop.mapred.JobContext
Update org.apache.hadoop.mapred.JobContextImpl org.apache.hadoop.mapred.JobContextImpl
Update org.apache.hadoop.mapred.jobcontrol.Job org.apache.hadoop.mapred.jobcontrol.Job
Delete org.apache.hadoop.mapred.jobcontrol.Job.LOG : Log org.apache.hadoop.mapred.jobcontrol.Job
Update org.apache.hadoop.mapred.jobcontrol.JobControl org.apache.hadoop.mapred.jobcontrol.JobControl
Update org.apache.hadoop.mapred.JobEndNotifier.JobEndStatusInfo org.apache.hadoop.mapred.JobEndNotifier.JobEndStatusInfo
Update org.apache.hadoop.mapred.JobEndNotifier org.apache.hadoop.mapred.JobEndNotifier
Delete org.apache.hadoop.mapred.JobEndNotifier.LOG : Log org.apache.hadoop.mapred.JobEndNotifier
Update org.apache.hadoop.mapred.JobID org.apache.hadoop.mapred.JobID
Update org.apache.hadoop.mapred.JobInfo org.apache.hadoop.mapred.JobInfo
Update org.apache.hadoop.mapred.JobInProgress.Counter org.apache.hadoop.mapred.JobInProgress.Counter
Update org.apache.hadoop.mapred.JobInProgress org.apache.hadoop.mapred.JobInProgress
Update org.apache.hadoop.mapred.JobPriority org.apache.hadoop.mapred.JobPriority
Update org.apache.hadoop.mapred.JobPriority.<clinit>() org.apache.hadoop.mapred.JobPriority.<clinit>()
Update org.apache.hadoop.mapred.JobProfile.1 org.apache.hadoop.mapred.JobProfile.1
Update org.apache.hadoop.mapred.JobProfile org.apache.hadoop.mapred.JobProfile
Update org.apache.hadoop.mapred.JobQueueClient org.apache.hadoop.mapred.JobQueueClient
Update org.apache.hadoop.mapred.JobQueueInfo org.apache.hadoop.mapred.JobQueueInfo
Update org.apache.hadoop.mapred.JobStatus org.apache.hadoop.mapred.JobStatus
Update org.apache.hadoop.mapred.JobStatus.<init>(JobID,float,float,float,float,int,JobPriority,String,String,String,String,String,boolean) org.apache.hadoop.mapred.JobStatus.<init>(JobID,float,float,float,float,int,JobPriority,String,String,String,String,String,boolean)
Update org.apache.hadoop.mapred.JobStatus.downgrade(JobStatus) org.apache.hadoop.mapred.JobStatus.downgrade(JobStatus)
Update org.apache.hadoop.mapred.JobStatus.getJobId() org.apache.hadoop.mapred.JobStatus.getJobId()
Update org.apache.hadoop.mapred.JobStatus.getJobID() org.apache.hadoop.mapred.JobStatus.getJobID()
Update org.apache.hadoop.mapred.JobStatus.getJobPriority() org.apache.hadoop.mapred.JobStatus.getJobPriority()
Update org.apache.hadoop.mapred.JobStatus.setMapProgress(float) org.apache.hadoop.mapred.JobStatus.setMapProgress(float)
Update org.apache.hadoop.mapred.JobStatus.setCleanupProgress(float) org.apache.hadoop.mapred.JobStatus.setCleanupProgress(float)
Update org.apache.hadoop.mapred.JobStatus.setSetupProgress(float) org.apache.hadoop.mapred.JobStatus.setSetupProgress(float)
Update org.apache.hadoop.mapred.JobStatus.setReduceProgress(float) org.apache.hadoop.mapred.JobStatus.setReduceProgress(float)
Update org.apache.hadoop.mapred.JobStatus.setFinishTime(long) org.apache.hadoop.mapred.JobStatus.setFinishTime(long)
Update org.apache.hadoop.mapred.JobStatus.setHistoryFile(String) org.apache.hadoop.mapred.JobStatus.setHistoryFile(String)
Update org.apache.hadoop.mapred.JobStatus.setTrackingUrl(String) org.apache.hadoop.mapred.JobStatus.setTrackingUrl(String)
Update org.apache.hadoop.mapred.JobStatus.setRetired() org.apache.hadoop.mapred.JobStatus.setRetired()
Update org.apache.hadoop.mapred.JobStatus.setRunState(int) org.apache.hadoop.mapred.JobStatus.setRunState(int)
Update org.apache.hadoop.mapred.JobStatus.getRunState() org.apache.hadoop.mapred.JobStatus.getRunState()
Update org.apache.hadoop.mapred.JobStatus.setStartTime(long) org.apache.hadoop.mapred.JobStatus.setStartTime(long)
Update org.apache.hadoop.mapred.JobStatus.setUsername(String) org.apache.hadoop.mapred.JobStatus.setUsername(String)
Update org.apache.hadoop.mapred.JobStatus.setSchedulingInfo(String) org.apache.hadoop.mapred.JobStatus.setSchedulingInfo(String)
Update org.apache.hadoop.mapred.JobStatus.setJobACLs(Map) org.apache.hadoop.mapred.JobStatus.setJobACLs(Map)
Update org.apache.hadoop.mapred.JobStatus.setFailureInfo(String) org.apache.hadoop.mapred.JobStatus.setFailureInfo(String)
Update org.apache.hadoop.mapred.JobStatus.setJobPriority(JobPriority) org.apache.hadoop.mapred.JobStatus.setJobPriority(JobPriority)
Update org.apache.hadoop.mapred.JobStatus.mapProgress() org.apache.hadoop.mapred.JobStatus.mapProgress()
Update org.apache.hadoop.mapred.JobStatus.cleanupProgress() org.apache.hadoop.mapred.JobStatus.cleanupProgress()
Update org.apache.hadoop.mapred.JobStatus.setupProgress() org.apache.hadoop.mapred.JobStatus.setupProgress()
Update org.apache.hadoop.mapred.JobStatus.reduceProgress() org.apache.hadoop.mapred.JobStatus.reduceProgress()
Update org.apache.hadoop.mapred.JobStatus.getOldNewJobRunState(JobStatus$State) org.apache.hadoop.mapred.JobStatus.getOldNewJobRunState(JobStatus$State)
Update org.apache.hadoop.mapred.JobStatus.getJobID() org.apache.hadoop.mapred.JobStatus.getJobID()
Update org.apache.hadoop.mapred.JobStatus.<clinit>() org.apache.hadoop.mapred.JobStatus.<clinit>()
Update org.apache.hadoop.mapred.JobTracker.State org.apache.hadoop.mapred.JobTracker.State
Update org.apache.hadoop.mapred.JobTracker org.apache.hadoop.mapred.JobTracker
Update org.apache.hadoop.mapred.join.ArrayListBackedIterator org.apache.hadoop.mapred.join.ArrayListBackedIterator
Update org.apache.hadoop.mapred.join.ComposableInputFormat org.apache.hadoop.mapred.join.ComposableInputFormat
Update org.apache.hadoop.mapred.join.ComposableRecordReader org.apache.hadoop.mapred.join.ComposableRecordReader
Update org.apache.hadoop.mapred.join.CompositeInputFormat org.apache.hadoop.mapred.join.CompositeInputFormat
Update org.apache.hadoop.mapred.join.CompositeInputSplit org.apache.hadoop.mapred.join.CompositeInputSplit
Update org.apache.hadoop.mapred.join.CompositeRecordReader.1 org.apache.hadoop.mapred.join.CompositeRecordReader.1
Update org.apache.hadoop.mapred.join.CompositeRecordReader.2 org.apache.hadoop.mapred.join.CompositeRecordReader.2
Update org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector
Update org.apache.hadoop.mapred.join.CompositeRecordReader org.apache.hadoop.mapred.join.CompositeRecordReader
Update org.apache.hadoop.mapred.join.InnerJoinRecordReader org.apache.hadoop.mapred.join.InnerJoinRecordReader
Update org.apache.hadoop.mapred.join.JoinRecordReader.JoinDelegationIterator org.apache.hadoop.mapred.join.JoinRecordReader.JoinDelegationIterator
Update org.apache.hadoop.mapred.join.JoinRecordReader org.apache.hadoop.mapred.join.JoinRecordReader
Update org.apache.hadoop.mapred.join.MultiFilterRecordReader.MultiFilterDelegationIterator org.apache.hadoop.mapred.join.MultiFilterRecordReader.MultiFilterDelegationIterator
Update org.apache.hadoop.mapred.join.MultiFilterRecordReader org.apache.hadoop.mapred.join.MultiFilterRecordReader
Update org.apache.hadoop.mapred.join.OuterJoinRecordReader org.apache.hadoop.mapred.join.OuterJoinRecordReader
Update org.apache.hadoop.mapred.join.OverrideRecordReader org.apache.hadoop.mapred.join.OverrideRecordReader
Update org.apache.hadoop.mapred.join.Parser.CNode org.apache.hadoop.mapred.join.Parser.CNode
Update org.apache.hadoop.mapred.join.Parser.Lexer org.apache.hadoop.mapred.join.Parser.Lexer
Update org.apache.hadoop.mapred.join.Parser.Node org.apache.hadoop.mapred.join.Parser.Node
Update org.apache.hadoop.mapred.join.Parser.NodeToken org.apache.hadoop.mapred.join.Parser.NodeToken
Update org.apache.hadoop.mapred.join.Parser.NumToken org.apache.hadoop.mapred.join.Parser.NumToken
Update org.apache.hadoop.mapred.join.Parser.StrToken org.apache.hadoop.mapred.join.Parser.StrToken
Update org.apache.hadoop.mapred.join.Parser.Token org.apache.hadoop.mapred.join.Parser.Token
Update org.apache.hadoop.mapred.join.Parser.TType org.apache.hadoop.mapred.join.Parser.TType
Update org.apache.hadoop.mapred.join.Parser.WNode org.apache.hadoop.mapred.join.Parser.WNode
Update org.apache.hadoop.mapred.join.Parser org.apache.hadoop.mapred.join.Parser
Update org.apache.hadoop.mapred.join.ResetableIterator.EMPTY org.apache.hadoop.mapred.join.ResetableIterator.EMPTY
Update org.apache.hadoop.mapred.join.ResetableIterator org.apache.hadoop.mapred.join.ResetableIterator
Update org.apache.hadoop.mapred.join.StreamBackedIterator org.apache.hadoop.mapred.join.StreamBackedIterator
Update org.apache.hadoop.mapred.join.TupleWritable org.apache.hadoop.mapred.join.TupleWritable
Update org.apache.hadoop.mapred.join.WrappedRecordReader org.apache.hadoop.mapred.join.WrappedRecordReader
Update org.apache.hadoop.mapred.JvmContext org.apache.hadoop.mapred.JvmContext
Delete org.apache.hadoop.mapred.JvmContext.LOG : Log org.apache.hadoop.mapred.JvmContext
Update org.apache.hadoop.mapred.JVMId org.apache.hadoop.mapred.JVMId
Update org.apache.hadoop.mapred.JVMId.compareTo(JVMId) org.apache.hadoop.mapred.JVMId.compareTo(JVMId)
Update org.apache.hadoop.mapred.JVMId.toString() org.apache.hadoop.mapred.JVMId.toString()
Update org.apache.hadoop.mapred.JVMId.appendTo(StringBuilder) org.apache.hadoop.mapred.JVMId.appendTo(StringBuilder)
Update org.apache.hadoop.mapred.JVMId.readFields(DataInput) org.apache.hadoop.mapred.JVMId.readFields(DataInput)
Update org.apache.hadoop.mapred.JVMId.write(DataOutput) org.apache.hadoop.mapred.JVMId.write(DataOutput)
Update org.apache.hadoop.mapred.JVMId.forName(String) org.apache.hadoop.mapred.JVMId.forName(String)
Update org.apache.hadoop.mapred.JVMId.<clinit>() org.apache.hadoop.mapred.JVMId.<clinit>()
Update org.apache.hadoop.mapred.JvmTask org.apache.hadoop.mapred.JvmTask
Update org.apache.hadoop.mapred.KeyValueLineRecordReader org.apache.hadoop.mapred.KeyValueLineRecordReader
Update org.apache.hadoop.mapred.KeyValueTextInputFormat org.apache.hadoop.mapred.KeyValueTextInputFormat
Update org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum
Update org.apache.hadoop.mapred.lib.aggregate.LongValueMax org.apache.hadoop.mapred.lib.aggregate.LongValueMax
Update org.apache.hadoop.mapred.lib.aggregate.LongValueMin org.apache.hadoop.mapred.lib.aggregate.LongValueMin
Update org.apache.hadoop.mapred.lib.aggregate.LongValueSum org.apache.hadoop.mapred.lib.aggregate.LongValueSum
Update org.apache.hadoop.mapred.lib.aggregate.StringValueMax org.apache.hadoop.mapred.lib.aggregate.StringValueMax
Update org.apache.hadoop.mapred.lib.aggregate.StringValueMin org.apache.hadoop.mapred.lib.aggregate.StringValueMin
Update org.apache.hadoop.mapred.lib.aggregate.UniqValueCount org.apache.hadoop.mapred.lib.aggregate.UniqValueCount
Update org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregator org.apache.hadoop.mapred.lib.aggregate.ValueAggregator
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.<init>() org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.<init>()
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.generateEntry(String,String,Text) org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.generateEntry(String,String,Text)
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.generateValueAggregator(String) org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.generateValueAggregator(String)
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.configure(JobConf) org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.configure(JobConf)
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.<clinit>() org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.<clinit>()
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper
Update org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer
Update org.apache.hadoop.mapred.lib.aggregate.ValueHistogram org.apache.hadoop.mapred.lib.aggregate.ValueHistogram
Update org.apache.hadoop.mapred.lib.BinaryPartitioner org.apache.hadoop.mapred.lib.BinaryPartitioner
Update org.apache.hadoop.mapred.lib.Chain.1 org.apache.hadoop.mapred.lib.Chain.1
Update org.apache.hadoop.mapred.lib.Chain.ChainOutputCollector org.apache.hadoop.mapred.lib.Chain.ChainOutputCollector
Update org.apache.hadoop.mapred.lib.Chain org.apache.hadoop.mapred.lib.Chain
Update org.apache.hadoop.mapred.lib.ChainMapper org.apache.hadoop.mapred.lib.ChainMapper
Update org.apache.hadoop.mapred.lib.ChainReducer org.apache.hadoop.mapred.lib.ChainReducer
Update org.apache.hadoop.mapred.lib.CombineFileInputFormat org.apache.hadoop.mapred.lib.CombineFileInputFormat
Update org.apache.hadoop.mapred.lib.CombineFileRecordReader org.apache.hadoop.mapred.lib.CombineFileRecordReader
Update org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper
Update org.apache.hadoop.mapred.lib.CombineFileSplit org.apache.hadoop.mapred.lib.CombineFileSplit
Update org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat.SequenceFileRecordReaderWrapper org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat.SequenceFileRecordReaderWrapper
Update org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat
Update org.apache.hadoop.mapred.lib.CombineTextInputFormat.TextRecordReaderWrapper org.apache.hadoop.mapred.lib.CombineTextInputFormat.TextRecordReaderWrapper
Update org.apache.hadoop.mapred.lib.CombineTextInputFormat org.apache.hadoop.mapred.lib.CombineTextInputFormat
Update org.apache.hadoop.mapred.lib.db.DBConfiguration org.apache.hadoop.mapred.lib.db.DBConfiguration
Update org.apache.hadoop.mapred.lib.db.DBConfiguration.configureDB(JobConf,String,String,String,String) org.apache.hadoop.mapred.lib.db.DBConfiguration.configureDB(JobConf,String,String,String,String)
Update org.apache.hadoop.mapred.lib.db.DBConfiguration.configureDB(JobConf,String,String) org.apache.hadoop.mapred.lib.db.DBConfiguration.configureDB(JobConf,String,String)
Update org.apache.hadoop.mapred.lib.db.DBConfiguration.<init>(JobConf) org.apache.hadoop.mapred.lib.db.DBConfiguration.<init>(JobConf)
Update org.apache.hadoop.mapred.lib.db.DBInputFormat.DBInputSplit org.apache.hadoop.mapred.lib.db.DBInputFormat.DBInputSplit
Update org.apache.hadoop.mapred.lib.db.DBInputFormat.DBRecordReader org.apache.hadoop.mapred.lib.db.DBInputFormat.DBRecordReader
Update org.apache.hadoop.mapred.lib.db.DBInputFormat.DBRecordReaderWrapper org.apache.hadoop.mapred.lib.db.DBInputFormat.DBRecordReaderWrapper
Update org.apache.hadoop.mapred.lib.db.DBInputFormat.NullDBWritable org.apache.hadoop.mapred.lib.db.DBInputFormat.NullDBWritable
Update org.apache.hadoop.mapred.lib.db.DBInputFormat org.apache.hadoop.mapred.lib.db.DBInputFormat
Update org.apache.hadoop.mapred.lib.db.DBOutputFormat.DBRecordWriter org.apache.hadoop.mapred.lib.db.DBOutputFormat.DBRecordWriter
Update org.apache.hadoop.mapred.lib.db.DBOutputFormat org.apache.hadoop.mapred.lib.db.DBOutputFormat
Update org.apache.hadoop.mapred.lib.db.DBWritable org.apache.hadoop.mapred.lib.db.DBWritable
Update org.apache.hadoop.mapred.lib.DelegatingInputFormat org.apache.hadoop.mapred.lib.DelegatingInputFormat
Update org.apache.hadoop.mapred.lib.DelegatingMapper org.apache.hadoop.mapred.lib.DelegatingMapper
Update org.apache.hadoop.mapred.lib.FieldSelectionMapReduce org.apache.hadoop.mapred.lib.FieldSelectionMapReduce
Delete org.apache.hadoop.mapred.lib.FieldSelectionMapReduce.LOG : Log org.apache.hadoop.mapred.lib.FieldSelectionMapReduce
Update org.apache.hadoop.mapred.lib.FilterOutputFormat.FilterRecordWriter org.apache.hadoop.mapred.lib.FilterOutputFormat.FilterRecordWriter
Update org.apache.hadoop.mapred.lib.FilterOutputFormat org.apache.hadoop.mapred.lib.FilterOutputFormat
Update org.apache.hadoop.mapred.lib.HashPartitioner org.apache.hadoop.mapred.lib.HashPartitioner
Update org.apache.hadoop.mapred.lib.IdentityMapper org.apache.hadoop.mapred.lib.IdentityMapper
Update org.apache.hadoop.mapred.lib.IdentityReducer org.apache.hadoop.mapred.lib.IdentityReducer
Update org.apache.hadoop.mapred.lib.InputSampler.IntervalSampler org.apache.hadoop.mapred.lib.InputSampler.IntervalSampler
Update org.apache.hadoop.mapred.lib.InputSampler.RandomSampler org.apache.hadoop.mapred.lib.InputSampler.RandomSampler
Update org.apache.hadoop.mapred.lib.InputSampler.Sampler org.apache.hadoop.mapred.lib.InputSampler.Sampler
Update org.apache.hadoop.mapred.lib.InputSampler.SplitSampler org.apache.hadoop.mapred.lib.InputSampler.SplitSampler
Update org.apache.hadoop.mapred.lib.InputSampler org.apache.hadoop.mapred.lib.InputSampler
Delete org.apache.hadoop.mapred.lib.InputSampler.access$000() org.apache.hadoop.mapred.lib.InputSampler
Delete org.apache.hadoop.mapred.lib.InputSampler.LOG : Log org.apache.hadoop.mapred.lib.InputSampler
Update org.apache.hadoop.mapred.lib.InverseMapper org.apache.hadoop.mapred.lib.InverseMapper
Update org.apache.hadoop.mapred.lib.KeyFieldBasedComparator org.apache.hadoop.mapred.lib.KeyFieldBasedComparator
Update org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner
Update org.apache.hadoop.mapred.lib.LazyOutputFormat.LazyRecordWriter org.apache.hadoop.mapred.lib.LazyOutputFormat.LazyRecordWriter
Update org.apache.hadoop.mapred.lib.LazyOutputFormat org.apache.hadoop.mapred.lib.LazyOutputFormat
Update org.apache.hadoop.mapred.lib.LongSumReducer org.apache.hadoop.mapred.lib.LongSumReducer
Update org.apache.hadoop.mapred.lib.MultipleInputs org.apache.hadoop.mapred.lib.MultipleInputs
Update org.apache.hadoop.mapred.lib.MultipleOutputFormat.1 org.apache.hadoop.mapred.lib.MultipleOutputFormat.1
Update org.apache.hadoop.mapred.lib.MultipleOutputFormat org.apache.hadoop.mapred.lib.MultipleOutputFormat
Update org.apache.hadoop.mapred.lib.MultipleOutputs.1 org.apache.hadoop.mapred.lib.MultipleOutputs.1
Update org.apache.hadoop.mapred.lib.MultipleOutputs.InternalFileOutputFormat org.apache.hadoop.mapred.lib.MultipleOutputs.InternalFileOutputFormat
Update org.apache.hadoop.mapred.lib.MultipleOutputs.RecordWriterWithCounter org.apache.hadoop.mapred.lib.MultipleOutputs.RecordWriterWithCounter
Update org.apache.hadoop.mapred.lib.MultipleOutputs org.apache.hadoop.mapred.lib.MultipleOutputs
Update org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat
Update org.apache.hadoop.mapred.lib.MultipleTextOutputFormat org.apache.hadoop.mapred.lib.MultipleTextOutputFormat
Update org.apache.hadoop.mapred.lib.MultithreadedMapRunner.BlockingArrayQueue org.apache.hadoop.mapred.lib.MultithreadedMapRunner.BlockingArrayQueue
Update org.apache.hadoop.mapred.lib.MultithreadedMapRunner.MapperInvokeRunable org.apache.hadoop.mapred.lib.MultithreadedMapRunner.MapperInvokeRunable
Update org.apache.hadoop.mapred.lib.MultithreadedMapRunner org.apache.hadoop.mapred.lib.MultithreadedMapRunner
Delete org.apache.hadoop.mapred.lib.MultithreadedMapRunner.LOG : Log org.apache.hadoop.mapred.lib.MultithreadedMapRunner
Update org.apache.hadoop.mapred.lib.NLineInputFormat org.apache.hadoop.mapred.lib.NLineInputFormat
Update org.apache.hadoop.mapred.lib.NullOutputFormat.1 org.apache.hadoop.mapred.lib.NullOutputFormat.1
Update org.apache.hadoop.mapred.lib.NullOutputFormat org.apache.hadoop.mapred.lib.NullOutputFormat
Update org.apache.hadoop.mapred.lib.RegexMapper org.apache.hadoop.mapred.lib.RegexMapper
Update org.apache.hadoop.mapred.lib.TaggedInputSplit org.apache.hadoop.mapred.lib.TaggedInputSplit
Update org.apache.hadoop.mapred.lib.TokenCountMapper org.apache.hadoop.mapred.lib.TokenCountMapper
Update org.apache.hadoop.mapred.lib.TotalOrderPartitioner org.apache.hadoop.mapred.lib.TotalOrderPartitioner
Update org.apache.hadoop.mapred.LineRecordReader.LineReader org.apache.hadoop.mapred.LineRecordReader.LineReader
Update org.apache.hadoop.mapred.LineRecordReader org.apache.hadoop.mapred.LineRecordReader
Update org.apache.hadoop.mapred.LineRecordReader.<init>(Configuration,FileSplit,byte[]) org.apache.hadoop.mapred.LineRecordReader.<init>(Configuration,FileSplit,byte[])
Update org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,int) org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,int)
Update org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,int,byte[]) org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,int,byte[])
Update org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,Configuration) org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,Configuration)
Update org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,Configuration,byte[]) org.apache.hadoop.mapred.LineRecordReader.<init>(InputStream,long,long,Configuration,byte[])
Update org.apache.hadoop.mapred.LineRecordReader.createKey() org.apache.hadoop.mapred.LineRecordReader.createKey()
Update org.apache.hadoop.mapred.LineRecordReader.createValue() org.apache.hadoop.mapred.LineRecordReader.createValue()
Update org.apache.hadoop.mapred.LineRecordReader.maxBytesToConsume(long) org.apache.hadoop.mapred.LineRecordReader.maxBytesToConsume(long)
Update org.apache.hadoop.mapred.LineRecordReader.getFilePosition() org.apache.hadoop.mapred.LineRecordReader.getFilePosition()
Update org.apache.hadoop.mapred.LineRecordReader.skipUtfByteOrderMark(Text) org.apache.hadoop.mapred.LineRecordReader.skipUtfByteOrderMark(Text)
Update org.apache.hadoop.mapred.LineRecordReader.next(LongWritable,Text) org.apache.hadoop.mapred.LineRecordReader.next(LongWritable,Text)
Update org.apache.hadoop.mapred.LineRecordReader.getProgress() org.apache.hadoop.mapred.LineRecordReader.getProgress()
Update org.apache.hadoop.mapred.LineRecordReader.getPos() org.apache.hadoop.mapred.LineRecordReader.getPos()
Update org.apache.hadoop.mapred.LineRecordReader.close() org.apache.hadoop.mapred.LineRecordReader.close()
Update org.apache.hadoop.mapred.LineRecordReader.createValue() org.apache.hadoop.mapred.LineRecordReader.createValue()
Update org.apache.hadoop.mapred.LineRecordReader.createKey() org.apache.hadoop.mapred.LineRecordReader.createKey()
Update org.apache.hadoop.mapred.LineRecordReader.next(Object,Object) org.apache.hadoop.mapred.LineRecordReader.next(Object,Object)
Update org.apache.hadoop.mapred.LineRecordReader.<clinit>() org.apache.hadoop.mapred.LineRecordReader.<clinit>()
Delete org.apache.hadoop.mapred.LineRecordReader.LOG : Log org.apache.hadoop.mapred.LineRecordReader
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.1 org.apache.hadoop.mapred.LocatedFileStatusFetcher.1
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallable.Result org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallable.Result
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallable org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallable
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallback org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInitialInputPathCallback
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallable.Result org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallable.Result
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallable org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallable
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallback org.apache.hadoop.mapred.LocatedFileStatusFetcher.ProcessInputDirCallback
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher org.apache.hadoop.mapred.LocatedFileStatusFetcher
Update org.apache.hadoop.mapred.LocatedFileStatusFetcher.registerError(Throwable) org.apache.hadoop.mapred.LocatedFileStatusFetcher.registerError(Throwable)
Update org.apache.hadoop.mapred.MapFileOutputFormat.1 org.apache.hadoop.mapred.MapFileOutputFormat.1
Update org.apache.hadoop.mapred.MapFileOutputFormat org.apache.hadoop.mapred.MapFileOutputFormat
Update org.apache.hadoop.mapred.MapFileOutputFormat.getEntry(MapFile$Reader[],Partitioner,WritableComparable,Writable) org.apache.hadoop.mapred.MapFileOutputFormat.getEntry(MapFile$Reader[],Partitioner,WritableComparable,Writable)
Update org.apache.hadoop.mapred.MapOutputCollector.Context org.apache.hadoop.mapred.MapOutputCollector.Context
Update org.apache.hadoop.mapred.MapOutputCollector org.apache.hadoop.mapred.MapOutputCollector
Update org.apache.hadoop.mapred.MapOutputFile org.apache.hadoop.mapred.MapOutputFile
Update org.apache.hadoop.mapred.Mapper org.apache.hadoop.mapred.Mapper
Update org.apache.hadoop.mapred.MapReduceBase org.apache.hadoop.mapred.MapReduceBase
Update org.apache.hadoop.mapred.MapRunnable org.apache.hadoop.mapred.MapRunnable
Update org.apache.hadoop.mapred.MapRunner org.apache.hadoop.mapred.MapRunner
Update org.apache.hadoop.mapred.MapTask.DirectMapOutputCollector org.apache.hadoop.mapred.MapTask.DirectMapOutputCollector
Update org.apache.hadoop.mapred.MapTask.MapBufferTooSmallException org.apache.hadoop.mapred.MapTask.MapBufferTooSmallException
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.BlockingBuffer org.apache.hadoop.mapred.MapTask.MapOutputBuffer.BlockingBuffer
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.Buffer org.apache.hadoop.mapred.MapTask.MapOutputBuffer.Buffer
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.InMemValBytes org.apache.hadoop.mapred.MapTask.MapOutputBuffer.InMemValBytes
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.MRResultIterator org.apache.hadoop.mapred.MapTask.MapOutputBuffer.MRResultIterator
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.SpillThread org.apache.hadoop.mapred.MapTask.MapOutputBuffer.SpillThread
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer org.apache.hadoop.mapred.MapTask.MapOutputBuffer
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.<init>() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.<init>()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.init(MapOutputCollector$Context) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.init(MapOutputCollector$Context)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.collect(Object,Object,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.collect(Object,Object,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.getTaskID() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.getTaskID()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.setEquator(int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.setEquator(int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.resetSpill() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.resetSpill()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.distanceTo(int,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.distanceTo(int,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.compare(int,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.compare(int,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.swap(int,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.swap(int,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.flush() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.flush()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.checkSpillException() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.checkSpillException()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.startSpill() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.startSpill()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.sortAndSpill() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.sortAndSpill()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.spillSingleRecord(Object,Object,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.spillSingleRecord(Object,Object,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.getVBytesForOffset(int,MapTask$MapOutputBuffer$InMemValBytes) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.getVBytesForOffset(int,MapTask$MapOutputBuffer$InMemValBytes)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.mergeParts() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.mergeParts()
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.sameVolRename(Path,Path) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.sameVolRename(Path,Path)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$300(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$300(MapTask$MapOutputBuffer)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$400(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$400(MapTask$MapOutputBuffer)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$500(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$500(MapTask$MapOutputBuffer)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$600(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$600(MapTask$MapOutputBuffer)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$700(MapTask$MapOutputBuffer,int) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$700(MapTask$MapOutputBuffer,int)
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$800(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$800(MapTask$MapOutputBuffer)
Delete org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$900(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer
Delete org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$1000(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer
Delete org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$1100(MapTask$MapOutputBuffer) org.apache.hadoop.mapred.MapTask.MapOutputBuffer
Delete org.apache.hadoop.mapred.MapTask.MapOutputBuffer.access$1200(MapTask$MapOutputBuffer,int,MapTask$MapOutputBuffer$InMemValBytes) org.apache.hadoop.mapred.MapTask.MapOutputBuffer
Update org.apache.hadoop.mapred.MapTask.MapOutputBuffer.<clinit>() org.apache.hadoop.mapred.MapTask.MapOutputBuffer.<clinit>()
Update org.apache.hadoop.mapred.MapTask.NewDirectOutputCollector org.apache.hadoop.mapred.MapTask.NewDirectOutputCollector
Update org.apache.hadoop.mapred.MapTask.NewOutputCollector.1 org.apache.hadoop.mapred.MapTask.NewOutputCollector.1
Update org.apache.hadoop.mapred.MapTask.NewOutputCollector org.apache.hadoop.mapred.MapTask.NewOutputCollector
Update org.apache.hadoop.mapred.MapTask.NewTrackingRecordReader org.apache.hadoop.mapred.MapTask.NewTrackingRecordReader
Update org.apache.hadoop.mapred.MapTask.OldOutputCollector.1 org.apache.hadoop.mapred.MapTask.OldOutputCollector.1
Update org.apache.hadoop.mapred.MapTask.OldOutputCollector org.apache.hadoop.mapred.MapTask.OldOutputCollector
Update org.apache.hadoop.mapred.MapTask.SkippingRecordReader org.apache.hadoop.mapred.MapTask.SkippingRecordReader
Update org.apache.hadoop.mapred.MapTask.TrackedRecordReader org.apache.hadoop.mapred.MapTask.TrackedRecordReader
Update org.apache.hadoop.mapred.MapTask org.apache.hadoop.mapred.MapTask
Update org.apache.hadoop.mapred.MapTask.<init>() org.apache.hadoop.mapred.MapTask.<init>()
Update org.apache.hadoop.mapred.MapTask.<init>(String,TaskAttemptID,int,JobSplit$TaskSplitIndex,int) org.apache.hadoop.mapred.MapTask.<init>(String,TaskAttemptID,int,JobSplit$TaskSplitIndex,int)
Update org.apache.hadoop.mapred.MapTask.localizeConfiguration(JobConf) org.apache.hadoop.mapred.MapTask.localizeConfiguration(JobConf)
Update org.apache.hadoop.mapred.MapTask.write(DataOutput) org.apache.hadoop.mapred.MapTask.write(DataOutput)
Update org.apache.hadoop.mapred.MapTask.readFields(DataInput) org.apache.hadoop.mapred.MapTask.readFields(DataInput)
Update org.apache.hadoop.mapred.MapTask.run(JobConf,TaskUmbilicalProtocol) org.apache.hadoop.mapred.MapTask.run(JobConf,TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.MapTask.getSortPhase() org.apache.hadoop.mapred.MapTask.getSortPhase()
Update org.apache.hadoop.mapred.MapTask.getSplitDetails(Path,long) org.apache.hadoop.mapred.MapTask.getSplitDetails(Path,long)
Update org.apache.hadoop.mapred.MapTask.createSortingCollector(JobConf,Task$TaskReporter) org.apache.hadoop.mapred.MapTask.createSortingCollector(JobConf,Task$TaskReporter)
Update org.apache.hadoop.mapred.MapTask.runOldMapper(JobConf,JobSplit$TaskSplitIndex,TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.MapTask.runOldMapper(JobConf,JobSplit$TaskSplitIndex,TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.MapTask.updateJobWithSplit(JobConf,InputSplit) org.apache.hadoop.mapred.MapTask.updateJobWithSplit(JobConf,InputSplit)
Update org.apache.hadoop.mapred.MapTask.runNewMapper(JobConf,JobSplit$TaskSplitIndex,TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.MapTask.runNewMapper(JobConf,JobSplit$TaskSplitIndex,TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.MapTask.closeQuietly(RecordReader) org.apache.hadoop.mapred.MapTask.closeQuietly(RecordReader)
Update org.apache.hadoop.mapred.MapTask.closeQuietly(MapOutputCollector) org.apache.hadoop.mapred.MapTask.closeQuietly(MapOutputCollector)
Update org.apache.hadoop.mapred.MapTask.closeQuietly(RecordReader) org.apache.hadoop.mapred.MapTask.closeQuietly(RecordReader)
Update org.apache.hadoop.mapred.MapTask.closeQuietly(RecordWriter,Mapper$Context) org.apache.hadoop.mapred.MapTask.closeQuietly(RecordWriter,Mapper$Context)
Delete org.apache.hadoop.mapred.MapTask.access$000() org.apache.hadoop.mapred.MapTask
Update org.apache.hadoop.mapred.MapTask.access$100(MapTask,JobConf,Task$TaskReporter) org.apache.hadoop.mapred.MapTask.access$100(MapTask,JobConf,Task$TaskReporter)
Update org.apache.hadoop.mapred.MapTask.<clinit>() org.apache.hadoop.mapred.MapTask.<clinit>()
Delete org.apache.hadoop.mapred.MapTask.LOG : Log org.apache.hadoop.mapred.MapTask
Update org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate
Update org.apache.hadoop.mapred.MapTaskStatus org.apache.hadoop.mapred.MapTaskStatus
Update org.apache.hadoop.mapred.Master.State org.apache.hadoop.mapred.Master.State
Update org.apache.hadoop.mapred.Master org.apache.hadoop.mapred.Master
Delete org.apache.hadoop.mapred.Master.getMasterUserName(Configuration) org.apache.hadoop.mapred.Master
Delete org.apache.hadoop.mapred.Master.getMasterAddress(Configuration) org.apache.hadoop.mapred.Master
Update org.apache.hadoop.mapred.Master.getMasterPrincipal(Configuration) org.apache.hadoop.mapred.Master.getMasterPrincipal(Configuration)
Update org.apache.hadoop.mapred.Merger.MergeQueue.1 org.apache.hadoop.mapred.Merger.MergeQueue.1
Update org.apache.hadoop.mapred.Merger.MergeQueue org.apache.hadoop.mapred.Merger.MergeQueue
Update org.apache.hadoop.mapred.Merger.MergeQueue.adjustPriorityQueue(Merger$Segment) org.apache.hadoop.mapred.Merger.MergeQueue.adjustPriorityQueue(Merger$Segment)
Update org.apache.hadoop.mapred.Merger.MergeQueue.resetKeyValue() org.apache.hadoop.mapred.Merger.MergeQueue.resetKeyValue()
Update org.apache.hadoop.mapred.Merger.MergeQueue.next() org.apache.hadoop.mapred.Merger.MergeQueue.next()
Update org.apache.hadoop.mapred.Merger.MergeQueue.lessThan(Object,Object) org.apache.hadoop.mapred.Merger.MergeQueue.lessThan(Object,Object)
Update org.apache.hadoop.mapred.Merger.MergeQueue.merge(Class,Class,int,Path,Counters$Counter,Counters$Counter,Progress) org.apache.hadoop.mapred.Merger.MergeQueue.merge(Class,Class,int,Path,Counters$Counter,Counters$Counter,Progress)
Update org.apache.hadoop.mapred.Merger.MergeQueue.merge(Class,Class,int,int,Path,Counters$Counter,Counters$Counter,Progress) org.apache.hadoop.mapred.Merger.MergeQueue.merge(Class,Class,int,int,Path,Counters$Counter,Counters$Counter,Progress)
Update org.apache.hadoop.mapred.Merger.MergeQueue.getSegmentDescriptors(int) org.apache.hadoop.mapred.Merger.MergeQueue.getSegmentDescriptors(int)
Update org.apache.hadoop.mapred.Merger.MergeQueue.computeBytesInMerges(int,int) org.apache.hadoop.mapred.Merger.MergeQueue.computeBytesInMerges(int,int)
Update org.apache.hadoop.mapred.Merger.Segment org.apache.hadoop.mapred.Merger.Segment
Update org.apache.hadoop.mapred.Merger org.apache.hadoop.mapred.Merger
Delete org.apache.hadoop.mapred.Merger.access$000() org.apache.hadoop.mapred.Merger
Delete org.apache.hadoop.mapred.Merger.LOG : Log org.apache.hadoop.mapred.Merger
Update org.apache.hadoop.mapred.MergeSorter org.apache.hadoop.mapred.MergeSorter
Update org.apache.hadoop.mapred.MRConstants org.apache.hadoop.mapred.MRConstants
Update org.apache.hadoop.mapred.MROutputFiles org.apache.hadoop.mapred.MROutputFiles
Update org.apache.hadoop.mapred.MRSortResultIterator.1 org.apache.hadoop.mapred.MRSortResultIterator.1
Update org.apache.hadoop.mapred.MRSortResultIterator.InMemUncompressedBytes org.apache.hadoop.mapred.MRSortResultIterator.InMemUncompressedBytes
Update org.apache.hadoop.mapred.MRSortResultIterator org.apache.hadoop.mapred.MRSortResultIterator
Update org.apache.hadoop.mapred.MultiFileInputFormat org.apache.hadoop.mapred.MultiFileInputFormat
Update org.apache.hadoop.mapred.MultiFileSplit org.apache.hadoop.mapred.MultiFileSplit
Update org.apache.hadoop.mapred.Operation org.apache.hadoop.mapred.Operation
Update org.apache.hadoop.mapred.OutputCollector org.apache.hadoop.mapred.OutputCollector
Update org.apache.hadoop.mapred.OutputCommitter org.apache.hadoop.mapred.OutputCommitter
Update org.apache.hadoop.mapred.OutputCommitter.setupJob(JobContext) org.apache.hadoop.mapred.OutputCommitter.setupJob(JobContext)
Update org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext) org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)
Update org.apache.hadoop.mapred.OutputCommitter.abortJob(JobContext,JobStatus$State) org.apache.hadoop.mapred.OutputCommitter.abortJob(JobContext,JobStatus$State)
Update org.apache.hadoop.mapred.OutputCommitter.setupTask(TaskAttemptContext) org.apache.hadoop.mapred.OutputCommitter.setupTask(TaskAttemptContext)
Update org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(TaskAttemptContext) org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(TaskAttemptContext)
Update org.apache.hadoop.mapred.OutputCommitter.commitTask(TaskAttemptContext) org.apache.hadoop.mapred.OutputCommitter.commitTask(TaskAttemptContext)
Update org.apache.hadoop.mapred.OutputCommitter.abortTask(TaskAttemptContext) org.apache.hadoop.mapred.OutputCommitter.abortTask(TaskAttemptContext)
Update org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext) org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)
Update org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext) org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)
Update org.apache.hadoop.mapred.OutputFormat org.apache.hadoop.mapred.OutputFormat
Update org.apache.hadoop.mapred.OutputLogFilter org.apache.hadoop.mapred.OutputLogFilter
Update org.apache.hadoop.mapred.Partitioner org.apache.hadoop.mapred.Partitioner
Update org.apache.hadoop.mapred.PeriodicStatsAccumulator.StatsetState org.apache.hadoop.mapred.PeriodicStatsAccumulator.StatsetState
Update org.apache.hadoop.mapred.PeriodicStatsAccumulator org.apache.hadoop.mapred.PeriodicStatsAccumulator
Update org.apache.hadoop.mapred.pipes.Application org.apache.hadoop.mapred.pipes.Application
Delete org.apache.hadoop.mapred.pipes.Application.LOG : Log org.apache.hadoop.mapred.pipes.Application
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.MessageType org.apache.hadoop.mapred.pipes.BinaryProtocol.MessageType
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.TeeOutputStream org.apache.hadoop.mapred.pipes.BinaryProtocol.TeeOutputStream
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.TeeOutputStream.close() org.apache.hadoop.mapred.pipes.BinaryProtocol.TeeOutputStream.close()
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread.run() org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread.run()
Update org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread.readObject(Writable) org.apache.hadoop.mapred.pipes.BinaryProtocol.UplinkReaderThread.readObject(Writable)
Update org.apache.hadoop.mapred.pipes.BinaryProtocol org.apache.hadoop.mapred.pipes.BinaryProtocol
Delete org.apache.hadoop.mapred.pipes.BinaryProtocol.access$000() org.apache.hadoop.mapred.pipes.BinaryProtocol
Delete org.apache.hadoop.mapred.pipes.BinaryProtocol.LOG : Log org.apache.hadoop.mapred.pipes.BinaryProtocol
Update org.apache.hadoop.mapred.pipes.DownwardProtocol org.apache.hadoop.mapred.pipes.DownwardProtocol
Update org.apache.hadoop.mapred.pipes.OutputHandler org.apache.hadoop.mapred.pipes.OutputHandler
Update org.apache.hadoop.mapred.pipes.PipesMapRunner org.apache.hadoop.mapred.pipes.PipesMapRunner
Update org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat.PipesDummyRecordReader org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat.PipesDummyRecordReader
Update org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat
Update org.apache.hadoop.mapred.pipes.PipesPartitioner org.apache.hadoop.mapred.pipes.PipesPartitioner
Delete org.apache.hadoop.mapred.pipes.PipesPartitioner.cache : ThreadLocal org.apache.hadoop.mapred.pipes.PipesPartitioner
Update org.apache.hadoop.mapred.pipes.PipesReducer.1 org.apache.hadoop.mapred.pipes.PipesReducer.1
Update org.apache.hadoop.mapred.pipes.PipesReducer org.apache.hadoop.mapred.pipes.PipesReducer
Delete org.apache.hadoop.mapred.pipes.PipesReducer.LOG : Log org.apache.hadoop.mapred.pipes.PipesReducer
Update org.apache.hadoop.mapred.pipes.Submitter.1 org.apache.hadoop.mapred.pipes.Submitter.1
Update org.apache.hadoop.mapred.pipes.Submitter.CommandLineParser org.apache.hadoop.mapred.pipes.Submitter.CommandLineParser
Update org.apache.hadoop.mapred.pipes.Submitter org.apache.hadoop.mapred.pipes.Submitter
Delete org.apache.hadoop.mapred.pipes.Submitter.LOG : Log org.apache.hadoop.mapred.pipes.Submitter
Update org.apache.hadoop.mapred.pipes.UpwardProtocol org.apache.hadoop.mapred.pipes.UpwardProtocol
Update org.apache.hadoop.mapred.ProgressSplitsBlock org.apache.hadoop.mapred.ProgressSplitsBlock
Update org.apache.hadoop.mapred.Queue org.apache.hadoop.mapred.Queue
Delete org.apache.hadoop.mapred.Queue.LOG : Log org.apache.hadoop.mapred.Queue
Update org.apache.hadoop.mapred.QueueACL org.apache.hadoop.mapred.QueueACL
Update org.apache.hadoop.mapred.QueueAclsInfo org.apache.hadoop.mapred.QueueAclsInfo
Update org.apache.hadoop.mapred.QueueConfigurationParser org.apache.hadoop.mapred.QueueConfigurationParser
Delete org.apache.hadoop.mapred.QueueConfigurationParser.LOG : Log org.apache.hadoop.mapred.QueueConfigurationParser
Update org.apache.hadoop.mapred.QueueManager org.apache.hadoop.mapred.QueueManager
Delete org.apache.hadoop.mapred.QueueManager.dumpConfiguration(JsonGenerator,Set) org.apache.hadoop.mapred.QueueManager
Delete org.apache.hadoop.mapred.QueueManager.LOG : Log org.apache.hadoop.mapred.QueueManager
Update org.apache.hadoop.mapred.QueueRefresher org.apache.hadoop.mapred.QueueRefresher
Update org.apache.hadoop.mapred.RamManager org.apache.hadoop.mapred.RamManager
Update org.apache.hadoop.mapred.RawKeyValueIterator org.apache.hadoop.mapred.RawKeyValueIterator
Update org.apache.hadoop.mapred.RecordReader org.apache.hadoop.mapred.RecordReader
Update org.apache.hadoop.mapred.RecordWriter org.apache.hadoop.mapred.RecordWriter
Update org.apache.hadoop.mapred.Reducer org.apache.hadoop.mapred.Reducer
Update org.apache.hadoop.mapred.ReduceTask.1 org.apache.hadoop.mapred.ReduceTask.1
Update org.apache.hadoop.mapred.ReduceTask.2 org.apache.hadoop.mapred.ReduceTask.2
Update org.apache.hadoop.mapred.ReduceTask.3 org.apache.hadoop.mapred.ReduceTask.3
Update org.apache.hadoop.mapred.ReduceTask.4 org.apache.hadoop.mapred.ReduceTask.4
Update org.apache.hadoop.mapred.ReduceTask.NewTrackingRecordWriter org.apache.hadoop.mapred.ReduceTask.NewTrackingRecordWriter
Update org.apache.hadoop.mapred.ReduceTask.OldTrackingRecordWriter org.apache.hadoop.mapred.ReduceTask.OldTrackingRecordWriter
Update org.apache.hadoop.mapred.ReduceTask.ReduceValuesIterator org.apache.hadoop.mapred.ReduceTask.ReduceValuesIterator
Update org.apache.hadoop.mapred.ReduceTask.SkippingReduceValuesIterator org.apache.hadoop.mapred.ReduceTask.SkippingReduceValuesIterator
Update org.apache.hadoop.mapred.ReduceTask org.apache.hadoop.mapred.ReduceTask
Update org.apache.hadoop.mapred.ReduceTask.runOldReducer(JobConf,TaskUmbilicalProtocol,Task$TaskReporter,RawKeyValueIterator,RawComparator,Class,Class) org.apache.hadoop.mapred.ReduceTask.runOldReducer(JobConf,TaskUmbilicalProtocol,Task$TaskReporter,RawKeyValueIterator,RawComparator,Class,Class)
Delete org.apache.hadoop.mapred.ReduceTask.access$200() org.apache.hadoop.mapred.ReduceTask
Delete org.apache.hadoop.mapred.ReduceTask.LOG : Log org.apache.hadoop.mapred.ReduceTask
Update org.apache.hadoop.mapred.ReduceTaskStatus org.apache.hadoop.mapred.ReduceTaskStatus
Update org.apache.hadoop.mapred.Reporter.1 org.apache.hadoop.mapred.Reporter.1
Update org.apache.hadoop.mapred.Reporter org.apache.hadoop.mapred.Reporter
Update org.apache.hadoop.mapred.RunningJob org.apache.hadoop.mapred.RunningJob
Update org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat.SequenceFileAsBinaryRecordReader org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat.SequenceFileAsBinaryRecordReader
Update org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat
Update org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat.1 org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat.1
Update org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat.WritableValueBytes org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat.WritableValueBytes
Update org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat
Update org.apache.hadoop.mapred.SequenceFileAsTextInputFormat org.apache.hadoop.mapred.SequenceFileAsTextInputFormat
Update org.apache.hadoop.mapred.SequenceFileAsTextRecordReader org.apache.hadoop.mapred.SequenceFileAsTextRecordReader
Update org.apache.hadoop.mapred.SequenceFileInputFilter.Filter org.apache.hadoop.mapred.SequenceFileInputFilter.Filter
Update org.apache.hadoop.mapred.SequenceFileInputFilter.FilterBase org.apache.hadoop.mapred.SequenceFileInputFilter.FilterBase
Update org.apache.hadoop.mapred.SequenceFileInputFilter.FilterRecordReader org.apache.hadoop.mapred.SequenceFileInputFilter.FilterRecordReader
Update org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter
Update org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter.setFrequency(Configuration,int) org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter.setFrequency(Configuration,int)
Update org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter.<init>() org.apache.hadoop.mapred.SequenceFileInputFilter.MD5Filter.<init>()
Update org.apache.hadoop.mapred.SequenceFileInputFilter.PercentFilter org.apache.hadoop.mapred.SequenceFileInputFilter.PercentFilter
Update org.apache.hadoop.mapred.SequenceFileInputFilter.RegexFilter org.apache.hadoop.mapred.SequenceFileInputFilter.RegexFilter
Update org.apache.hadoop.mapred.SequenceFileInputFilter org.apache.hadoop.mapred.SequenceFileInputFilter
Update org.apache.hadoop.mapred.SequenceFileInputFilter.<init>() org.apache.hadoop.mapred.SequenceFileInputFilter.<init>()
Update org.apache.hadoop.mapred.SequenceFileInputFilter.getRecordReader(InputSplit,JobConf,Reporter) org.apache.hadoop.mapred.SequenceFileInputFilter.getRecordReader(InputSplit,JobConf,Reporter)
Update org.apache.hadoop.mapred.SequenceFileInputFilter.setFilterClass(Configuration,Class) org.apache.hadoop.mapred.SequenceFileInputFilter.setFilterClass(Configuration,Class)
Update org.apache.hadoop.mapred.SequenceFileInputFormat org.apache.hadoop.mapred.SequenceFileInputFormat
Update org.apache.hadoop.mapred.SequenceFileOutputFormat.1 org.apache.hadoop.mapred.SequenceFileOutputFormat.1
Update org.apache.hadoop.mapred.SequenceFileOutputFormat org.apache.hadoop.mapred.SequenceFileOutputFormat
Update org.apache.hadoop.mapred.SequenceFileRecordReader org.apache.hadoop.mapred.SequenceFileRecordReader
Update org.apache.hadoop.mapred.ShuffleConsumerPlugin.Context org.apache.hadoop.mapred.ShuffleConsumerPlugin.Context
Update org.apache.hadoop.mapred.ShuffleConsumerPlugin org.apache.hadoop.mapred.ShuffleConsumerPlugin
Update org.apache.hadoop.mapred.SkipBadRecords org.apache.hadoop.mapred.SkipBadRecords
Update org.apache.hadoop.mapred.SkipBadRecords.<init>() org.apache.hadoop.mapred.SkipBadRecords.<init>()
Update org.apache.hadoop.mapred.SkipBadRecords.getAttemptsToStartSkipping(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getAttemptsToStartSkipping(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setAttemptsToStartSkipping(Configuration,int) org.apache.hadoop.mapred.SkipBadRecords.setAttemptsToStartSkipping(Configuration,int)
Update org.apache.hadoop.mapred.SkipBadRecords.getAutoIncrMapperProcCount(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getAutoIncrMapperProcCount(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setAutoIncrMapperProcCount(Configuration,boolean) org.apache.hadoop.mapred.SkipBadRecords.setAutoIncrMapperProcCount(Configuration,boolean)
Update org.apache.hadoop.mapred.SkipBadRecords.getAutoIncrReducerProcCount(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getAutoIncrReducerProcCount(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setAutoIncrReducerProcCount(Configuration,boolean) org.apache.hadoop.mapred.SkipBadRecords.setAutoIncrReducerProcCount(Configuration,boolean)
Update org.apache.hadoop.mapred.SkipBadRecords.getSkipOutputPath(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getSkipOutputPath(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setSkipOutputPath(JobConf,Path) org.apache.hadoop.mapred.SkipBadRecords.setSkipOutputPath(JobConf,Path)
Update org.apache.hadoop.mapred.SkipBadRecords.getMapperMaxSkipRecords(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getMapperMaxSkipRecords(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setMapperMaxSkipRecords(Configuration,long) org.apache.hadoop.mapred.SkipBadRecords.setMapperMaxSkipRecords(Configuration,long)
Update org.apache.hadoop.mapred.SkipBadRecords.getReducerMaxSkipGroups(Configuration) org.apache.hadoop.mapred.SkipBadRecords.getReducerMaxSkipGroups(Configuration)
Update org.apache.hadoop.mapred.SkipBadRecords.setReducerMaxSkipGroups(Configuration,long) org.apache.hadoop.mapred.SkipBadRecords.setReducerMaxSkipGroups(Configuration,long)
Update org.apache.hadoop.mapred.SortedRanges.Range org.apache.hadoop.mapred.SortedRanges.Range
Update org.apache.hadoop.mapred.SortedRanges.SkipRangeIterator org.apache.hadoop.mapred.SortedRanges.SkipRangeIterator
Update org.apache.hadoop.mapred.SortedRanges org.apache.hadoop.mapred.SortedRanges
Delete org.apache.hadoop.mapred.SortedRanges.access$000() org.apache.hadoop.mapred.SortedRanges
Delete org.apache.hadoop.mapred.SortedRanges.LOG : Log org.apache.hadoop.mapred.SortedRanges
Update org.apache.hadoop.mapred.SpillRecord org.apache.hadoop.mapred.SpillRecord
Update org.apache.hadoop.mapred.SplitLocationInfo org.apache.hadoop.mapred.SplitLocationInfo
Update org.apache.hadoop.mapred.StatePeriodicStats org.apache.hadoop.mapred.StatePeriodicStats
Update org.apache.hadoop.mapred.StatisticsCollector.1 org.apache.hadoop.mapred.StatisticsCollector.1
Update org.apache.hadoop.mapred.StatisticsCollector.Stat.TimeStat org.apache.hadoop.mapred.StatisticsCollector.Stat.TimeStat
Update org.apache.hadoop.mapred.StatisticsCollector.Stat org.apache.hadoop.mapred.StatisticsCollector.Stat
Update org.apache.hadoop.mapred.StatisticsCollector.StatUpdater org.apache.hadoop.mapred.StatisticsCollector.StatUpdater
Update org.apache.hadoop.mapred.StatisticsCollector.TimeWindow org.apache.hadoop.mapred.StatisticsCollector.TimeWindow
Update org.apache.hadoop.mapred.StatisticsCollector.TimeWindowStatUpdater org.apache.hadoop.mapred.StatisticsCollector.TimeWindowStatUpdater
Update org.apache.hadoop.mapred.StatisticsCollector org.apache.hadoop.mapred.StatisticsCollector
Update org.apache.hadoop.mapred.Task.CombineOutputCollector org.apache.hadoop.mapred.Task.CombineOutputCollector
Update org.apache.hadoop.mapred.Task.CombinerRunner org.apache.hadoop.mapred.Task.CombinerRunner
Update org.apache.hadoop.mapred.Task.CombineValuesIterator org.apache.hadoop.mapred.Task.CombineValuesIterator
Update org.apache.hadoop.mapred.Task.Counter org.apache.hadoop.mapred.Task.Counter
Update org.apache.hadoop.mapred.Task.Counter.<clinit>() org.apache.hadoop.mapred.Task.Counter.<clinit>()
Update org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater
Update org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater.<init>(Task,List,String) org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater.<init>(Task,List,String)
Update org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater.updateCounters() org.apache.hadoop.mapred.Task.FileSystemStatisticUpdater.updateCounters()
Update org.apache.hadoop.mapred.Task.GcTimeUpdater org.apache.hadoop.mapred.Task.GcTimeUpdater
Update org.apache.hadoop.mapred.Task.NewCombinerRunner.OutputConverter org.apache.hadoop.mapred.Task.NewCombinerRunner.OutputConverter
Update org.apache.hadoop.mapred.Task.NewCombinerRunner org.apache.hadoop.mapred.Task.NewCombinerRunner
Update org.apache.hadoop.mapred.Task.OldCombinerRunner org.apache.hadoop.mapred.Task.OldCombinerRunner
Update org.apache.hadoop.mapred.Task.TaskReporter org.apache.hadoop.mapred.Task.TaskReporter
Update org.apache.hadoop.mapred.Task.TaskReporter.<init>(Task,Progress,TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.TaskReporter.<init>(Task,Progress,TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.TaskReporter.setProgressFlag() org.apache.hadoop.mapred.Task.TaskReporter.setProgressFlag()
Update org.apache.hadoop.mapred.Task.TaskReporter.resetProgressFlag() org.apache.hadoop.mapred.Task.TaskReporter.resetProgressFlag()
Update org.apache.hadoop.mapred.Task.TaskReporter.setStatus(String) org.apache.hadoop.mapred.Task.TaskReporter.setStatus(String)
Update org.apache.hadoop.mapred.Task.TaskReporter.setProgress(float) org.apache.hadoop.mapred.Task.TaskReporter.setProgress(float)
Update org.apache.hadoop.mapred.Task.TaskReporter.getProgress() org.apache.hadoop.mapred.Task.TaskReporter.getProgress()
Update org.apache.hadoop.mapred.Task.TaskReporter.progress() org.apache.hadoop.mapred.Task.TaskReporter.progress()
Update org.apache.hadoop.mapred.Task.TaskReporter.getCounter(String,String) org.apache.hadoop.mapred.Task.TaskReporter.getCounter(String,String)
Update org.apache.hadoop.mapred.Task.TaskReporter.getCounter(Enum) org.apache.hadoop.mapred.Task.TaskReporter.getCounter(Enum)
Update org.apache.hadoop.mapred.Task.TaskReporter.incrCounter(Enum,long) org.apache.hadoop.mapred.Task.TaskReporter.incrCounter(Enum,long)
Update org.apache.hadoop.mapred.Task.TaskReporter.incrCounter(String,String,long) org.apache.hadoop.mapred.Task.TaskReporter.incrCounter(String,String,long)
Update org.apache.hadoop.mapred.Task.TaskReporter.getInputSplit() org.apache.hadoop.mapred.Task.TaskReporter.getInputSplit()
Update org.apache.hadoop.mapred.Task.TaskReporter.run() org.apache.hadoop.mapred.Task.TaskReporter.run()
Update org.apache.hadoop.mapred.Task.TaskReporter.resetDoneFlag() org.apache.hadoop.mapred.Task.TaskReporter.resetDoneFlag()
Update org.apache.hadoop.mapred.Task.TaskReporter.startCommunicationThread() org.apache.hadoop.mapred.Task.TaskReporter.startCommunicationThread()
Update org.apache.hadoop.mapred.Task.TaskReporter.stopCommunicationThread() org.apache.hadoop.mapred.Task.TaskReporter.stopCommunicationThread()
Update org.apache.hadoop.mapred.Task.TaskReporter.getCounter(String,String) org.apache.hadoop.mapred.Task.TaskReporter.getCounter(String,String)
Update org.apache.hadoop.mapred.Task.TaskReporter.getCounter(Enum) org.apache.hadoop.mapred.Task.TaskReporter.getCounter(Enum)
Update org.apache.hadoop.mapred.Task.ValuesIterator org.apache.hadoop.mapred.Task.ValuesIterator
Update org.apache.hadoop.mapred.Task org.apache.hadoop.mapred.Task
Update org.apache.hadoop.mapred.Task.getFileSystemCounterNames(String) org.apache.hadoop.mapred.Task.getFileSystemCounterNames(String)
Update org.apache.hadoop.mapred.Task.getOutputName(int) org.apache.hadoop.mapred.Task.getOutputName(int)
Update org.apache.hadoop.mapred.Task.<init>() org.apache.hadoop.mapred.Task.<init>()
Update org.apache.hadoop.mapred.Task.<init>(String,TaskAttemptID,int,int) org.apache.hadoop.mapred.Task.<init>(String,TaskAttemptID,int,int)
Update org.apache.hadoop.mapred.Task.setJobFile(String) org.apache.hadoop.mapred.Task.setJobFile(String)
Update org.apache.hadoop.mapred.Task.getJobFile() org.apache.hadoop.mapred.Task.getJobFile()
Update org.apache.hadoop.mapred.Task.getNumSlotsRequired() org.apache.hadoop.mapred.Task.getNumSlotsRequired()
Update org.apache.hadoop.mapred.Task.getCounters() org.apache.hadoop.mapred.Task.getCounters()
Update org.apache.hadoop.mapred.Task.getJobID() org.apache.hadoop.mapred.Task.getJobID()
Update org.apache.hadoop.mapred.Task.setJobTokenSecret(SecretKey) org.apache.hadoop.mapred.Task.setJobTokenSecret(SecretKey)
Update org.apache.hadoop.mapred.Task.getJobTokenSecret() org.apache.hadoop.mapred.Task.getJobTokenSecret()
Update org.apache.hadoop.mapred.Task.setShuffleSecret(SecretKey) org.apache.hadoop.mapred.Task.setShuffleSecret(SecretKey)
Update org.apache.hadoop.mapred.Task.getShuffleSecret() org.apache.hadoop.mapred.Task.getShuffleSecret()
Update org.apache.hadoop.mapred.Task.getPartition() org.apache.hadoop.mapred.Task.getPartition()
Update org.apache.hadoop.mapred.Task.getPhase() org.apache.hadoop.mapred.Task.getPhase()
Update org.apache.hadoop.mapred.Task.setPhase(TaskStatus$Phase) org.apache.hadoop.mapred.Task.setPhase(TaskStatus$Phase)
Update org.apache.hadoop.mapred.Task.toWriteSkipRecs() org.apache.hadoop.mapred.Task.toWriteSkipRecs()
Update org.apache.hadoop.mapred.Task.setWriteSkipRecs(boolean) org.apache.hadoop.mapred.Task.setWriteSkipRecs(boolean)
Delete org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID,Throwable,String) org.apache.hadoop.mapred.Task
Update org.apache.hadoop.mapred.Task.getFsStatistics(Path,Configuration) org.apache.hadoop.mapred.Task.getFsStatistics(Path,Configuration)
Update org.apache.hadoop.mapred.Task.getSkipRanges() org.apache.hadoop.mapred.Task.getSkipRanges()
Update org.apache.hadoop.mapred.Task.setSkipRanges(SortedRanges) org.apache.hadoop.mapred.Task.setSkipRanges(SortedRanges)
Update org.apache.hadoop.mapred.Task.isSkipping() org.apache.hadoop.mapred.Task.isSkipping()
Update org.apache.hadoop.mapred.Task.setSkipping(boolean) org.apache.hadoop.mapred.Task.setSkipping(boolean)
Update org.apache.hadoop.mapred.Task.getState() org.apache.hadoop.mapred.Task.getState()
Update org.apache.hadoop.mapred.Task.setState(TaskStatus$State) org.apache.hadoop.mapred.Task.setState(TaskStatus$State)
Update org.apache.hadoop.mapred.Task.setTaskCleanupTask() org.apache.hadoop.mapred.Task.setTaskCleanupTask()
Update org.apache.hadoop.mapred.Task.isTaskCleanupTask() org.apache.hadoop.mapred.Task.isTaskCleanupTask()
Update org.apache.hadoop.mapred.Task.isJobCleanupTask() org.apache.hadoop.mapred.Task.isJobCleanupTask()
Update org.apache.hadoop.mapred.Task.isJobAbortTask() org.apache.hadoop.mapred.Task.isJobAbortTask()
Update org.apache.hadoop.mapred.Task.isJobSetupTask() org.apache.hadoop.mapred.Task.isJobSetupTask()
Update org.apache.hadoop.mapred.Task.setJobSetupTask() org.apache.hadoop.mapred.Task.setJobSetupTask()
Update org.apache.hadoop.mapred.Task.setJobCleanupTask() org.apache.hadoop.mapred.Task.setJobCleanupTask()
Update org.apache.hadoop.mapred.Task.setJobCleanupTaskState(JobStatus$State) org.apache.hadoop.mapred.Task.setJobCleanupTaskState(JobStatus$State)
Update org.apache.hadoop.mapred.Task.isMapOrReduce() org.apache.hadoop.mapred.Task.isMapOrReduce()
Update org.apache.hadoop.mapred.Task.getUser() org.apache.hadoop.mapred.Task.getUser()
Update org.apache.hadoop.mapred.Task.setUser(String) org.apache.hadoop.mapred.Task.setUser(String)
Update org.apache.hadoop.mapred.Task.write(DataOutput) org.apache.hadoop.mapred.Task.write(DataOutput)
Update org.apache.hadoop.mapred.Task.readFields(DataInput) org.apache.hadoop.mapred.Task.readFields(DataInput)
Update org.apache.hadoop.mapred.Task.toString() org.apache.hadoop.mapred.Task.toString()
Update org.apache.hadoop.mapred.Task.localizeConfiguration(JobConf) org.apache.hadoop.mapred.Task.localizeConfiguration(JobConf)
Update org.apache.hadoop.mapred.Task.getProgress() org.apache.hadoop.mapred.Task.getProgress()
Update org.apache.hadoop.mapred.Task.initialize(JobConf,JobID,Reporter,boolean) org.apache.hadoop.mapred.Task.initialize(JobConf,JobID,Reporter,boolean)
Update org.apache.hadoop.mapred.Task.normalizeStatus(String,Configuration) org.apache.hadoop.mapred.Task.normalizeStatus(String,Configuration)
Update org.apache.hadoop.mapred.Task.reportNextRecordRange(TaskUmbilicalProtocol,long) org.apache.hadoop.mapred.Task.reportNextRecordRange(TaskUmbilicalProtocol,long)
Update org.apache.hadoop.mapred.Task.startReporter(TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.startReporter(TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.updateResourceCounters() org.apache.hadoop.mapred.Task.updateResourceCounters()
Update org.apache.hadoop.mapred.Task.updateCounters() org.apache.hadoop.mapred.Task.updateCounters()
Update org.apache.hadoop.mapred.Task.updateHeapUsageCounter() org.apache.hadoop.mapred.Task.updateHeapUsageCounter()
Update org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.Task.isCommitRequired() org.apache.hadoop.mapred.Task.isCommitRequired()
Update org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.sendLastUpdate(TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.sendLastUpdate(TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.calculateOutputSize() org.apache.hadoop.mapred.Task.calculateOutputSize()
Update org.apache.hadoop.mapred.Task.sendDone(TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.sendDone(TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol,Task$TaskReporter,OutputCommitter) org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol,Task$TaskReporter,OutputCommitter)
Update org.apache.hadoop.mapred.Task.discardOutput(TaskAttemptContext) org.apache.hadoop.mapred.Task.discardOutput(TaskAttemptContext)
Update org.apache.hadoop.mapred.Task.runTaskCleanupTask(TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.Task.runTaskCleanupTask(TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.Task.taskCleanup(TaskUmbilicalProtocol) org.apache.hadoop.mapred.Task.taskCleanup(TaskUmbilicalProtocol)
Update org.apache.hadoop.mapred.Task.runJobCleanupTask(TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.Task.runJobCleanupTask(TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.Task.keepTaskFiles(JobConf) org.apache.hadoop.mapred.Task.keepTaskFiles(JobConf)
Update org.apache.hadoop.mapred.Task.runJobSetupTask(TaskUmbilicalProtocol,Task$TaskReporter) org.apache.hadoop.mapred.Task.runJobSetupTask(TaskUmbilicalProtocol,Task$TaskReporter)
Update org.apache.hadoop.mapred.Task.setConf(Configuration) org.apache.hadoop.mapred.Task.setConf(Configuration)
Update org.apache.hadoop.mapred.Task.getConf() org.apache.hadoop.mapred.Task.getConf()
Update org.apache.hadoop.mapred.Task.getMapOutputFile() org.apache.hadoop.mapred.Task.getMapOutputFile()
Update org.apache.hadoop.mapred.Task.createReduceContext(Reducer,Configuration,TaskAttemptID,RawKeyValueIterator,Counter,Counter,RecordWriter,OutputCommitter,StatusReporter,RawComparator,Class,Class) org.apache.hadoop.mapred.Task.createReduceContext(Reducer,Configuration,TaskAttemptID,RawKeyValueIterator,Counter,Counter,RecordWriter,OutputCommitter,StatusReporter,RawComparator,Class,Class)
Update org.apache.hadoop.mapred.Task.getExtraData() org.apache.hadoop.mapred.Task.getExtraData()
Update org.apache.hadoop.mapred.Task.setExtraData(BytesWritable) org.apache.hadoop.mapred.Task.setExtraData(BytesWritable)
Update org.apache.hadoop.mapred.Task.access$000(Task) org.apache.hadoop.mapred.Task.access$000(Task)
Update org.apache.hadoop.mapred.Task.access$100(Task) org.apache.hadoop.mapred.Task.access$100(Task)
Update org.apache.hadoop.mapred.Task.access$202(Task,long) org.apache.hadoop.mapred.Task.access$202(Task,long)
Update org.apache.hadoop.mapred.Task.access$300(Task) org.apache.hadoop.mapred.Task.access$300(Task)
Update org.apache.hadoop.mapred.Task.access$400(Task) org.apache.hadoop.mapred.Task.access$400(Task)
Delete org.apache.hadoop.mapred.Task.access$500(Task) org.apache.hadoop.mapred.Task
Delete org.apache.hadoop.mapred.Task.access$600(Task) org.apache.hadoop.mapred.Task
Delete org.apache.hadoop.mapred.Task.access$700() org.apache.hadoop.mapred.Task
Update org.apache.hadoop.mapred.Task.<clinit>() org.apache.hadoop.mapred.Task.<clinit>()
Delete org.apache.hadoop.mapred.Task.LOG : Log org.apache.hadoop.mapred.Task
Delete org.apache.hadoop.mapred.Task.PROGRESS_INTERVAL : int org.apache.hadoop.mapred.Task
Update org.apache.hadoop.mapred.TaskAttemptContext org.apache.hadoop.mapred.TaskAttemptContext
Update org.apache.hadoop.mapred.TaskAttemptContextImpl org.apache.hadoop.mapred.TaskAttemptContextImpl
Update org.apache.hadoop.mapred.TaskAttemptID org.apache.hadoop.mapred.TaskAttemptID
Update org.apache.hadoop.mapred.TaskCompletionEvent.Status org.apache.hadoop.mapred.TaskCompletionEvent.Status
Update org.apache.hadoop.mapred.TaskCompletionEvent org.apache.hadoop.mapred.TaskCompletionEvent
Update org.apache.hadoop.mapred.TaskID org.apache.hadoop.mapred.TaskID
Update org.apache.hadoop.mapred.TaskLog.1 org.apache.hadoop.mapred.TaskLog.1
Update org.apache.hadoop.mapred.TaskLog.2 org.apache.hadoop.mapred.TaskLog.2
Update org.apache.hadoop.mapred.TaskLog.3 org.apache.hadoop.mapred.TaskLog.3
Update org.apache.hadoop.mapred.TaskLog.LogFileDetail org.apache.hadoop.mapred.TaskLog.LogFileDetail
Update org.apache.hadoop.mapred.TaskLog.LogName org.apache.hadoop.mapred.TaskLog.LogName
Update org.apache.hadoop.mapred.TaskLog.Reader org.apache.hadoop.mapred.TaskLog.Reader
Update org.apache.hadoop.mapred.TaskLog org.apache.hadoop.mapred.TaskLog
Delete org.apache.hadoop.mapred.TaskLog.LOG : Log org.apache.hadoop.mapred.TaskLog
Update org.apache.hadoop.mapred.TaskLogAppender org.apache.hadoop.mapred.TaskLogAppender
Update org.apache.hadoop.mapred.TaskReport org.apache.hadoop.mapred.TaskReport
Update org.apache.hadoop.mapred.TaskStatus.Phase org.apache.hadoop.mapred.TaskStatus.Phase
Update org.apache.hadoop.mapred.TaskStatus.State org.apache.hadoop.mapred.TaskStatus.State
Update org.apache.hadoop.mapred.TaskStatus.State.<clinit>() org.apache.hadoop.mapred.TaskStatus.State.<clinit>()
Update org.apache.hadoop.mapred.TaskStatus org.apache.hadoop.mapred.TaskStatus
Delete org.apache.hadoop.mapred.TaskStatus.LOG : Log org.apache.hadoop.mapred.TaskStatus
Update org.apache.hadoop.mapred.TaskUmbilicalProtocol org.apache.hadoop.mapred.TaskUmbilicalProtocol
Delete org.apache.hadoop.mapred.TaskUmbilicalProtocol.statusUpdate(TaskAttemptID,TaskStatus) org.apache.hadoop.mapred.TaskUmbilicalProtocol
Delete org.apache.hadoop.mapred.TaskUmbilicalProtocol.ping(TaskAttemptID) org.apache.hadoop.mapred.TaskUmbilicalProtocol
Delete org.apache.hadoop.mapred.TaskUmbilicalProtocol.fatalError(TaskAttemptID,String) org.apache.hadoop.mapred.TaskUmbilicalProtocol
Update org.apache.hadoop.mapred.TextInputFormat org.apache.hadoop.mapred.TextInputFormat
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream,String) org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream,String)
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream) org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream)
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.writeObject(Object) org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.writeObject(Object)
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.write(Object,Object) org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.write(Object,Object)
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.close(Reporter) org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.close(Reporter)
Update org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<clinit>() org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.<clinit>()
Delete org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.utf8 : String org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter
Delete org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter.newline : byte[] org.apache.hadoop.mapred.TextOutputFormat.LineRecordWriter
Update org.apache.hadoop.mapred.TextOutputFormat org.apache.hadoop.mapred.TextOutputFormat
Update org.apache.hadoop.mapred.TIPStatus org.apache.hadoop.mapred.TIPStatus
Update org.apache.hadoop.mapred.Utils.OutputFileUtils.OutputFilesFilter org.apache.hadoop.mapred.Utils.OutputFileUtils.OutputFilesFilter
Update org.apache.hadoop.mapred.Utils.OutputFileUtils.OutputLogFilter org.apache.hadoop.mapred.Utils.OutputFileUtils.OutputLogFilter
Update org.apache.hadoop.mapred.Utils.OutputFileUtils org.apache.hadoop.mapred.Utils.OutputFileUtils
Update org.apache.hadoop.mapred.Utils org.apache.hadoop.mapred.Utils
Update org.apache.hadoop.mapreduce.Cluster.1 org.apache.hadoop.mapreduce.Cluster.1
Update org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus
Update org.apache.hadoop.mapreduce.Cluster org.apache.hadoop.mapreduce.Cluster
Update org.apache.hadoop.mapreduce.Cluster.<init>(Configuration) org.apache.hadoop.mapreduce.Cluster.<init>(Configuration)
Update org.apache.hadoop.mapreduce.Cluster.<init>(InetSocketAddress,Configuration) org.apache.hadoop.mapreduce.Cluster.<init>(InetSocketAddress,Configuration)
Update org.apache.hadoop.mapreduce.Cluster.initialize(InetSocketAddress,Configuration) org.apache.hadoop.mapreduce.Cluster.initialize(InetSocketAddress,Configuration)
Update org.apache.hadoop.mapreduce.Cluster.getConf() org.apache.hadoop.mapreduce.Cluster.getConf()
Update org.apache.hadoop.mapreduce.Cluster.close() org.apache.hadoop.mapreduce.Cluster.close()
Update org.apache.hadoop.mapreduce.Cluster.getJobs(JobStatus[]) org.apache.hadoop.mapreduce.Cluster.getJobs(JobStatus[])
Update org.apache.hadoop.mapreduce.Cluster.getFileSystem() org.apache.hadoop.mapreduce.Cluster.getFileSystem()
Update org.apache.hadoop.mapreduce.Cluster.getJob(JobID) org.apache.hadoop.mapreduce.Cluster.getJob(JobID)
Update org.apache.hadoop.mapreduce.Cluster.getQueues() org.apache.hadoop.mapreduce.Cluster.getQueues()
Update org.apache.hadoop.mapreduce.Cluster.getQueue(String) org.apache.hadoop.mapreduce.Cluster.getQueue(String)
Update org.apache.hadoop.mapreduce.Cluster.getLogParams(JobID,TaskAttemptID) org.apache.hadoop.mapreduce.Cluster.getLogParams(JobID,TaskAttemptID)
Update org.apache.hadoop.mapreduce.Cluster.getClusterStatus() org.apache.hadoop.mapreduce.Cluster.getClusterStatus()
Update org.apache.hadoop.mapreduce.Cluster.getActiveTaskTrackers() org.apache.hadoop.mapreduce.Cluster.getActiveTaskTrackers()
Update org.apache.hadoop.mapreduce.Cluster.getBlackListedTaskTrackers() org.apache.hadoop.mapreduce.Cluster.getBlackListedTaskTrackers()
Update org.apache.hadoop.mapreduce.Cluster.getAllJobs() org.apache.hadoop.mapreduce.Cluster.getAllJobs()
Update org.apache.hadoop.mapreduce.Cluster.getAllJobStatuses() org.apache.hadoop.mapreduce.Cluster.getAllJobStatuses()
Update org.apache.hadoop.mapreduce.Cluster.getSystemDir() org.apache.hadoop.mapreduce.Cluster.getSystemDir()
Update org.apache.hadoop.mapreduce.Cluster.getStagingAreaDir() org.apache.hadoop.mapreduce.Cluster.getStagingAreaDir()
Update org.apache.hadoop.mapreduce.Cluster.getJobHistoryUrl(JobID) org.apache.hadoop.mapreduce.Cluster.getJobHistoryUrl(JobID)
Update org.apache.hadoop.mapreduce.Cluster.getQueueAclsForCurrentUser() org.apache.hadoop.mapreduce.Cluster.getQueueAclsForCurrentUser()
Update org.apache.hadoop.mapreduce.Cluster.getRootQueues() org.apache.hadoop.mapreduce.Cluster.getRootQueues()
Update org.apache.hadoop.mapreduce.Cluster.getChildQueues(String) org.apache.hadoop.mapreduce.Cluster.getChildQueues(String)
Update org.apache.hadoop.mapreduce.Cluster.getJobTrackerStatus() org.apache.hadoop.mapreduce.Cluster.getJobTrackerStatus()
Update org.apache.hadoop.mapreduce.Cluster.getTaskTrackerExpiryInterval() org.apache.hadoop.mapreduce.Cluster.getTaskTrackerExpiryInterval()
Update org.apache.hadoop.mapreduce.Cluster.getDelegationToken(Text) org.apache.hadoop.mapreduce.Cluster.getDelegationToken(Text)
Update org.apache.hadoop.mapreduce.Cluster.renewDelegationToken(Token) org.apache.hadoop.mapreduce.Cluster.renewDelegationToken(Token)
Update org.apache.hadoop.mapreduce.Cluster.cancelDelegationToken(Token) org.apache.hadoop.mapreduce.Cluster.cancelDelegationToken(Token)
Update org.apache.hadoop.mapreduce.Cluster.<clinit>() org.apache.hadoop.mapreduce.Cluster.<clinit>()
Delete org.apache.hadoop.mapreduce.Cluster.LOG : Log org.apache.hadoop.mapreduce.Cluster
Delete org.apache.hadoop.mapreduce.Cluster.frameworkLoader : ServiceLoader org.apache.hadoop.mapreduce.Cluster
Update org.apache.hadoop.mapreduce.ClusterMetrics org.apache.hadoop.mapreduce.ClusterMetrics
Update org.apache.hadoop.mapreduce.ContextFactory org.apache.hadoop.mapreduce.ContextFactory
Update org.apache.hadoop.mapreduce.Counter org.apache.hadoop.mapreduce.Counter
Update org.apache.hadoop.mapreduce.CounterGroup org.apache.hadoop.mapreduce.CounterGroup
Update org.apache.hadoop.mapreduce.counters.AbstractCounter org.apache.hadoop.mapreduce.counters.AbstractCounter
Update org.apache.hadoop.mapreduce.counters.AbstractCounterGroup org.apache.hadoop.mapreduce.counters.AbstractCounterGroup
Update org.apache.hadoop.mapreduce.counters.AbstractCounters.1 org.apache.hadoop.mapreduce.counters.AbstractCounters.1
Update org.apache.hadoop.mapreduce.counters.AbstractCounters.GroupType org.apache.hadoop.mapreduce.counters.AbstractCounters.GroupType
Update org.apache.hadoop.mapreduce.counters.AbstractCounters org.apache.hadoop.mapreduce.counters.AbstractCounters
Delete org.apache.hadoop.mapreduce.counters.AbstractCounters.LOG : Log org.apache.hadoop.mapreduce.counters.AbstractCounters
Update org.apache.hadoop.mapreduce.counters.CounterGroupBase org.apache.hadoop.mapreduce.counters.CounterGroupBase
Update org.apache.hadoop.mapreduce.counters.CounterGroupFactory.FrameworkGroupFactory org.apache.hadoop.mapreduce.counters.CounterGroupFactory.FrameworkGroupFactory
Update org.apache.hadoop.mapreduce.counters.CounterGroupFactory org.apache.hadoop.mapreduce.counters.CounterGroupFactory
Update org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.1 org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.1
Update org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.FSCounter org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.FSCounter
Update org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup
Delete org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.LOG : Log org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.1 org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.1
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.increment(long) org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.increment(long)
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.write(DataOutput) org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.write(DataOutput)
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.readFields(DataInput) org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.readFields(DataInput)
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.<clinit>() org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.FrameworkCounter.<clinit>()
Update org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup
Delete org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.LOG : Log org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup
Update org.apache.hadoop.mapreduce.counters.GenericCounter org.apache.hadoop.mapreduce.counters.GenericCounter
Update org.apache.hadoop.mapreduce.counters.LimitExceededException org.apache.hadoop.mapreduce.counters.LimitExceededException
Update org.apache.hadoop.mapreduce.counters.Limits org.apache.hadoop.mapreduce.counters.Limits
Update org.apache.hadoop.mapreduce.counters.package-info org.apache.hadoop.mapreduce.counters.package-info
Update org.apache.hadoop.mapreduce.Counters.1 org.apache.hadoop.mapreduce.Counters.1
Update org.apache.hadoop.mapreduce.Counters.FileSystemGroup org.apache.hadoop.mapreduce.Counters.FileSystemGroup
Update org.apache.hadoop.mapreduce.Counters.FrameworkGroupImpl org.apache.hadoop.mapreduce.Counters.FrameworkGroupImpl
Update org.apache.hadoop.mapreduce.Counters.GenericGroup org.apache.hadoop.mapreduce.Counters.GenericGroup
Update org.apache.hadoop.mapreduce.Counters.GroupFactory.1 org.apache.hadoop.mapreduce.Counters.GroupFactory.1
Update org.apache.hadoop.mapreduce.Counters.GroupFactory org.apache.hadoop.mapreduce.Counters.GroupFactory
Update org.apache.hadoop.mapreduce.Counters org.apache.hadoop.mapreduce.Counters
Update org.apache.hadoop.mapreduce.CryptoUtils org.apache.hadoop.mapreduce.CryptoUtils
Delete org.apache.hadoop.mapreduce.CryptoUtils.isShuffleEncrypted(Configuration) org.apache.hadoop.mapreduce.CryptoUtils
Update org.apache.hadoop.mapreduce.CryptoUtils.createIV(Configuration) org.apache.hadoop.mapreduce.CryptoUtils.createIV(Configuration)
Update org.apache.hadoop.mapreduce.CryptoUtils.cryptoPadding(Configuration) org.apache.hadoop.mapreduce.CryptoUtils.cryptoPadding(Configuration)
Update org.apache.hadoop.mapreduce.CryptoUtils.getEncryptionKey() org.apache.hadoop.mapreduce.CryptoUtils.getEncryptionKey()
Update org.apache.hadoop.mapreduce.CryptoUtils.getBufferSize(Configuration) org.apache.hadoop.mapreduce.CryptoUtils.getBufferSize(Configuration)
Update org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,FSDataOutputStream) org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,FSDataOutputStream)
Update org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,InputStream,long) org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,InputStream,long)
Update org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,FSDataInputStream) org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(Configuration,FSDataInputStream)
Update org.apache.hadoop.mapreduce.CryptoUtils.<clinit>() org.apache.hadoop.mapreduce.CryptoUtils.<clinit>()
Delete org.apache.hadoop.mapreduce.CryptoUtils.LOG : Log org.apache.hadoop.mapreduce.CryptoUtils
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(Configuration) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(Configuration)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(Configuration,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(Configuration,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getDelegationTokens(Configuration,Credentials) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getDelegationTokens(Configuration,Credentials)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineCacheVisibilities(Configuration,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineCacheVisibilities(Configuration,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setArchiveVisibilities(Configuration,String) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setArchiveVisibilities(Configuration,String)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setFileVisibilities(Configuration,String) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setFileVisibilities(Configuration,String)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setArchiveTimestamps(Configuration,String) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setArchiveTimestamps(Configuration,String)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setFileTimestamps(Configuration,String) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.setFileTimestamps(Configuration,String)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(Configuration,URI,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(Configuration,URI,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.isPublic(Configuration,URI,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.isPublic(Configuration,URI,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.ancestorsHaveExecutePermissions(FileSystem,Path,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.ancestorsHaveExecutePermissions(FileSystem,Path,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.checkPermissionOfOther(FileSystem,Path,FsAction,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.checkPermissionOfOther(FileSystem,Path,FsAction,Map)
Update org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(FileSystem,URI,Map) org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(FileSystem,URI,Map)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache org.apache.hadoop.mapreduce.filecache.DistributedCache
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.addFileToClassPath(Path,Configuration,FileSystem) org.apache.hadoop.mapreduce.filecache.DistributedCache.addFileToClassPath(Path,Configuration,FileSystem)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration) org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.addArchiveToClassPath(Path,Configuration) org.apache.hadoop.mapreduce.filecache.DistributedCache.addArchiveToClassPath(Path,Configuration)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.addArchiveToClassPath(Path,Configuration,FileSystem) org.apache.hadoop.mapreduce.filecache.DistributedCache.addArchiveToClassPath(Path,Configuration,FileSystem)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration) org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.parseBooleans(String[]) org.apache.hadoop.mapreduce.filecache.DistributedCache.parseBooleans(String[])
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileVisibilities(Configuration) org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileVisibilities(Configuration)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveVisibilities(Configuration) org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveVisibilities(Configuration)
Update org.apache.hadoop.mapreduce.filecache.DistributedCache.checkURIs(URI[],URI[]) org.apache.hadoop.mapreduce.filecache.DistributedCache.checkURIs(URI[],URI[])
Update org.apache.hadoop.mapreduce.filecache.package-info org.apache.hadoop.mapreduce.filecache.package-info
Update org.apache.hadoop.mapreduce.FileSystemCounter org.apache.hadoop.mapreduce.FileSystemCounter
Update org.apache.hadoop.mapreduce.FileSystemCounter.<clinit>() org.apache.hadoop.mapreduce.FileSystemCounter.<clinit>()
Update org.apache.hadoop.mapreduce.ID org.apache.hadoop.mapreduce.ID
Update org.apache.hadoop.mapreduce.InputFormat org.apache.hadoop.mapreduce.InputFormat
Update org.apache.hadoop.mapreduce.InputSplit org.apache.hadoop.mapreduce.InputSplit
Update org.apache.hadoop.mapreduce.Job.1 org.apache.hadoop.mapreduce.Job.1
Update org.apache.hadoop.mapreduce.Job.1.run() org.apache.hadoop.mapreduce.Job.1.run()
Update org.apache.hadoop.mapreduce.Job.1.run() org.apache.hadoop.mapreduce.Job.1.run()
Update org.apache.hadoop.mapreduce.Job.10 org.apache.hadoop.mapreduce.Job.10
Delete org.apache.hadoop.mapreduce.Job.10.<init>(Job,JobSubmitter) org.apache.hadoop.mapreduce.Job.10
Delete org.apache.hadoop.mapreduce.Job.10.run() org.apache.hadoop.mapreduce.Job.10
Delete org.apache.hadoop.mapreduce.Job.10.val$submitter : JobSubmitter org.apache.hadoop.mapreduce.Job.10
Update org.apache.hadoop.mapreduce.Job.11 org.apache.hadoop.mapreduce.Job.11
Delete org.apache.hadoop.mapreduce.Job.11.<clinit>() org.apache.hadoop.mapreduce.Job.11
Delete org.apache.hadoop.mapreduce.Job.11.$SwitchMap$org$apache$hadoop$mapreduce$Job$TaskStatusFilter : int[] org.apache.hadoop.mapreduce.Job.11
Update org.apache.hadoop.mapreduce.Job.2 org.apache.hadoop.mapreduce.Job.2
Update org.apache.hadoop.mapreduce.Job.3 org.apache.hadoop.mapreduce.Job.3
Update org.apache.hadoop.mapreduce.Job.4 org.apache.hadoop.mapreduce.Job.4
Delete org.apache.hadoop.mapreduce.Job.4.<init>(Job,JobPriority) org.apache.hadoop.mapreduce.Job.4
Update org.apache.hadoop.mapreduce.Job.4.run() org.apache.hadoop.mapreduce.Job.4.run()
Delete org.apache.hadoop.mapreduce.Job.4.val$tmpPriority : JobPriority org.apache.hadoop.mapreduce.Job.4
Update org.apache.hadoop.mapreduce.Job.5 org.apache.hadoop.mapreduce.Job.5
Delete org.apache.hadoop.mapreduce.Job.5.<init>(Job,int,int) org.apache.hadoop.mapreduce.Job.5
Delete org.apache.hadoop.mapreduce.Job.5.run() org.apache.hadoop.mapreduce.Job.5
Update org.apache.hadoop.mapreduce.Job.5.run() org.apache.hadoop.mapreduce.Job.5.run()
Delete org.apache.hadoop.mapreduce.Job.5.val$startFrom : int org.apache.hadoop.mapreduce.Job.5
Delete org.apache.hadoop.mapreduce.Job.5.val$numEvents : int org.apache.hadoop.mapreduce.Job.5
Update org.apache.hadoop.mapreduce.Job.6 org.apache.hadoop.mapreduce.Job.6
Delete org.apache.hadoop.mapreduce.Job.6.<init>(Job,TaskAttemptID,boolean) org.apache.hadoop.mapreduce.Job.6
Delete org.apache.hadoop.mapreduce.Job.6.run() org.apache.hadoop.mapreduce.Job.6
Delete org.apache.hadoop.mapreduce.Job.6.val$taskId : TaskAttemptID org.apache.hadoop.mapreduce.Job.6
Delete org.apache.hadoop.mapreduce.Job.6.val$shouldFail : boolean org.apache.hadoop.mapreduce.Job.6
Update org.apache.hadoop.mapreduce.Job.7 org.apache.hadoop.mapreduce.Job.7
Delete org.apache.hadoop.mapreduce.Job.7.<init>(Job) org.apache.hadoop.mapreduce.Job.7
Delete org.apache.hadoop.mapreduce.Job.7.run() org.apache.hadoop.mapreduce.Job.7
Update org.apache.hadoop.mapreduce.Job.7.run() org.apache.hadoop.mapreduce.Job.7.run()
Update org.apache.hadoop.mapreduce.Job.8 org.apache.hadoop.mapreduce.Job.8
Delete org.apache.hadoop.mapreduce.Job.8.<init>(Job,TaskAttemptID) org.apache.hadoop.mapreduce.Job.8
Delete org.apache.hadoop.mapreduce.Job.8.run() org.apache.hadoop.mapreduce.Job.8
Delete org.apache.hadoop.mapreduce.Job.8.val$taskid : TaskAttemptID org.apache.hadoop.mapreduce.Job.8
Update org.apache.hadoop.mapreduce.Job.9 org.apache.hadoop.mapreduce.Job.9
Delete org.apache.hadoop.mapreduce.Job.9.<init>(Job) org.apache.hadoop.mapreduce.Job.9
Delete org.apache.hadoop.mapreduce.Job.9.run() org.apache.hadoop.mapreduce.Job.9
Update org.apache.hadoop.mapreduce.Job.9.run() org.apache.hadoop.mapreduce.Job.9.run()
Update org.apache.hadoop.mapreduce.Job.JobState org.apache.hadoop.mapreduce.Job.JobState
Update org.apache.hadoop.mapreduce.Job.TaskStatusFilter org.apache.hadoop.mapreduce.Job.TaskStatusFilter
Update org.apache.hadoop.mapreduce.Job org.apache.hadoop.mapreduce.Job
Update org.apache.hadoop.mapreduce.Job.<init>(JobConf) org.apache.hadoop.mapreduce.Job.<init>(JobConf)
Update org.apache.hadoop.mapreduce.Job.<init>(JobStatus,JobConf) org.apache.hadoop.mapreduce.Job.<init>(JobStatus,JobConf)
Update org.apache.hadoop.mapreduce.Job.ensureState(Job$JobState) org.apache.hadoop.mapreduce.Job.ensureState(Job$JobState)
Update org.apache.hadoop.mapreduce.Job.updateStatus() org.apache.hadoop.mapreduce.Job.updateStatus()
Update org.apache.hadoop.mapreduce.Job.getStatus() org.apache.hadoop.mapreduce.Job.getStatus()
Update org.apache.hadoop.mapreduce.Job.getJobState() org.apache.hadoop.mapreduce.Job.getJobState()
Update org.apache.hadoop.mapreduce.Job.getTrackingURL() org.apache.hadoop.mapreduce.Job.getTrackingURL()
Update org.apache.hadoop.mapreduce.Job.getJobFile() org.apache.hadoop.mapreduce.Job.getJobFile()
Update org.apache.hadoop.mapreduce.Job.getStartTime() org.apache.hadoop.mapreduce.Job.getStartTime()
Update org.apache.hadoop.mapreduce.Job.getFinishTime() org.apache.hadoop.mapreduce.Job.getFinishTime()
Update org.apache.hadoop.mapreduce.Job.getSchedulingInfo() org.apache.hadoop.mapreduce.Job.getSchedulingInfo()
Update org.apache.hadoop.mapreduce.Job.getPriority() org.apache.hadoop.mapreduce.Job.getPriority()
Update org.apache.hadoop.mapreduce.Job.getJobName() org.apache.hadoop.mapreduce.Job.getJobName()
Update org.apache.hadoop.mapreduce.Job.getHistoryUrl() org.apache.hadoop.mapreduce.Job.getHistoryUrl()
Update org.apache.hadoop.mapreduce.Job.isRetired() org.apache.hadoop.mapreduce.Job.isRetired()
Update org.apache.hadoop.mapreduce.Job.getCluster() org.apache.hadoop.mapreduce.Job.getCluster()
Update org.apache.hadoop.mapreduce.Job.setCluster(Cluster) org.apache.hadoop.mapreduce.Job.setCluster(Cluster)
Update org.apache.hadoop.mapreduce.Job.toString() org.apache.hadoop.mapreduce.Job.toString()
Update org.apache.hadoop.mapreduce.Job.getTaskFailureEventString() org.apache.hadoop.mapreduce.Job.getTaskFailureEventString()
Update org.apache.hadoop.mapreduce.Job.getTaskReports(TaskType) org.apache.hadoop.mapreduce.Job.getTaskReports(TaskType)
Update org.apache.hadoop.mapreduce.Job.mapProgress() org.apache.hadoop.mapreduce.Job.mapProgress()
Update org.apache.hadoop.mapreduce.Job.reduceProgress() org.apache.hadoop.mapreduce.Job.reduceProgress()
Update org.apache.hadoop.mapreduce.Job.cleanupProgress() org.apache.hadoop.mapreduce.Job.cleanupProgress()
Update org.apache.hadoop.mapreduce.Job.setupProgress() org.apache.hadoop.mapreduce.Job.setupProgress()
Update org.apache.hadoop.mapreduce.Job.isComplete() org.apache.hadoop.mapreduce.Job.isComplete()
Update org.apache.hadoop.mapreduce.Job.isSuccessful() org.apache.hadoop.mapreduce.Job.isSuccessful()
Update org.apache.hadoop.mapreduce.Job.killJob() org.apache.hadoop.mapreduce.Job.killJob()
Update org.apache.hadoop.mapreduce.Job.setPriority(JobPriority) org.apache.hadoop.mapreduce.Job.setPriority(JobPriority)
Update org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(int,int) org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(int,int)
Update org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(int) org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(int)
Update org.apache.hadoop.mapreduce.Job.killTask(TaskAttemptID,boolean) org.apache.hadoop.mapreduce.Job.killTask(TaskAttemptID,boolean)
Update org.apache.hadoop.mapreduce.Job.killTask(TaskAttemptID) org.apache.hadoop.mapreduce.Job.killTask(TaskAttemptID)
Update org.apache.hadoop.mapreduce.Job.failTask(TaskAttemptID) org.apache.hadoop.mapreduce.Job.failTask(TaskAttemptID)
Update org.apache.hadoop.mapreduce.Job.getCounters() org.apache.hadoop.mapreduce.Job.getCounters()
Update org.apache.hadoop.mapreduce.Job.getTaskDiagnostics(TaskAttemptID) org.apache.hadoop.mapreduce.Job.getTaskDiagnostics(TaskAttemptID)
Update org.apache.hadoop.mapreduce.Job.setNumReduceTasks(int) org.apache.hadoop.mapreduce.Job.setNumReduceTasks(int)
Update org.apache.hadoop.mapreduce.Job.setWorkingDirectory(Path) org.apache.hadoop.mapreduce.Job.setWorkingDirectory(Path)
Update org.apache.hadoop.mapreduce.Job.setInputFormatClass(Class) org.apache.hadoop.mapreduce.Job.setInputFormatClass(Class)
Update org.apache.hadoop.mapreduce.Job.setOutputFormatClass(Class) org.apache.hadoop.mapreduce.Job.setOutputFormatClass(Class)
Update org.apache.hadoop.mapreduce.Job.setMapperClass(Class) org.apache.hadoop.mapreduce.Job.setMapperClass(Class)
Update org.apache.hadoop.mapreduce.Job.setJarByClass(Class) org.apache.hadoop.mapreduce.Job.setJarByClass(Class)
Update org.apache.hadoop.mapreduce.Job.setJar(String) org.apache.hadoop.mapreduce.Job.setJar(String)
Update org.apache.hadoop.mapreduce.Job.setUser(String) org.apache.hadoop.mapreduce.Job.setUser(String)
Update org.apache.hadoop.mapreduce.Job.setCombinerClass(Class) org.apache.hadoop.mapreduce.Job.setCombinerClass(Class)
Update org.apache.hadoop.mapreduce.Job.setReducerClass(Class) org.apache.hadoop.mapreduce.Job.setReducerClass(Class)
Update org.apache.hadoop.mapreduce.Job.setPartitionerClass(Class) org.apache.hadoop.mapreduce.Job.setPartitionerClass(Class)
Update org.apache.hadoop.mapreduce.Job.setMapOutputKeyClass(Class) org.apache.hadoop.mapreduce.Job.setMapOutputKeyClass(Class)
Update org.apache.hadoop.mapreduce.Job.setMapOutputValueClass(Class) org.apache.hadoop.mapreduce.Job.setMapOutputValueClass(Class)
Update org.apache.hadoop.mapreduce.Job.setOutputKeyClass(Class) org.apache.hadoop.mapreduce.Job.setOutputKeyClass(Class)
Update org.apache.hadoop.mapreduce.Job.setOutputValueClass(Class) org.apache.hadoop.mapreduce.Job.setOutputValueClass(Class)
Update org.apache.hadoop.mapreduce.Job.setCombinerKeyGroupingComparatorClass(Class) org.apache.hadoop.mapreduce.Job.setCombinerKeyGroupingComparatorClass(Class)
Update org.apache.hadoop.mapreduce.Job.setSortComparatorClass(Class) org.apache.hadoop.mapreduce.Job.setSortComparatorClass(Class)
Update org.apache.hadoop.mapreduce.Job.setGroupingComparatorClass(Class) org.apache.hadoop.mapreduce.Job.setGroupingComparatorClass(Class)
Update org.apache.hadoop.mapreduce.Job.setJobName(String) org.apache.hadoop.mapreduce.Job.setJobName(String)
Update org.apache.hadoop.mapreduce.Job.setSpeculativeExecution(boolean) org.apache.hadoop.mapreduce.Job.setSpeculativeExecution(boolean)
Update org.apache.hadoop.mapreduce.Job.setMapSpeculativeExecution(boolean) org.apache.hadoop.mapreduce.Job.setMapSpeculativeExecution(boolean)
Update org.apache.hadoop.mapreduce.Job.setReduceSpeculativeExecution(boolean) org.apache.hadoop.mapreduce.Job.setReduceSpeculativeExecution(boolean)
Update org.apache.hadoop.mapreduce.Job.setJobSetupCleanupNeeded(boolean) org.apache.hadoop.mapreduce.Job.setJobSetupCleanupNeeded(boolean)
Update org.apache.hadoop.mapreduce.Job.setCacheArchives(URI[]) org.apache.hadoop.mapreduce.Job.setCacheArchives(URI[])
Update org.apache.hadoop.mapreduce.Job.setCacheFiles(URI[]) org.apache.hadoop.mapreduce.Job.setCacheFiles(URI[])
Update org.apache.hadoop.mapreduce.Job.addCacheArchive(URI) org.apache.hadoop.mapreduce.Job.addCacheArchive(URI)
Update org.apache.hadoop.mapreduce.Job.addCacheFile(URI) org.apache.hadoop.mapreduce.Job.addCacheFile(URI)
Update org.apache.hadoop.mapreduce.Job.addFileToClassPath(Path) org.apache.hadoop.mapreduce.Job.addFileToClassPath(Path)
Update org.apache.hadoop.mapreduce.Job.addArchiveToClassPath(Path) org.apache.hadoop.mapreduce.Job.addArchiveToClassPath(Path)
Update org.apache.hadoop.mapreduce.Job.createSymlink() org.apache.hadoop.mapreduce.Job.createSymlink()
Update org.apache.hadoop.mapreduce.Job.setMaxMapAttempts(int) org.apache.hadoop.mapreduce.Job.setMaxMapAttempts(int)
Update org.apache.hadoop.mapreduce.Job.setMaxReduceAttempts(int) org.apache.hadoop.mapreduce.Job.setMaxReduceAttempts(int)
Update org.apache.hadoop.mapreduce.Job.setProfileEnabled(boolean) org.apache.hadoop.mapreduce.Job.setProfileEnabled(boolean)
Update org.apache.hadoop.mapreduce.Job.setProfileParams(String) org.apache.hadoop.mapreduce.Job.setProfileParams(String)
Update org.apache.hadoop.mapreduce.Job.setProfileTaskRange(boolean,String) org.apache.hadoop.mapreduce.Job.setProfileTaskRange(boolean,String)
Update org.apache.hadoop.mapreduce.Job.ensureNotSet(String,String) org.apache.hadoop.mapreduce.Job.ensureNotSet(String,String)
Update org.apache.hadoop.mapreduce.Job.setCancelDelegationTokenUponJobCompletion(boolean) org.apache.hadoop.mapreduce.Job.setCancelDelegationTokenUponJobCompletion(boolean)
Update org.apache.hadoop.mapreduce.Job.setUseNewAPI() org.apache.hadoop.mapreduce.Job.setUseNewAPI()
Update org.apache.hadoop.mapreduce.Job.connect() org.apache.hadoop.mapreduce.Job.connect()
Update org.apache.hadoop.mapreduce.Job.isConnected() org.apache.hadoop.mapreduce.Job.isConnected()
Update org.apache.hadoop.mapreduce.Job.getJobSubmitter(FileSystem,ClientProtocol) org.apache.hadoop.mapreduce.Job.getJobSubmitter(FileSystem,ClientProtocol)
Update org.apache.hadoop.mapreduce.Job.submit() org.apache.hadoop.mapreduce.Job.submit()
Update org.apache.hadoop.mapreduce.Job.waitForCompletion(boolean) org.apache.hadoop.mapreduce.Job.waitForCompletion(boolean)
Update org.apache.hadoop.mapreduce.Job.monitorAndPrintJob() org.apache.hadoop.mapreduce.Job.monitorAndPrintJob()
Update org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[],Job$TaskStatusFilter,boolean,Configuration$IntegerRanges,Configuration$IntegerRanges) org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[],Job$TaskStatusFilter,boolean,Configuration$IntegerRanges,Configuration$IntegerRanges)
Update org.apache.hadoop.mapreduce.Job.getProgressPollInterval(Configuration) org.apache.hadoop.mapreduce.Job.getProgressPollInterval(Configuration)
Update org.apache.hadoop.mapreduce.Job.getCompletionPollInterval(Configuration) org.apache.hadoop.mapreduce.Job.getCompletionPollInterval(Configuration)
Update org.apache.hadoop.mapreduce.Job.getTaskOutputFilter(Configuration) org.apache.hadoop.mapreduce.Job.getTaskOutputFilter(Configuration)
Update org.apache.hadoop.mapreduce.Job.setTaskOutputFilter(Configuration,Job$TaskStatusFilter) org.apache.hadoop.mapreduce.Job.setTaskOutputFilter(Configuration,Job$TaskStatusFilter)
Update org.apache.hadoop.mapreduce.Job.isUber() org.apache.hadoop.mapreduce.Job.isUber()
Update org.apache.hadoop.mapreduce.Job.getReservationId() org.apache.hadoop.mapreduce.Job.getReservationId()
Update org.apache.hadoop.mapreduce.Job.setReservationId(ReservationId) org.apache.hadoop.mapreduce.Job.setReservationId(ReservationId)
Delete org.apache.hadoop.mapreduce.Job.access$000(Job) org.apache.hadoop.mapreduce.Job
Delete org.apache.hadoop.mapreduce.Job.access$100(Job) org.apache.hadoop.mapreduce.Job
Update org.apache.hadoop.mapreduce.Job.<clinit>() org.apache.hadoop.mapreduce.Job.<clinit>()
Delete org.apache.hadoop.mapreduce.Job.LOG : Log org.apache.hadoop.mapreduce.Job
Update org.apache.hadoop.mapreduce.JobACL org.apache.hadoop.mapreduce.JobACL
Update org.apache.hadoop.mapreduce.JobContext org.apache.hadoop.mapreduce.JobContext
Update org.apache.hadoop.mapreduce.JobCounter org.apache.hadoop.mapreduce.JobCounter
Update org.apache.hadoop.mapreduce.JobCounter.<clinit>() org.apache.hadoop.mapreduce.JobCounter.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.1 org.apache.hadoop.mapreduce.jobhistory.AMStarted.1
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.<init>(AMStarted$Builder) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.<init>(AMStarted$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.<init>(AMStarted) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.<init>(AMStarted)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getApplicationAttemptId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getApplicationAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setApplicationAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setApplicationAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasApplicationAttemptId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasApplicationAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearApplicationAttemptId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearApplicationAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getStartTime() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setStartTime(long) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setStartTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasStartTime() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearStartTime() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getContainerId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setContainerId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setContainerId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasContainerId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearContainerId() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerHost() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerHost()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerHost(CharSequence) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerHost(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerHost() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerHost()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerHost() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerHost()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerPort(int) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerHttpPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.getNodeManagerHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerHttpPort(int) org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.setNodeManagerHttpPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerHttpPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.hasNodeManagerHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerHttpPort() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.clearNodeManagerHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.build() org.apache.hadoop.mapreduce.jobhistory.AMStarted.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.AMStarted org.apache.hadoop.mapreduce.jobhistory.AMStarted
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent
Delete org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.<init>(ApplicationAttemptId,long,ContainerId,String,int,int) org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent
Delete org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.<init>(ApplicationAttemptId,long,ContainerId,String,int,int,String) org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getAppAttemptId() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getAppAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getStartTime() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getContainerId() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerHost() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerHost()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerPort() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerHttpPort() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getNodeManagerHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getForcedJobStateOnShutDown() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getForcedJobStateOnShutDown()
Update org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils
Update org.apache.hadoop.mapreduce.jobhistory.Event.1 org.apache.hadoop.mapreduce.jobhistory.Event.1
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder org.apache.hadoop.mapreduce.jobhistory.Event.Builder
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.<init>(Event$Builder) org.apache.hadoop.mapreduce.jobhistory.Event.Builder.<init>(Event$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.<init>(Event) org.apache.hadoop.mapreduce.jobhistory.Event.Builder.<init>(Event)
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.getType() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.getType()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.setType(EventType) org.apache.hadoop.mapreduce.jobhistory.Event.Builder.setType(EventType)
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.hasType() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.hasType()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.clearType() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.clearType()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.getEvent() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.getEvent()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.setEvent(Object) org.apache.hadoop.mapreduce.jobhistory.Event.Builder.setEvent(Object)
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.hasEvent() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.hasEvent()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.clearEvent() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.clearEvent()
Update org.apache.hadoop.mapreduce.jobhistory.Event.Builder.build() org.apache.hadoop.mapreduce.jobhistory.Event.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.Event org.apache.hadoop.mapreduce.jobhistory.Event
Update org.apache.hadoop.mapreduce.jobhistory.EventReader.1 org.apache.hadoop.mapreduce.jobhistory.EventReader.1
Update org.apache.hadoop.mapreduce.jobhistory.EventReader org.apache.hadoop.mapreduce.jobhistory.EventReader
Update org.apache.hadoop.mapreduce.jobhistory.EventReader.<init>(DataInputStream) org.apache.hadoop.mapreduce.jobhistory.EventReader.<init>(DataInputStream)
Update org.apache.hadoop.mapreduce.jobhistory.EventReader.getNextEvent() org.apache.hadoop.mapreduce.jobhistory.EventReader.getNextEvent()
Update org.apache.hadoop.mapreduce.jobhistory.EventReader.close() org.apache.hadoop.mapreduce.jobhistory.EventReader.close()
Update org.apache.hadoop.mapreduce.jobhistory.EventReader.fromAvro(JhCounters) org.apache.hadoop.mapreduce.jobhistory.EventReader.fromAvro(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.Events.Callback org.apache.hadoop.mapreduce.jobhistory.Events.Callback
Update org.apache.hadoop.mapreduce.jobhistory.Events org.apache.hadoop.mapreduce.jobhistory.Events
Update org.apache.hadoop.mapreduce.jobhistory.EventType org.apache.hadoop.mapreduce.jobhistory.EventType
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter org.apache.hadoop.mapreduce.jobhistory.EventWriter
Delete org.apache.hadoop.mapreduce.jobhistory.EventWriter.<init>(FSDataOutputStream) org.apache.hadoop.mapreduce.jobhistory.EventWriter
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.write(HistoryEvent) org.apache.hadoop.mapreduce.jobhistory.EventWriter.write(HistoryEvent)
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.flush() org.apache.hadoop.mapreduce.jobhistory.EventWriter.flush()
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.close() org.apache.hadoop.mapreduce.jobhistory.EventWriter.close()
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.toAvro(Counters) org.apache.hadoop.mapreduce.jobhistory.EventWriter.toAvro(Counters)
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.toAvro(Counters,String) org.apache.hadoop.mapreduce.jobhistory.EventWriter.toAvro(Counters,String)
Update org.apache.hadoop.mapreduce.jobhistory.EventWriter.<clinit>() org.apache.hadoop.mapreduce.jobhistory.EventWriter.<clinit>()
Delete org.apache.hadoop.mapreduce.jobhistory.EventWriter.LOG : Log org.apache.hadoop.mapreduce.jobhistory.EventWriter
Update org.apache.hadoop.mapreduce.jobhistory.HistoryEvent org.apache.hadoop.mapreduce.jobhistory.HistoryEvent
Update org.apache.hadoop.mapreduce.jobhistory.HistoryEventHandler org.apache.hadoop.mapreduce.jobhistory.HistoryEventHandler
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.1 org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.1
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.2 org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.2
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.3 org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.3
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.4 org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.4
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.5 org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.5
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.AnalyzedJob org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.AnalyzedJob
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.FilteredJob org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.FilteredJob
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.SummarizedJob org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.SummarizedJob
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.<init>(String,Configuration,boolean) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.<init>(String,Configuration,boolean)
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.print() org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.print()
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printJobDetails() org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printCounters(StringBuffer,Counters,Counters,Counters) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printAllTaskAttempts(TaskType) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printTaskSummary() org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printJobAnalysis() org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printAnalysis(JobHistoryParser$TaskAttemptInfo[],Comparator,String,long,int) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printLast(JobHistoryParser$TaskAttemptInfo[],String,Comparator) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printTasks(TaskType,String) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printFailedAttempts(HistoryViewer$FilteredJob) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Update org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.getTaskLogsUrl(String,JobHistoryParser$TaskAttemptInfo) org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.getTaskLogsUrl(String,JobHistoryParser$TaskAttemptInfo)
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.<clinit>() org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.dateFormat : SimpleDateFormat org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.jobId : String org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printAll : boolean org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.cMap : Comparator org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.cShuffle : Comparator org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.cFinishShuffle : Comparator org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.cFinishMapRed : Comparator org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Delete org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.cReduce : Comparator org.apache.hadoop.mapreduce.jobhistory.HistoryViewer
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.1 org.apache.hadoop.mapreduce.jobhistory.JhCounter.1
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.<init>(JhCounter$Builder) org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.<init>(JhCounter$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.<init>(JhCounter) org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.<init>(JhCounter)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setDisplayName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setDisplayName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getValue() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.getValue()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setValue(long) org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.setValue(long)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasValue() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.hasValue()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearValue() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.clearValue()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JhCounter.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounter org.apache.hadoop.mapreduce.jobhistory.JhCounter
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.1 org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.1
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.<init>(JhCounterGroup$Builder) org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.<init>(JhCounterGroup$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.<init>(JhCounterGroup) org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.<init>(JhCounterGroup)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setDisplayName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setDisplayName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearDisplayName() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearDisplayName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getCounts() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.getCounts()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setCounts(List) org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.setCounts(List)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasCounts() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.hasCounts()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearCounts() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.clearCounts()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.1 org.apache.hadoop.mapreduce.jobhistory.JhCounters.1
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.<init>(JhCounters$Builder) org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.<init>(JhCounters$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.<init>(JhCounters) org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.<init>(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.getName() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.getName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.setName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.setName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.hasName() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.hasName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.clearName() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.clearName()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.getGroups() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.getGroups()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.setGroups(List) org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.setGroups(List)
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.hasGroups() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.hasGroups()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.clearGroups() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.clearGroups()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JhCounters.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JhCounters org.apache.hadoop.mapreduce.jobhistory.JhCounters
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.1 org.apache.hadoop.mapreduce.jobhistory.JobFinished.1
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.<init>(JobFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.<init>(JobFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.<init>(JobFinished) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.<init>(JobFinished)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishedMaps(int) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishedMaps(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishedReduces(int) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFinishedReduces(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFailedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFailedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFailedMaps(int) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFailedMaps(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFailedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFailedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFailedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFailedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFailedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getFailedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFailedReduces(int) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setFailedReduces(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFailedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasFailedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFailedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearFailedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getTotalCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getTotalCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setTotalCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setTotalCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasTotalCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasTotalCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearTotalCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearTotalCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getMapCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getMapCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setMapCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setMapCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasMapCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasMapCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearMapCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearMapCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getReduceCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.getReduceCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setReduceCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.setReduceCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasReduceCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.hasReduceCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearReduceCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.clearReduceCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished org.apache.hadoop.mapreduce.jobhistory.JobFinished
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinished.<init>(CharSequence,Long,Integer,Integer,Integer,Integer,JhCounters,JhCounters,JhCounters) org.apache.hadoop.mapreduce.jobhistory.JobFinished
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.get(int) org.apache.hadoop.mapreduce.jobhistory.JobFinished.get(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.put(int,Object) org.apache.hadoop.mapreduce.jobhistory.JobFinished.put(int,Object)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFailedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFailedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFailedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinished.getFailedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder() org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder(JobFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder(JobFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder(JobFinished) org.apache.hadoop.mapreduce.jobhistory.JobFinished.newBuilder(JobFinished)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinished.<clinit>() org.apache.hadoop.mapreduce.jobhistory.JobFinished.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.<init>(JobID,long,int,int,int,int,Counters,Counters,Counters) org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getEventType()
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getTotalCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getTotalCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getMapCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getMapCounters()
Update org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getReduceCounters() org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getReduceCounters()
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.finishedMaps : int org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.finishedReduces : int org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.1 org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.1
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.AMInfo org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.AMInfo
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo
Delete org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo
Delete org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getPriority() org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getPriority()
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getLatestAMInfo() org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.getLatestAMInfo()
Delete org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.finishedMaps : int org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo
Delete org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo.finishedReduces : int org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.TaskAttemptInfo org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.TaskAttemptInfo
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.TaskInfo org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.TaskInfo
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobFailedEvent(JobUnsuccessfulCompletionEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobFailedEvent(JobUnsuccessfulCompletionEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobFinishedEvent(JobFinishedEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobFinishedEvent(JobFinishedEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobPriorityChangeEvent(JobPriorityChangeEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobPriorityChangeEvent(JobPriorityChangeEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobQueueChangeEvent(JobQueueChangeEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobQueueChangeEvent(JobQueueChangeEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobInitedEvent(JobInitedEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobInitedEvent(JobInitedEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleAMStartedEvent(AMStartedEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleAMStartedEvent(AMStartedEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobInfoChangeEvent(JobInfoChangeEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobInfoChangeEvent(JobInfoChangeEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobSubmittedEvent(JobSubmittedEvent) org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleJobSubmittedEvent(JobSubmittedEvent)
Update org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.<clinit>() org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.<clinit>()
Delete org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.LOG : Log org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.1 org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.1
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.<init>(JobInfoChange$Builder) org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.<init>(JobInfoChange$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.<init>(JobInfoChange) org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.<init>(JobInfoChange)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setSubmitTime(long) org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setSubmitTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.getLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setLaunchTime(long) org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.setLaunchTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.hasLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.clearLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobInfoChange.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChange org.apache.hadoop.mapreduce.jobhistory.JobInfoChange
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.<init>(JobID,long,long) org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.<init>(JobID,long,long)
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.1 org.apache.hadoop.mapreduce.jobhistory.JobInited.1
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.<init>(JobInited$Builder) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.<init>(JobInited$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.<init>(JobInited) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.<init>(JobInited)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setLaunchTime(long) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setLaunchTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getTotalMaps() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getTotalMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setTotalMaps(int) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setTotalMaps(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasTotalMaps() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasTotalMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearTotalMaps() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearTotalMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getTotalReduces() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getTotalReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setTotalReduces(int) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setTotalReduces(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasTotalReduces() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasTotalReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearTotalReduces() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearTotalReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setJobStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setJobStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getUberized() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.getUberized()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setUberized(boolean) org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.setUberized(boolean)
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasUberized() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.hasUberized()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearUberized() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.clearUberized()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobInited.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobInited org.apache.hadoop.mapreduce.jobhistory.JobInited
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.<init>(JobID,long,int,int,String,boolean) org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.<init>(JobID,long,int,int,String,boolean)
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getLaunchTime() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getLaunchTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getTotalMaps() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getTotalMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getTotalReduces() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getTotalReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getStatus() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getUberized() org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent.getUberized()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.1 org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.1
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.<init>(JobPriorityChange$Builder) org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.<init>(JobPriorityChange$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.<init>(JobPriorityChange) org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.<init>(JobPriorityChange)
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.getPriority() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.getPriority()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.setPriority(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.setPriority(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.hasPriority() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.hasPriority()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.clearPriority() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.clearPriority()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.<init>(JobID,JobPriority) org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.<init>(JobID,JobPriority)
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getPriority() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getPriority()
Update org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.1 org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.1
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.<init>(JobQueueChange$Builder) org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.<init>(JobQueueChange$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.<init>(JobQueueChange) org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.<init>(JobQueueChange)
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.getJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.getJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.setJobQueueName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.setJobQueueName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.hasJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.hasJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.clearJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.clearJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobQueueChange.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChange org.apache.hadoop.mapreduce.jobhistory.JobQueueChange
Update org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.1 org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.1
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.<init>(JobStatusChanged$Builder) org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.<init>(JobStatusChanged$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.<init>(JobStatusChanged) org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.<init>(JobStatusChanged)
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.getJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.getJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.setJobStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.setJobStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.hasJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.hasJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.clearJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.clearJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.<init>(JobID,String) org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.<init>(JobID,String)
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getStatus() org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.1 org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.1
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.<init>(JobSubmitted$Builder) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.<init>(JobSubmitted$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.<init>(JobSubmitted) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.<init>(JobSubmitted)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getUserName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getUserName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setUserName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setUserName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasUserName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasUserName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearUserName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearUserName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setSubmitTime(long) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setSubmitTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobConfPath() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobConfPath()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobConfPath(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobConfPath(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobConfPath() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobConfPath()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobConfPath() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobConfPath()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getAcls() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getAcls()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setAcls(Map) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setAcls(Map)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasAcls() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasAcls()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearAcls() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearAcls()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobQueueName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setJobQueueName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowId() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowId()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowId() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowId()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowId() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowId()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowNodeName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowNodeName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowNodeName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowNodeName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowNodeName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowNodeName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowNodeName() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowNodeName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowAdjacencies() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowAdjacencies()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowAdjacencies(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowAdjacencies(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowAdjacencies() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowAdjacencies()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowAdjacencies() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowAdjacencies()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowTags() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.getWorkflowTags()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowTags(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.setWorkflowTags(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowTags() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.hasWorkflowTags()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowTags() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.clearWorkflowTags()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobSubmitted.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmitted org.apache.hadoop.mapreduce.jobhistory.JobSubmitted
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.<init>(JobID,String,String,long,String,Map,String,String,String,String,String,String) org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.<init>(JobID,String,String,long,String,Map,String,String,String,String,String,String)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.<init>() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.<init>()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobName() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobQueueName() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobQueueName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getUserName() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getUserName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getSubmitTime() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getSubmitTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobConfPath() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobConfPath()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobAcls() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobAcls()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowId() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowId()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowName() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowNodeName() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowNodeName()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowAdjacencies() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowAdjacencies()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowTags() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getWorkflowTags()
Update org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.1 org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.1
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.<init>(JobUnsuccessfulCompletion$Builder) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.<init>(JobUnsuccessfulCompletion$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.<init>(JobUnsuccessfulCompletion) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.<init>(JobUnsuccessfulCompletion)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getJobid() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setJobid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setJobid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasJobid() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearJobid() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearJobid()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishedMaps(int) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishedMaps(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishedReduces(int) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setFinishedReduces(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setJobStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setJobStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearJobStatus() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearJobStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getDiagnostics() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.getDiagnostics()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setDiagnostics(CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.setDiagnostics(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasDiagnostics() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.hasDiagnostics()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearDiagnostics() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.clearDiagnostics()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.build() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion
Delete org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.<init>(CharSequence,Long,Integer,Integer,CharSequence,CharSequence) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.get(int) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.get(int)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.put(int,Object) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.put(int,Object)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishedMaps()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.getFinishedReduces()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder(JobUnsuccessfulCompletion$Builder) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder(JobUnsuccessfulCompletion$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder(JobUnsuccessfulCompletion) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.newBuilder(JobUnsuccessfulCompletion)
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.<clinit>() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.<init>(JobID,long,int,int,String) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.<init>(JobID,long,int,int,String,Iterable) org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getJobId() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getJobId()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getFinishTime()
Delete org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getFinishedMaps() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent
Delete org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getFinishedReduces() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getStatus() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getDiagnostics() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.getDiagnostics()
Update org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.<clinit>() org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.1 org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.1
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.<init>(MapAttemptFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.<init>(MapAttemptFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.<init>(MapAttemptFinished) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.<init>(MapAttemptFinished)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getAttemptId() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasAttemptId() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearAttemptId() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setTaskStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskStatus() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskStatus() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getMapFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getMapFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setMapFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setMapFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasMapFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasMapFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearMapFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearMapFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getHostname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setHostname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setHostname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasHostname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasHostname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearHostname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearHostname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getPort() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getPort()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setPort(int) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasPort() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasPort()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearPort() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearPort()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getRackname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getRackname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setRackname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setRackname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasRackname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasRackname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearRackname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearRackname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getState() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getState()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setState(CharSequence) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setState(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasState() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasState()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearState() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearState()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getClockSplits() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setClockSplits(List) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setClockSplits(List)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasClockSplits() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearClockSplits() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getCpuUsages() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setCpuUsages(List) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setCpuUsages(List)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasCpuUsages() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearCpuUsages() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setVMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setVMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.getPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setPhysMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.setPhysMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.hasPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.clearPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,String,int,String,String,Counters,int[][]) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,String,int,String,String,Counters,int[][])
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,String,String,Counters) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,String,String,Counters)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getHostname() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getState() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getState()
Update org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent
Delete org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent.<init>(TaskType,int) org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent
Delete org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent.getMemory() org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent
Delete org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent.memory : int org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent
Update org.apache.hadoop.mapreduce.jobhistory.package-info org.apache.hadoop.mapreduce.jobhistory.package-info
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.1 org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.1
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.<init>(ReduceAttemptFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.<init>(ReduceAttemptFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.<init>(ReduceAttemptFinished) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.<init>(ReduceAttemptFinished)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getAttemptId() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasAttemptId() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearAttemptId() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setTaskStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskStatus() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskStatus() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getShuffleFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getShuffleFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setShuffleFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setShuffleFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasShuffleFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasShuffleFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearShuffleFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearShuffleFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getSortFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getSortFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setSortFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setSortFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasSortFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasSortFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearSortFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearSortFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getHostname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setHostname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setHostname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasHostname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasHostname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearHostname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearHostname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getPort() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getPort()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setPort(int) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasPort() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasPort()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearPort() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearPort()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getRackname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getRackname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setRackname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setRackname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasRackname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasRackname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearRackname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearRackname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getState() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getState()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setState(CharSequence) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setState(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasState() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasState()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearState() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearState()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getClockSplits() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setClockSplits(List) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setClockSplits(List)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasClockSplits() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearClockSplits() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getCpuUsages() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setCpuUsages(List) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setCpuUsages(List)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasCpuUsages() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearCpuUsages() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setVMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setVMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.getPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setPhysMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.setPhysMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.hasPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.clearPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,long,String,int,String,String,Counters,int[][]) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,long,String,int,String,String,Counters,int[][])
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,long,String,String,Counters) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,long,long,String,String,Counters)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getHostname() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getRackName() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getRackName()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getState() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getState()
Update org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.1 org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.<init>(TaskAttemptFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.<init>(TaskAttemptFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.<init>(TaskAttemptFinished) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.<init>(TaskAttemptFinished)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setTaskStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setRackname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setRackname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setHostname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setHostname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getState() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getState()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setState(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setState(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasState() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasState()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearState() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearState()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,String,String,String,Counters) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.<init>(TaskAttemptID,TaskType,String,long,String,String,String,Counters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getRackName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getRackName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getState() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getState()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.1 org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.<init>(TaskAttemptStarted$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.<init>(TaskAttemptStarted$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.<init>(TaskAttemptStarted) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.<init>(TaskAttemptStarted)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setStartTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setStartTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTrackerName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getTrackerName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTrackerName(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setTrackerName(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTrackerName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasTrackerName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTrackerName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearTrackerName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getHttpPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setHttpPort(int) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setHttpPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasHttpPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearHttpPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getShufflePort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getShufflePort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setShufflePort(int) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setShufflePort(int)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasShufflePort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasShufflePort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearShufflePort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearShufflePort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getContainerId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setContainerId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setContainerId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasContainerId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearContainerId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getLocality() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getLocality()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setLocality(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setLocality(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasLocality() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasLocality()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearLocality() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearLocality()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getAvataar() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.getAvataar()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setAvataar(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.setAvataar(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasAvataar() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.hasAvataar()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearAvataar() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.clearAvataar()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.<init>(TaskAttemptID,TaskType,long,String,int,int,ContainerId,String,String) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.<init>(TaskAttemptID,TaskType,long,String,int,int,ContainerId,String,String)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.<init>(TaskAttemptID,TaskType,long,String,int,int,String,String) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.<init>(TaskAttemptID,TaskType,long,String,int,int,String,String)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTrackerName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTrackerName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getHttpPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getHttpPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getShufflePort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getShufflePort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getTaskAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getContainerId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getContainerId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getLocality() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getLocality()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getAvataar() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent.getAvataar()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.1 org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.<init>(TaskAttemptUnsuccessfulCompletion$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.<init>(TaskAttemptUnsuccessfulCompletion$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.<init>(TaskAttemptUnsuccessfulCompletion) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.<init>(TaskAttemptUnsuccessfulCompletion)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setHostname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setHostname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearHostname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearHostname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setPort(int) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setPort(int)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearPort() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearPort()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setRackname(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setRackname(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearRackname() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearRackname()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getError() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setError(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setError(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasError() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearError() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getClockSplits() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setClockSplits(List) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setClockSplits(List)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasClockSplits() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearClockSplits() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearClockSplits()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getCpuUsages() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setCpuUsages(List) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setCpuUsages(List)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasCpuUsages() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearCpuUsages() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearCpuUsages()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setVMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setVMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearVMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearVMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.getPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setPhysMemKbytes(List) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.setPhysMemKbytes(List)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.hasPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearPhysMemKbytes() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.clearPhysMemKbytes()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,int,String,String,Counters,int[][]) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,int,String,String,Counters,int[][])
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,String) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,String)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,int,String,String,int[][]) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<init>(TaskAttemptID,TaskType,String,long,String,int,String,String,int[][])
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getRackName() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getRackName()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getError() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<clinit>() org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.1 org.apache.hadoop.mapreduce.jobhistory.TaskFailed.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.<init>(TaskFailed$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.<init>(TaskFailed$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.<init>(TaskFailed) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.<init>(TaskFailed)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getError() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setError(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setError(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasError() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearError() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearError()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getFailedDueToAttempt() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getFailedDueToAttempt()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setFailedDueToAttempt(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setFailedDueToAttempt(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasFailedDueToAttempt() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasFailedDueToAttempt()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearFailedDueToAttempt() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearFailedDueToAttempt()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskFailed.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailed org.apache.hadoop.mapreduce.jobhistory.TaskFailed
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<init>(TaskID,long,TaskType,String,String,TaskAttemptID,Counters) org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<init>(TaskID,long,TaskType,String,String,TaskAttemptID,Counters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<init>(TaskID,long,TaskType,String,String,TaskAttemptID) org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<init>(TaskID,long,TaskType,String,String,TaskAttemptID)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<clinit>() org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent.<clinit>()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.1 org.apache.hadoop.mapreduce.jobhistory.TaskFinished.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.<init>(TaskFinished$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.<init>(TaskFinished$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.<init>(TaskFinished) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.<init>(TaskFinished)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setStatus(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setStatus(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setCounters(JhCounters) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setCounters(JhCounters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearCounters() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearCounters()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getSuccessfulAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.getSuccessfulAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setSuccessfulAttemptId(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.setSuccessfulAttemptId(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasSuccessfulAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.hasSuccessfulAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearSuccessfulAttemptId() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.clearSuccessfulAttemptId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskFinished.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinished org.apache.hadoop.mapreduce.jobhistory.TaskFinished
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.<init>(TaskID,TaskAttemptID,long,TaskType,String,Counters) org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.<init>(TaskID,TaskAttemptID,long,TaskType,String,Counters)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getDatum() org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getDatum()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.setDatum(Object) org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.setDatum(Object)
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getTaskStatus() org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getTaskStatus()
Update org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.1 org.apache.hadoop.mapreduce.jobhistory.TaskStarted.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.<init>(TaskStarted$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.<init>(TaskStarted$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.<init>(TaskStarted) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.<init>(TaskStarted)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setTaskType(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setTaskType(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setStartTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setStartTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getSplitLocations() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.getSplitLocations()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setSplitLocations(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.setSplitLocations(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasSplitLocations() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.hasSplitLocations()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearSplitLocations() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.clearSplitLocations()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskStarted.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStarted org.apache.hadoop.mapreduce.jobhistory.TaskStarted
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.<init>(TaskID,long,TaskType,String) org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.<init>(TaskID,long,TaskType,String)
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getSplitLocations() org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getSplitLocations()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getStartTime() org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getStartTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getTaskType() org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getTaskType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent.getEventType()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.1 org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.1
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.<init>(TaskUpdated$Builder) org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.<init>(TaskUpdated$Builder)
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.<init>(TaskUpdated) org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.<init>(TaskUpdated)
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.getTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.getTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.setTaskid(CharSequence) org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.setTaskid(CharSequence)
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.hasTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.hasTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.clearTaskid() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.clearTaskid()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.setFinishTime(long) org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.setFinishTime(long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.hasFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.hasFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.clearFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.clearFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.build() org.apache.hadoop.mapreduce.jobhistory.TaskUpdated.Builder.build()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdated org.apache.hadoop.mapreduce.jobhistory.TaskUpdated
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.<init>(TaskID,long) org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.<init>(TaskID,long)
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getTaskId() org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getTaskId()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getFinishTime() org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getFinishTime()
Update org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getEventType() org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent.getEventType()
Update org.apache.hadoop.mapreduce.JobID org.apache.hadoop.mapreduce.JobID
Update org.apache.hadoop.mapreduce.JobID.<init>(String,int) org.apache.hadoop.mapreduce.JobID.<init>(String,int)
Update org.apache.hadoop.mapreduce.JobID.<init>() org.apache.hadoop.mapreduce.JobID.<init>()
Update org.apache.hadoop.mapreduce.JobID.getJtIdentifier() org.apache.hadoop.mapreduce.JobID.getJtIdentifier()
Update org.apache.hadoop.mapreduce.JobID.equals(Object) org.apache.hadoop.mapreduce.JobID.equals(Object)
Update org.apache.hadoop.mapreduce.JobID.compareTo(ID) org.apache.hadoop.mapreduce.JobID.compareTo(ID)
Update org.apache.hadoop.mapreduce.JobID.appendTo(StringBuilder) org.apache.hadoop.mapreduce.JobID.appendTo(StringBuilder)
Update org.apache.hadoop.mapreduce.JobID.hashCode() org.apache.hadoop.mapreduce.JobID.hashCode()
Update org.apache.hadoop.mapreduce.JobID.readFields(DataInput) org.apache.hadoop.mapreduce.JobID.readFields(DataInput)
Update org.apache.hadoop.mapreduce.JobID.write(DataOutput) org.apache.hadoop.mapreduce.JobID.write(DataOutput)
Update org.apache.hadoop.mapreduce.JobID.compareTo(Object) org.apache.hadoop.mapreduce.JobID.compareTo(Object)
Update org.apache.hadoop.mapreduce.JobPriority org.apache.hadoop.mapreduce.JobPriority
Update org.apache.hadoop.mapreduce.JobPriority.<clinit>() org.apache.hadoop.mapreduce.JobPriority.<clinit>()
Update org.apache.hadoop.mapreduce.JobResourceUploader org.apache.hadoop.mapreduce.JobResourceUploader
Delete org.apache.hadoop.mapreduce.JobResourceUploader.<init>(FileSystem) org.apache.hadoop.mapreduce.JobResourceUploader
Delete org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(Job,Path) org.apache.hadoop.mapreduce.JobResourceUploader
Update org.apache.hadoop.mapreduce.JobResourceUploader.copyRemoteFiles(Path,Path,Configuration,short) org.apache.hadoop.mapreduce.JobResourceUploader.copyRemoteFiles(Path,Path,Configuration,short)
Delete org.apache.hadoop.mapreduce.JobResourceUploader.compareFs(FileSystem,FileSystem) org.apache.hadoop.mapreduce.JobResourceUploader
Update org.apache.hadoop.mapreduce.JobResourceUploader.copyJar(Path,Path,short) org.apache.hadoop.mapreduce.JobResourceUploader.copyJar(Path,Path,short)
Update org.apache.hadoop.mapreduce.JobResourceUploader.addLog4jToDistributedCache(Job,Path) org.apache.hadoop.mapreduce.JobResourceUploader.addLog4jToDistributedCache(Job,Path)
Update org.apache.hadoop.mapreduce.JobResourceUploader.getPathURI(Path,String) org.apache.hadoop.mapreduce.JobResourceUploader.getPathURI(Path,String)
Update org.apache.hadoop.mapreduce.JobResourceUploader.copyLog4jPropertyFile(Job,Path,short) org.apache.hadoop.mapreduce.JobResourceUploader.copyLog4jPropertyFile(Job,Path,short)
Update org.apache.hadoop.mapreduce.JobResourceUploader.validateFilePath(String,Configuration) org.apache.hadoop.mapreduce.JobResourceUploader.validateFilePath(String,Configuration)
Update org.apache.hadoop.mapreduce.JobResourceUploader.<clinit>() org.apache.hadoop.mapreduce.JobResourceUploader.<clinit>()
Delete org.apache.hadoop.mapreduce.JobResourceUploader.LOG : Log org.apache.hadoop.mapreduce.JobResourceUploader
Update org.apache.hadoop.mapreduce.JobStatus.1 org.apache.hadoop.mapreduce.JobStatus.1
Update org.apache.hadoop.mapreduce.JobStatus.State org.apache.hadoop.mapreduce.JobStatus.State
Update org.apache.hadoop.mapreduce.JobStatus org.apache.hadoop.mapreduce.JobStatus
Update org.apache.hadoop.mapreduce.JobStatus.<init>(JobID,float,float,float,float,JobStatus$State,JobPriority,String,String,String,String,String,boolean) org.apache.hadoop.mapreduce.JobStatus.<init>(JobID,float,float,float,float,JobStatus$State,JobPriority,String,String,String,String,String,boolean)
Update org.apache.hadoop.mapreduce.JobStatus.setMapProgress(float) org.apache.hadoop.mapreduce.JobStatus.setMapProgress(float)
Update org.apache.hadoop.mapreduce.JobStatus.setCleanupProgress(float) org.apache.hadoop.mapreduce.JobStatus.setCleanupProgress(float)
Update org.apache.hadoop.mapreduce.JobStatus.setSetupProgress(float) org.apache.hadoop.mapreduce.JobStatus.setSetupProgress(float)
Update org.apache.hadoop.mapreduce.JobStatus.setReduceProgress(float) org.apache.hadoop.mapreduce.JobStatus.setReduceProgress(float)
Update org.apache.hadoop.mapreduce.JobStatus.setPriority(JobPriority) org.apache.hadoop.mapreduce.JobStatus.setPriority(JobPriority)
Update org.apache.hadoop.mapreduce.JobStatus.setFinishTime(long) org.apache.hadoop.mapreduce.JobStatus.setFinishTime(long)
Update org.apache.hadoop.mapreduce.JobStatus.setRetired() org.apache.hadoop.mapreduce.JobStatus.setRetired()
Update org.apache.hadoop.mapreduce.JobStatus.setState(JobStatus$State) org.apache.hadoop.mapreduce.JobStatus.setState(JobStatus$State)
Update org.apache.hadoop.mapreduce.JobStatus.setStartTime(long) org.apache.hadoop.mapreduce.JobStatus.setStartTime(long)
Update org.apache.hadoop.mapreduce.JobStatus.setUsername(String) org.apache.hadoop.mapreduce.JobStatus.setUsername(String)
Update org.apache.hadoop.mapreduce.JobStatus.setQueue(String) org.apache.hadoop.mapreduce.JobStatus.setQueue(String)
Update org.apache.hadoop.mapreduce.JobStatus.getQueue() org.apache.hadoop.mapreduce.JobStatus.getQueue()
Update org.apache.hadoop.mapreduce.JobStatus.getMapProgress() org.apache.hadoop.mapreduce.JobStatus.getMapProgress()
Update org.apache.hadoop.mapreduce.JobStatus.getCleanupProgress() org.apache.hadoop.mapreduce.JobStatus.getCleanupProgress()
Update org.apache.hadoop.mapreduce.JobStatus.getSetupProgress() org.apache.hadoop.mapreduce.JobStatus.getSetupProgress()
Update org.apache.hadoop.mapreduce.JobStatus.getReduceProgress() org.apache.hadoop.mapreduce.JobStatus.getReduceProgress()
Update org.apache.hadoop.mapreduce.JobStatus.getState() org.apache.hadoop.mapreduce.JobStatus.getState()
Update org.apache.hadoop.mapreduce.JobStatus.getStartTime() org.apache.hadoop.mapreduce.JobStatus.getStartTime()
Update org.apache.hadoop.mapreduce.JobStatus.clone() org.apache.hadoop.mapreduce.JobStatus.clone()
Update org.apache.hadoop.mapreduce.JobStatus.getJobID() org.apache.hadoop.mapreduce.JobStatus.getJobID()
Update org.apache.hadoop.mapreduce.JobStatus.getUsername() org.apache.hadoop.mapreduce.JobStatus.getUsername()
Update org.apache.hadoop.mapreduce.JobStatus.getPriority() org.apache.hadoop.mapreduce.JobStatus.getPriority()
Update org.apache.hadoop.mapreduce.JobStatus.isJobComplete() org.apache.hadoop.mapreduce.JobStatus.isJobComplete()
Update org.apache.hadoop.mapreduce.JobStatus.write(DataOutput) org.apache.hadoop.mapreduce.JobStatus.write(DataOutput)
Update org.apache.hadoop.mapreduce.JobStatus.readFields(DataInput) org.apache.hadoop.mapreduce.JobStatus.readFields(DataInput)
Update org.apache.hadoop.mapreduce.JobStatus.getJobName() org.apache.hadoop.mapreduce.JobStatus.getJobName()
Update org.apache.hadoop.mapreduce.JobStatus.getJobFile() org.apache.hadoop.mapreduce.JobStatus.getJobFile()
Update org.apache.hadoop.mapreduce.JobStatus.getFinishTime() org.apache.hadoop.mapreduce.JobStatus.getFinishTime()
Update org.apache.hadoop.mapreduce.JobStatus.isRetired() org.apache.hadoop.mapreduce.JobStatus.isRetired()
Update org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots() org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots()
Update org.apache.hadoop.mapreduce.JobStatus.setNumUsedSlots(int) org.apache.hadoop.mapreduce.JobStatus.setNumUsedSlots(int)
Update org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots() org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots()
Update org.apache.hadoop.mapreduce.JobStatus.setNumReservedSlots(int) org.apache.hadoop.mapreduce.JobStatus.setNumReservedSlots(int)
Update org.apache.hadoop.mapreduce.JobStatus.getUsedMem() org.apache.hadoop.mapreduce.JobStatus.getUsedMem()
Update org.apache.hadoop.mapreduce.JobStatus.setUsedMem(int) org.apache.hadoop.mapreduce.JobStatus.setUsedMem(int)
Update org.apache.hadoop.mapreduce.JobStatus.getReservedMem() org.apache.hadoop.mapreduce.JobStatus.getReservedMem()
Update org.apache.hadoop.mapreduce.JobStatus.setReservedMem(int) org.apache.hadoop.mapreduce.JobStatus.setReservedMem(int)
Update org.apache.hadoop.mapreduce.JobStatus.getNeededMem() org.apache.hadoop.mapreduce.JobStatus.getNeededMem()
Update org.apache.hadoop.mapreduce.JobStatus.setNeededMem(int) org.apache.hadoop.mapreduce.JobStatus.setNeededMem(int)
Update org.apache.hadoop.mapreduce.JobStatus.isUber() org.apache.hadoop.mapreduce.JobStatus.isUber()
Update org.apache.hadoop.mapreduce.JobStatus.setUber(boolean) org.apache.hadoop.mapreduce.JobStatus.setUber(boolean)
Update org.apache.hadoop.mapreduce.JobStatus.toString() org.apache.hadoop.mapreduce.JobStatus.toString()
Update org.apache.hadoop.mapreduce.JobStatus.<clinit>() org.apache.hadoop.mapreduce.JobStatus.<clinit>()
Update org.apache.hadoop.mapreduce.JobSubmissionFiles org.apache.hadoop.mapreduce.JobSubmissionFiles
Update org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(Cluster,Configuration) org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(Cluster,Configuration)
Update org.apache.hadoop.mapreduce.JobSubmissionFiles.<clinit>() org.apache.hadoop.mapreduce.JobSubmissionFiles.<clinit>()
Delete org.apache.hadoop.mapreduce.JobSubmissionFiles.LOG : Log org.apache.hadoop.mapreduce.JobSubmissionFiles
Update org.apache.hadoop.mapreduce.JobSubmitter.1 org.apache.hadoop.mapreduce.JobSubmitter.1
Update org.apache.hadoop.mapreduce.JobSubmitter.SplitComparator org.apache.hadoop.mapreduce.JobSubmitter.SplitComparator
Update org.apache.hadoop.mapreduce.JobSubmitter org.apache.hadoop.mapreduce.JobSubmitter
Update org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job,Path) org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job,Path)
Update org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Job,Cluster) org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Job,Cluster)
Update org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(Job) org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(Job)
Update org.apache.hadoop.mapreduce.JobSubmitter.writeConf(Configuration,Path) org.apache.hadoop.mapreduce.JobSubmitter.writeConf(Configuration,Path)
Update org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobID,Credentials) org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobID,Credentials)
Update org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobContext,Path) org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobContext,Path)
Update org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobContext,Path) org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobContext,Path)
Update org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobConf,Path) org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobConf,Path)
Update org.apache.hadoop.mapreduce.JobSubmitter.readTokensFromFiles(Configuration,Credentials) org.apache.hadoop.mapreduce.JobSubmitter.readTokensFromFiles(Configuration,Credentials)
Update org.apache.hadoop.mapreduce.JobSubmitter.populateTokenCache(Configuration,Credentials) org.apache.hadoop.mapreduce.JobSubmitter.populateTokenCache(Configuration,Credentials)
Update org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(Configuration) org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(Configuration)
Update org.apache.hadoop.mapreduce.JobSubmitter.<clinit>() org.apache.hadoop.mapreduce.JobSubmitter.<clinit>()
Delete org.apache.hadoop.mapreduce.JobSubmitter.LOG : Log org.apache.hadoop.mapreduce.JobSubmitter
Update org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum
Update org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax
Update org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin
Update org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum
Update org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax
Update org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin
Update org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount
Update org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor.MyEntry org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor.MyEntry
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer
Update org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram
Update org.apache.hadoop.mapreduce.lib.chain.Chain.ChainBlockingQueue org.apache.hadoop.mapreduce.lib.chain.Chain.ChainBlockingQueue
Update org.apache.hadoop.mapreduce.lib.chain.Chain.ChainRecordReader org.apache.hadoop.mapreduce.lib.chain.Chain.ChainRecordReader
Update org.apache.hadoop.mapreduce.lib.chain.Chain.ChainRecordWriter org.apache.hadoop.mapreduce.lib.chain.Chain.ChainRecordWriter
Update org.apache.hadoop.mapreduce.lib.chain.Chain.KeyValuePair org.apache.hadoop.mapreduce.lib.chain.Chain.KeyValuePair
Update org.apache.hadoop.mapreduce.lib.chain.Chain.MapRunner org.apache.hadoop.mapreduce.lib.chain.Chain.MapRunner
Update org.apache.hadoop.mapreduce.lib.chain.Chain.ReduceRunner org.apache.hadoop.mapreduce.lib.chain.Chain.ReduceRunner
Update org.apache.hadoop.mapreduce.lib.chain.Chain org.apache.hadoop.mapreduce.lib.chain.Chain
Update org.apache.hadoop.mapreduce.lib.chain.ChainMapContextImpl org.apache.hadoop.mapreduce.lib.chain.ChainMapContextImpl
Update org.apache.hadoop.mapreduce.lib.chain.ChainMapper org.apache.hadoop.mapreduce.lib.chain.ChainMapper
Update org.apache.hadoop.mapreduce.lib.chain.ChainReduceContextImpl org.apache.hadoop.mapreduce.lib.chain.ChainReduceContextImpl
Update org.apache.hadoop.mapreduce.lib.chain.ChainReducer org.apache.hadoop.mapreduce.lib.chain.ChainReducer
Update org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter
Delete org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter.LOG : Log org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter
Update org.apache.hadoop.mapreduce.lib.db.BooleanSplitter org.apache.hadoop.mapreduce.lib.db.BooleanSplitter
Update org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.DataDrivenDBInputSplit org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.DataDrivenDBInputSplit
Update org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat
Delete org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.LOG : Log org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat
Update org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader
Delete org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader.LOG : Log org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.DateSplitter org.apache.hadoop.mapreduce.lib.db.DateSplitter
Delete org.apache.hadoop.mapreduce.lib.db.DateSplitter.LOG : Log org.apache.hadoop.mapreduce.lib.db.DateSplitter
Update org.apache.hadoop.mapreduce.lib.db.DBConfiguration org.apache.hadoop.mapreduce.lib.db.DBConfiguration
Update org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit
Update org.apache.hadoop.mapreduce.lib.db.DBInputFormat.NullDBWritable org.apache.hadoop.mapreduce.lib.db.DBInputFormat.NullDBWritable
Update org.apache.hadoop.mapreduce.lib.db.DBInputFormat org.apache.hadoop.mapreduce.lib.db.DBInputFormat
Delete org.apache.hadoop.mapreduce.lib.db.DBInputFormat.LOG : Log org.apache.hadoop.mapreduce.lib.db.DBInputFormat
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.DBRecordWriter org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.DBRecordWriter
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat org.apache.hadoop.mapreduce.lib.db.DBOutputFormat
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.<init>() org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.<init>()
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getOutputCommitter(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getOutputCommitter(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.constructQuery(String,String[]) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.constructQuery(String,String[])
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String,String[]) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String,String[])
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String,int) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String,int)
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String) org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.setOutput(Job,String)
Delete org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.access$000() org.apache.hadoop.mapreduce.lib.db.DBOutputFormat
Update org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.<clinit>() org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.LOG : Log org.apache.hadoop.mapreduce.lib.db.DBOutputFormat
Update org.apache.hadoop.mapreduce.lib.db.DBRecordReader org.apache.hadoop.mapreduce.lib.db.DBRecordReader
Delete org.apache.hadoop.mapreduce.lib.db.DBRecordReader.LOG : Log org.apache.hadoop.mapreduce.lib.db.DBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.DBSplitter org.apache.hadoop.mapreduce.lib.db.DBSplitter
Update org.apache.hadoop.mapreduce.lib.db.DBWritable org.apache.hadoop.mapreduce.lib.db.DBWritable
Update org.apache.hadoop.mapreduce.lib.db.FloatSplitter org.apache.hadoop.mapreduce.lib.db.FloatSplitter
Update org.apache.hadoop.mapreduce.lib.db.FloatSplitter.<init>() org.apache.hadoop.mapreduce.lib.db.FloatSplitter.<init>()
Update org.apache.hadoop.mapreduce.lib.db.FloatSplitter.split(Configuration,ResultSet,String) org.apache.hadoop.mapreduce.lib.db.FloatSplitter.split(Configuration,ResultSet,String)
Update org.apache.hadoop.mapreduce.lib.db.FloatSplitter.<clinit>() org.apache.hadoop.mapreduce.lib.db.FloatSplitter.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.db.FloatSplitter.LOG : Log org.apache.hadoop.mapreduce.lib.db.FloatSplitter
Update org.apache.hadoop.mapreduce.lib.db.IntegerSplitter org.apache.hadoop.mapreduce.lib.db.IntegerSplitter
Update org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat
Update org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter
Update org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader
Delete org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.LOG : Log org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader
Update org.apache.hadoop.mapreduce.lib.db.TextSplitter org.apache.hadoop.mapreduce.lib.db.TextSplitter
Delete org.apache.hadoop.mapreduce.lib.db.TextSplitter.LOG : Log org.apache.hadoop.mapreduce.lib.db.TextSplitter
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[],List) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[],List)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[],List,int,String) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[],List,int,String)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.parseOutputKeyValueSpec(String,List,List) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.parseOutputKeyValueSpec(String,List,List)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.specToString(String,String,int,List,List) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.specToString(String,String,int,List,List)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<init>() org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<init>()
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<init>(Text,Text) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<init>(Text,Text)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.getKey() org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.getKey()
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.getValue() org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.getValue()
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractOutputKeyValue(String,String,String,List,List,int,boolean,boolean) org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractOutputKeyValue(String,String,String,List,List,int,boolean,boolean)
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<clinit>() org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.<clinit>()
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper
Delete org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper.LOG : Log org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper
Update org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer
Delete org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer.LOG : Log org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.MultiPathFilter org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.MultiPathFilter
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneBlockInfo org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneBlockInfo
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo.<init>(FileStatus,Configuration,boolean,HashMap,HashMap,HashMap,HashMap,long) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo.<init>(FileStatus,Configuration,boolean,HashMap,HashMap,HashMap,HashMap,long)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo.populateBlockInfo(CombineFileInputFormat$OneBlockInfo[],Map,Map,Map,Map) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.OneFileInfo.populateBlockInfo(CombineFileInputFormat$OneBlockInfo[],Map,Map,Map,Map)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMaxSplitSize(long) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMaxSplitSize(long)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMinSplitSizeNode(long) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMinSplitSizeNode(long)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMinSplitSizeRack(long) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.setMinSplitSizeRack(long)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createPool(List) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createPool(List)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createPool(PathFilter[]) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createPool(PathFilter[])
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.isSplitable(JobContext,Path) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.isSplitable(JobContext,Path)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.<init>() org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.<init>()
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getSplits(JobContext) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getSplits(JobContext)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getMoreSplits(JobContext,List,long,long,long,List) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getMoreSplits(JobContext,List,long,long,long,List)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createSplits(Map,Map,Map,long,long,long,long,List) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.createSplits(Map,Map,Map,long,long,long,long,List)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.addCreatedSplit(List,Collection,ArrayList) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.addCreatedSplit(List,Collection,ArrayList)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getFileBlockLocations(FileSystem,FileStatus) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getFileBlockLocations(FileSystem,FileStatus)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.addHostToRack(Map,String,String) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.addHostToRack(Map,String,String)
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getHosts(Set) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getHosts(Set)
Delete org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.access$000(Map,String,String) org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.<clinit>() org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.LOG : Log org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader
Update org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper
Update org.apache.hadoop.mapreduce.lib.input.CombineFileSplit org.apache.hadoop.mapreduce.lib.input.CombineFileSplit
Update org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat.SequenceFileRecordReaderWrapper org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat.SequenceFileRecordReaderWrapper
Update org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat.TextRecordReaderWrapper org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat.TextRecordReaderWrapper
Update org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat
Update org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader
Update org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat
Update org.apache.hadoop.mapreduce.lib.input.DelegatingMapper org.apache.hadoop.mapreduce.lib.input.DelegatingMapper
Update org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.1 org.apache.hadoop.mapreduce.lib.input.FileInputFormat.1
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.Counter org.apache.hadoop.mapreduce.lib.input.FileInputFormat.Counter
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.MultiPathFilter org.apache.hadoop.mapreduce.lib.input.FileInputFormat.MultiPathFilter
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat org.apache.hadoop.mapreduce.lib.input.FileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(JobContext) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(JobContext)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.computeSplitSize(long,long,long) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.computeSplitSize(long,long,long)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getBlockIndex(BlockLocation[],long) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getBlockIndex(BlockLocation[],long)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(Job,String) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(Job,String)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPaths(Job,String) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPaths(Job,String)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(Job,Path[]) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(Job,Path[])
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(Job,Path) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(Job,Path)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getPathStrings(String) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getPathStrings(String)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getInputPaths(JobContext) org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getInputPaths(JobContext)
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormat.<clinit>() org.apache.hadoop.mapreduce.lib.input.FileInputFormat.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.input.FileInputFormat.LOG : Log org.apache.hadoop.mapreduce.lib.input.FileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
Update org.apache.hadoop.mapreduce.lib.input.FileSplit org.apache.hadoop.mapreduce.lib.input.FileSplit
Update org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat
Update org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader
Delete org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.LOG : Log org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader
Update org.apache.hadoop.mapreduce.lib.input.InvalidInputException org.apache.hadoop.mapreduce.lib.input.InvalidInputException
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.getKeyClass() org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.getKeyClass()
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.<init>(Configuration) org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.<init>(Configuration)
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.initialize(InputSplit,TaskAttemptContext) org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.initialize(InputSplit,TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.nextKeyValue() org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.nextKeyValue()
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.getProgress() org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.getProgress()
Update org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.close() org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.close()
Update org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader org.apache.hadoop.mapreduce.lib.input.LineRecordReader
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(InputSplit,TaskAttemptContext) org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(InputSplit,TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.maxBytesToConsume(long) org.apache.hadoop.mapreduce.lib.input.LineRecordReader.maxBytesToConsume(long)
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getFilePosition() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getFilePosition()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentKey() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentKey()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentValue() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentValue()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getProgress() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getProgress()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentValue() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentValue()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentKey() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.getCurrentKey()
Update org.apache.hadoop.mapreduce.lib.input.LineRecordReader.<clinit>() org.apache.hadoop.mapreduce.lib.input.LineRecordReader.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.input.LineRecordReader.LOG : Log org.apache.hadoop.mapreduce.lib.input.LineRecordReader
Update org.apache.hadoop.mapreduce.lib.input.MultipleInputs org.apache.hadoop.mapreduce.lib.input.MultipleInputs
Update org.apache.hadoop.mapreduce.lib.input.NLineInputFormat org.apache.hadoop.mapreduce.lib.input.NLineInputFormat
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat.SequenceFileAsBinaryRecordReader org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat.SequenceFileAsBinaryRecordReader
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.Filter org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.Filter
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.FilterBase org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.FilterBase
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.FilterRecordReader org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.FilterRecordReader
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.accept(Object) org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.accept(Object)
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(Text) org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(Text)
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(BytesWritable) org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(BytesWritable)
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(byte[],int,int) org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.MD5Hashcode(byte[],int,int)
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.<clinit>() org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.MD5Filter.<clinit>()
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.PercentFilter org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.PercentFilter
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.RegexFilter org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.RegexFilter
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter
Delete org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.LOG : Log org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat
Update org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader
Update org.apache.hadoop.mapreduce.lib.input.SplitLineReader org.apache.hadoop.mapreduce.lib.input.SplitLineReader
Update org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit
Update org.apache.hadoop.mapreduce.lib.input.TextInputFormat org.apache.hadoop.mapreduce.lib.input.TextInputFormat
Update org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State
Update org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob
Delete org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.LOG : Log org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.1 org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.1
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.ThreadState org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.ThreadState
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run() org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run()
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.failAllJobs(Throwable) org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.failAllJobs(Throwable)
Update org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.<clinit>() org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.LOG : Log org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl
Update org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator
Update org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat
Update org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader
Update org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat
Update org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit
Update org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.1 org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.1
Update org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.2 org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.2
Update org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector
Update org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader
Update org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader
Update org.apache.hadoop.mapreduce.lib.join.JoinRecordReader.JoinDelegationIterator org.apache.hadoop.mapreduce.lib.join.JoinRecordReader.JoinDelegationIterator
Update org.apache.hadoop.mapreduce.lib.join.JoinRecordReader org.apache.hadoop.mapreduce.lib.join.JoinRecordReader
Update org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader.MultiFilterDelegationIterator org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader.MultiFilterDelegationIterator
Update org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader
Update org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader
Update org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader
Update org.apache.hadoop.mapreduce.lib.join.Parser.CNode org.apache.hadoop.mapreduce.lib.join.Parser.CNode
Update org.apache.hadoop.mapreduce.lib.join.Parser.Lexer org.apache.hadoop.mapreduce.lib.join.Parser.Lexer
Update org.apache.hadoop.mapreduce.lib.join.Parser.Node org.apache.hadoop.mapreduce.lib.join.Parser.Node
Update org.apache.hadoop.mapreduce.lib.join.Parser.NodeToken org.apache.hadoop.mapreduce.lib.join.Parser.NodeToken
Update org.apache.hadoop.mapreduce.lib.join.Parser.NumToken org.apache.hadoop.mapreduce.lib.join.Parser.NumToken
Update org.apache.hadoop.mapreduce.lib.join.Parser.StrToken org.apache.hadoop.mapreduce.lib.join.Parser.StrToken
Update org.apache.hadoop.mapreduce.lib.join.Parser.Token org.apache.hadoop.mapreduce.lib.join.Parser.Token
Update org.apache.hadoop.mapreduce.lib.join.Parser.TType org.apache.hadoop.mapreduce.lib.join.Parser.TType
Update org.apache.hadoop.mapreduce.lib.join.Parser.WNode org.apache.hadoop.mapreduce.lib.join.Parser.WNode
Update org.apache.hadoop.mapreduce.lib.join.Parser.WrappedStatusReporter org.apache.hadoop.mapreduce.lib.join.Parser.WrappedStatusReporter
Update org.apache.hadoop.mapreduce.lib.join.Parser org.apache.hadoop.mapreduce.lib.join.Parser
Update org.apache.hadoop.mapreduce.lib.join.ResetableIterator.EMPTY org.apache.hadoop.mapreduce.lib.join.ResetableIterator.EMPTY
Update org.apache.hadoop.mapreduce.lib.join.ResetableIterator org.apache.hadoop.mapreduce.lib.join.ResetableIterator
Update org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.ReplayableByteInputStream org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.ReplayableByteInputStream
Update org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator
Update org.apache.hadoop.mapreduce.lib.join.TupleWritable.1 org.apache.hadoop.mapreduce.lib.join.TupleWritable.1
Update org.apache.hadoop.mapreduce.lib.join.TupleWritable org.apache.hadoop.mapreduce.lib.join.TupleWritable
Update org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader
Update org.apache.hadoop.mapreduce.lib.map.InverseMapper org.apache.hadoop.mapreduce.lib.map.InverseMapper
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.1 org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.1
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MapRunner org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MapRunner
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapRecordReader org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapRecordReader
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapRecordWriter org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapRecordWriter
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapStatusReporter org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.SubMapStatusReporter
Update org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper
Delete org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.LOG : Log org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper
Update org.apache.hadoop.mapreduce.lib.map.RegexMapper org.apache.hadoop.mapreduce.lib.map.RegexMapper
Update org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper
Update org.apache.hadoop.mapreduce.lib.map.WrappedMapper.Context org.apache.hadoop.mapreduce.lib.map.WrappedMapper.Context
Update org.apache.hadoop.mapreduce.lib.map.WrappedMapper org.apache.hadoop.mapreduce.lib.map.WrappedMapper
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.1
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.CommittedTaskFilter org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.CommittedTaskFilter
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(Path,TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(Path,TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(Path,JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(Path,JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getOutputPath() org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getOutputPath()
Delete org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.hasOutputPath() org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath() org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath()
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath(Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath(Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAppAttemptId(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAppAttemptId(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(JobContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(JobContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(int) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(int)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(int,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(int,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(JobContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(JobContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(int,TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(int,TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(int,TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getCommittedTaskPath(int,TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getWorkPath() org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getWorkPath()
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileSystem,FileStatus,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileSystem,FileStatus,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.renameOrMerge(FileSystem,FileStatus,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.renameOrMerge(FileSystem,FileStatus,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.cleanupJob(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.cleanupJob(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortJob(JobContext,JobStatus$State) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortJob(JobContext,JobStatus$State)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortTask(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortTask(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortTask(TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.abortTask(TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.needsTaskCommit(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.needsTaskCommit(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.needsTaskCommit(TaskAttemptContext,Path) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.needsTaskCommit(TaskAttemptContext,Path)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.recoverTask(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.recoverTask(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<clinit>() org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.LOG : Log org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.Counter org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.Counter
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getWorkOutputPath(TaskInputOutputContext) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getWorkOutputPath(TaskInputOutputContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getPathForWorkFile(TaskInputOutputContext,String,String) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getPathForWorkFile(TaskInputOutputContext,String,String)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getUniqueFile(TaskAttemptContext,String,String) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getUniqueFile(TaskAttemptContext,String,String)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getDefaultWorkFile(TaskAttemptContext,String) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getDefaultWorkFile(TaskAttemptContext,String)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getOutputName(JobContext) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getOutputName(JobContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputName(JobContext,String) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputName(JobContext,String)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getOutputCommitter(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.getOutputCommitter(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.<clinit>() org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.committer : FileOutputCommitter org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
Update org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat.FilterRecordWriter org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat.FilterRecordWriter
Update org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.LazyRecordWriter org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.LazyRecordWriter
Update org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.1 org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.1
Update org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getReaders(Path,Configuration) org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getReaders(Path,Configuration)
Update org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getEntry(MapFile$Reader[],Partitioner,WritableComparable,Writable) org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getEntry(MapFile$Reader[],Partitioner,WritableComparable,Writable)
Update org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.RecordWriterWithCounter org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.RecordWriterWithCounter
Update org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.WrappedStatusReporter org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.WrappedStatusReporter
Update org.apache.hadoop.mapreduce.lib.output.MultipleOutputs org.apache.hadoop.mapreduce.lib.output.MultipleOutputs
Update org.apache.hadoop.mapreduce.lib.output.NullOutputFormat.1 org.apache.hadoop.mapreduce.lib.output.NullOutputFormat.1
Update org.apache.hadoop.mapreduce.lib.output.NullOutputFormat.2 org.apache.hadoop.mapreduce.lib.output.NullOutputFormat.2
Update org.apache.hadoop.mapreduce.lib.output.NullOutputFormat org.apache.hadoop.mapreduce.lib.output.NullOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter.cleanUpPartialOutputForTask(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter.cleanUpPartialOutputForTask(TaskAttemptContext)
Delete org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter.LOG : Log org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter
Update org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.1 org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.1
Update org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.WritableValueBytes org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.WritableValueBytes
Update org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat.1 org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat.1
Update org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream,String) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream,String)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<init>(DataOutputStream)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.writeObject(Object) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.writeObject(Object)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.write(Object,Object) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.write(Object,Object)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.close(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.close(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<clinit>() org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.utf8 : String org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter
Delete org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter.newline : byte[] org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.LineRecordWriter
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TaskAttemptContext) org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TaskAttemptContext)
Update org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.<clinit>() org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.<clinit>()
Update org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner
Update org.apache.hadoop.mapreduce.lib.partition.HashPartitioner org.apache.hadoop.mapreduce.lib.partition.HashPartitioner
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.IntervalSampler org.apache.hadoop.mapreduce.lib.partition.InputSampler.IntervalSampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.RandomSampler org.apache.hadoop.mapreduce.lib.partition.InputSampler.RandomSampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.RandomSampler.getSample(InputFormat,Job) org.apache.hadoop.mapreduce.lib.partition.InputSampler.RandomSampler.getSample(InputFormat,Job)
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.SplitSampler org.apache.hadoop.mapreduce.lib.partition.InputSampler.SplitSampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler org.apache.hadoop.mapreduce.lib.partition.InputSampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.writePartitionFile(Job,InputSampler$Sampler) org.apache.hadoop.mapreduce.lib.partition.InputSampler.writePartitionFile(Job,InputSampler$Sampler)
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.run(String[]) org.apache.hadoop.mapreduce.lib.partition.InputSampler.run(String[])
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.main(String[]) org.apache.hadoop.mapreduce.lib.partition.InputSampler.main(String[])
Delete org.apache.hadoop.mapreduce.lib.partition.InputSampler.access$000() org.apache.hadoop.mapreduce.lib.partition.InputSampler
Update org.apache.hadoop.mapreduce.lib.partition.InputSampler.<clinit>() org.apache.hadoop.mapreduce.lib.partition.InputSampler.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.partition.InputSampler.LOG : Log org.apache.hadoop.mapreduce.lib.partition.InputSampler
Update org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator
Update org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner
Delete org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.LOG : Log org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner
Update org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.KeyDescription org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.KeyDescription
Update org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode.<init>(TotalOrderPartitioner,WritableComparable[],RawComparator) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode.findPartition(WritableComparable) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode.findPartition(Object) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode.findPartition(Object)
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode.splitPoints : WritableComparable[] org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.BinarySearchNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.CarriedTrieNodeRef org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.CarriedTrieNodeRef
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.InnerTrieNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.InnerTrieNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.LeafTrieNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.LeafTrieNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.Node org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.Node
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.SinglySplitTrieNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.SinglySplitTrieNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.TrieNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.TrieNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.UnsplitTrieNode org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.UnsplitTrieNode
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.getPartition(WritableComparable,Object,int) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.readPartitions(FileSystem,Path,Class,Configuration) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.getPartition(Object,Object,int) org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.getPartition(Object,Object,int)
Update org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.<clinit>() org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.<clinit>()
Delete org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.LOG : Log org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner
Update org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer
Update org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer
Update org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer.Context org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer.Context
Update org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer
Update org.apache.hadoop.mapreduce.MapContext org.apache.hadoop.mapreduce.MapContext
Update org.apache.hadoop.mapreduce.Mapper.Context org.apache.hadoop.mapreduce.Mapper.Context
Update org.apache.hadoop.mapreduce.Mapper org.apache.hadoop.mapreduce.Mapper
Update org.apache.hadoop.mapreduce.MarkableIterator org.apache.hadoop.mapreduce.MarkableIterator
Update org.apache.hadoop.mapreduce.MarkableIteratorInterface org.apache.hadoop.mapreduce.MarkableIteratorInterface
Update org.apache.hadoop.mapreduce.MRConfig org.apache.hadoop.mapreduce.MRConfig
Update org.apache.hadoop.mapreduce.MRJobConfig org.apache.hadoop.mapreduce.MRJobConfig
Update org.apache.hadoop.mapreduce.OutputCommitter org.apache.hadoop.mapreduce.OutputCommitter
Update org.apache.hadoop.mapreduce.OutputFormat org.apache.hadoop.mapreduce.OutputFormat
Update org.apache.hadoop.mapreduce.Partitioner org.apache.hadoop.mapreduce.Partitioner
Update org.apache.hadoop.mapreduce.protocol.ClientProtocol org.apache.hadoop.mapreduce.protocol.ClientProtocol
Update org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider
Update org.apache.hadoop.mapreduce.protocol.package-info org.apache.hadoop.mapreduce.protocol.package-info
Update org.apache.hadoop.mapreduce.QueueAclsInfo org.apache.hadoop.mapreduce.QueueAclsInfo
Update org.apache.hadoop.mapreduce.QueueInfo org.apache.hadoop.mapreduce.QueueInfo
Update org.apache.hadoop.mapreduce.QueueState org.apache.hadoop.mapreduce.QueueState
Update org.apache.hadoop.mapreduce.RecordReader org.apache.hadoop.mapreduce.RecordReader
Update org.apache.hadoop.mapreduce.RecordWriter org.apache.hadoop.mapreduce.RecordWriter
Update org.apache.hadoop.mapreduce.ReduceContext.ValueIterator org.apache.hadoop.mapreduce.ReduceContext.ValueIterator
Update org.apache.hadoop.mapreduce.ReduceContext org.apache.hadoop.mapreduce.ReduceContext
Update org.apache.hadoop.mapreduce.Reducer.Context org.apache.hadoop.mapreduce.Reducer.Context
Update org.apache.hadoop.mapreduce.Reducer org.apache.hadoop.mapreduce.Reducer
Update org.apache.hadoop.mapreduce.security.SecureShuffleUtils org.apache.hadoop.mapreduce.security.SecureShuffleUtils
Delete org.apache.hadoop.mapreduce.security.SecureShuffleUtils.LOG : Log org.apache.hadoop.mapreduce.security.SecureShuffleUtils
Update org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier
Update org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSecretManager org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSecretManager
Update org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSelector org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSelector
Update org.apache.hadoop.mapreduce.security.token.delegation.package-info org.apache.hadoop.mapreduce.security.token.delegation.package-info
Update org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier.Renewer org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier.Renewer
Update org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier
Update org.apache.hadoop.mapreduce.security.token.JobTokenSecretManager org.apache.hadoop.mapreduce.security.token.JobTokenSecretManager
Update org.apache.hadoop.mapreduce.security.token.JobTokenSelector org.apache.hadoop.mapreduce.security.token.JobTokenSelector
Update org.apache.hadoop.mapreduce.security.token.package-info org.apache.hadoop.mapreduce.security.token.package-info
Update org.apache.hadoop.mapreduce.security.TokenCache org.apache.hadoop.mapreduce.security.TokenCache
Update org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(Credentials,Path[],Configuration) org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(Credentials,Path[],Configuration)
Delete org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(FileSystem,Credentials,Configuration) org.apache.hadoop.mapreduce.security.TokenCache
Update org.apache.hadoop.mapreduce.security.TokenCache.mergeBinaryTokens(Credentials,Configuration) org.apache.hadoop.mapreduce.security.TokenCache.mergeBinaryTokens(Credentials,Configuration)
Update org.apache.hadoop.mapreduce.security.TokenCache.loadTokens(String,JobConf) org.apache.hadoop.mapreduce.security.TokenCache.loadTokens(String,JobConf)
Update org.apache.hadoop.mapreduce.security.TokenCache.loadTokens(String,Configuration) org.apache.hadoop.mapreduce.security.TokenCache.loadTokens(String,Configuration)
Update org.apache.hadoop.mapreduce.security.TokenCache.setJobToken(Token,Credentials) org.apache.hadoop.mapreduce.security.TokenCache.setJobToken(Token,Credentials)
Update org.apache.hadoop.mapreduce.security.TokenCache.getJobToken(Credentials) org.apache.hadoop.mapreduce.security.TokenCache.getJobToken(Credentials)
Update org.apache.hadoop.mapreduce.security.TokenCache.setShuffleSecretKey(byte[],Credentials) org.apache.hadoop.mapreduce.security.TokenCache.setShuffleSecretKey(byte[],Credentials)
Update org.apache.hadoop.mapreduce.security.TokenCache.getShuffleSecretKey(Credentials) org.apache.hadoop.mapreduce.security.TokenCache.getShuffleSecretKey(Credentials)
Update org.apache.hadoop.mapreduce.security.TokenCache.getDelegationToken(Credentials,String) org.apache.hadoop.mapreduce.security.TokenCache.getDelegationToken(Credentials,String)
Update org.apache.hadoop.mapreduce.security.TokenCache.<clinit>() org.apache.hadoop.mapreduce.security.TokenCache.<clinit>()
Delete org.apache.hadoop.mapreduce.security.TokenCache.LOG : Log org.apache.hadoop.mapreduce.security.TokenCache
Update org.apache.hadoop.mapreduce.server.jobtracker.JTConfig org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HTTP_ADDRESS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_IPC_HANDLER_COUNT : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_RESTART_ENABLED : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_TASK_SCHEDULER : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_INSTRUMENTATION : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_TASKS_PER_JOB : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HEARTBEATS_IN_SECOND : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HEARTBEATS_SCALING_FACTOR : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HEARTBEAT_INTERVAL_MIN : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HEARTBEAT_INTERVAL_MIN_DEFAULT : int org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_PERSIST_JOBSTATUS_HOURS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_PERSIST_JOBSTATUS_DIR : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_SUPERGROUP : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_RETIREJOB_CACHE_SIZE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_TASK_ALLOC_PAD_FRACTION : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBINIT_THREADS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_TRACKER_EXPIRY_INTERVAL : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_RUNNINGTASKS_PER_JOB : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HOSTS_FILENAME : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_HOSTS_EXCLUDE_FILENAME : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_CACHE_SIZE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_BLOCK_SIZE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_COMPLETED_LOCATION : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_LOCATION : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_TASKPROGRESS_NUMBER_SPLITS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_AVG_BLACKLIST_THRESHOLD : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_MAX_TRACKER_BLACKLISTS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_JOBHISTORY_MAXAGE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_MAX_JOB_SPLIT_METAINFO_SIZE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_KEYTAB_FILE : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.PRIVATE_ACTIONS_KEY : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.JT_PLUGINS : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.SHUFFLE_EXCEPTION_STACK_REGEX : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Delete org.apache.hadoop.mapreduce.server.jobtracker.JTConfig.SHUFFLE_EXCEPTION_MSG_REGEX : String org.apache.hadoop.mapreduce.server.jobtracker.JTConfig
Update org.apache.hadoop.mapreduce.server.tasktracker.TTConfig org.apache.hadoop.mapreduce.server.tasktracker.TTConfig
Delete org.apache.hadoop.mapreduce.server.tasktracker.TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL : String org.apache.hadoop.mapreduce.server.tasktracker.TTConfig
Update org.apache.hadoop.mapreduce.split.JobSplit.SplitMetaInfo org.apache.hadoop.mapreduce.split.JobSplit.SplitMetaInfo
Update org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitIndex org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitIndex
Update org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitMetaInfo org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitMetaInfo
Update org.apache.hadoop.mapreduce.split.JobSplit org.apache.hadoop.mapreduce.split.JobSplit
Update org.apache.hadoop.mapreduce.split.JobSplitWriter org.apache.hadoop.mapreduce.split.JobSplitWriter
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.<init>() org.apache.hadoop.mapreduce.split.JobSplitWriter.<init>()
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,List) org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,List)
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,InputSplit[]) org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,InputSplit[])
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,InputSplit[]) org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(Path,Configuration,FileSystem,InputSplit[])
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(FileSystem,Path,Configuration) org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(FileSystem,Path,Configuration)
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.writeSplitHeader(FSDataOutputStream) org.apache.hadoop.mapreduce.split.JobSplitWriter.writeSplitHeader(FSDataOutputStream)
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.writeNewSplits(Configuration,InputSplit[],FSDataOutputStream) org.apache.hadoop.mapreduce.split.JobSplitWriter.writeNewSplits(Configuration,InputSplit[],FSDataOutputStream)
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.writeOldSplits(InputSplit[],FSDataOutputStream,Configuration) org.apache.hadoop.mapreduce.split.JobSplitWriter.writeOldSplits(InputSplit[],FSDataOutputStream,Configuration)
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.writeJobSplitMetaInfo(FileSystem,Path,FsPermission,int,JobSplit$SplitMetaInfo[]) org.apache.hadoop.mapreduce.split.JobSplitWriter.writeJobSplitMetaInfo(FileSystem,Path,FsPermission,int,JobSplit$SplitMetaInfo[])
Update org.apache.hadoop.mapreduce.split.JobSplitWriter.<clinit>() org.apache.hadoop.mapreduce.split.JobSplitWriter.<clinit>()
Delete org.apache.hadoop.mapreduce.split.JobSplitWriter.LOG : Log org.apache.hadoop.mapreduce.split.JobSplitWriter
Update org.apache.hadoop.mapreduce.split.package-info org.apache.hadoop.mapreduce.split.package-info
Update org.apache.hadoop.mapreduce.split.SplitMetaInfoReader org.apache.hadoop.mapreduce.split.SplitMetaInfoReader
Update org.apache.hadoop.mapreduce.StatusReporter org.apache.hadoop.mapreduce.StatusReporter
Update org.apache.hadoop.mapreduce.task.annotation.Checkpointable org.apache.hadoop.mapreduce.task.annotation.Checkpointable
Update org.apache.hadoop.mapreduce.task.JobContextImpl org.apache.hadoop.mapreduce.task.JobContextImpl
Update org.apache.hadoop.mapreduce.task.MapContextImpl org.apache.hadoop.mapreduce.task.MapContextImpl
Update org.apache.hadoop.mapreduce.task.package-info org.apache.hadoop.mapreduce.task.package-info
Update org.apache.hadoop.mapreduce.task.reduce.EventFetcher org.apache.hadoop.mapreduce.task.reduce.EventFetcher
Update org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run() org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run()
Update org.apache.hadoop.mapreduce.task.reduce.EventFetcher.shutDown() org.apache.hadoop.mapreduce.task.reduce.EventFetcher.shutDown()
Update org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents() org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()
Update org.apache.hadoop.mapreduce.task.reduce.EventFetcher.<clinit>() org.apache.hadoop.mapreduce.task.reduce.EventFetcher.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.EventFetcher.LOG : Log org.apache.hadoop.mapreduce.task.reduce.EventFetcher
Update org.apache.hadoop.mapreduce.task.reduce.ExceptionReporter org.apache.hadoop.mapreduce.task.reduce.ExceptionReporter
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.ShuffleErrors org.apache.hadoop.mapreduce.task.reduce.Fetcher.ShuffleErrors
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher org.apache.hadoop.mapreduce.task.reduce.Fetcher
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.openShuffleUrl(MapHost,Set,URL) org.apache.hadoop.mapreduce.task.reduce.Fetcher.openShuffleUrl(MapHost,Set,URL)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(MapHost) org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(MapHost)
Delete org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupConnectionsWithRetry(MapHost,Set,URL) org.apache.hadoop.mapreduce.task.reduce.Fetcher
Delete org.apache.hadoop.mapreduce.task.reduce.Fetcher.openConnectionWithRetry(MapHost,Set,URL) org.apache.hadoop.mapreduce.task.reduce.Fetcher
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifyConnection(URL,String,String) org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifyConnection(URL,String,String)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupShuffleConnection(String) org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupShuffleConnection(String)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(MapHost,DataInputStream,Set,boolean) org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(MapHost,DataInputStream,Set,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.checkTimeoutOrRetry(MapHost,IOException) org.apache.hadoop.mapreduce.task.reduce.Fetcher.checkTimeoutOrRetry(MapHost,IOException)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifySanity(long,long,int,Set,TaskAttemptID) org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifySanity(long,long,int,Set,TaskAttemptID)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.getMapOutputURL(MapHost,Collection) org.apache.hadoop.mapreduce.task.reduce.Fetcher.getMapOutputURL(MapHost,Collection)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.connect(URLConnection,int) org.apache.hadoop.mapreduce.task.reduce.Fetcher.connect(URLConnection,int)
Update org.apache.hadoop.mapreduce.task.reduce.Fetcher.<clinit>() org.apache.hadoop.mapreduce.task.reduce.Fetcher.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.Fetcher.LOG : Log org.apache.hadoop.mapreduce.task.reduce.Fetcher
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.<init>(Configuration,TaskAttemptID,MergeManagerImpl,int,CompressionCodec,boolean) org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.<init>(Configuration,TaskAttemptID,MergeManagerImpl,int,CompressionCodec,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getMemory() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getMemory()
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getArrayStream() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getArrayStream()
Delete org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(MapHost,InputStream,long,long,ShuffleClientMetrics,Reporter) org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.commit() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.commit()
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.abort() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.abort()
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getDescription() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.getDescription()
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.<clinit>() org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.LOG : Log org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput
Delete org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.conf : Configuration org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput
Delete org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.merger : MergeManagerImpl org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryReader org.apache.hadoop.mapreduce.task.reduce.InMemoryReader
Update org.apache.hadoop.mapreduce.task.reduce.InMemoryWriter org.apache.hadoop.mapreduce.task.reduce.InMemoryWriter
Update org.apache.hadoop.mapreduce.task.reduce.LocalFetcher org.apache.hadoop.mapreduce.task.reduce.LocalFetcher
Update org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(TaskAttemptID) org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(TaskAttemptID)
Update org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.<clinit>() org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.LOG : Log org.apache.hadoop.mapreduce.task.reduce.LocalFetcher
Update org.apache.hadoop.mapreduce.task.reduce.MapHost.State org.apache.hadoop.mapreduce.task.reduce.MapHost.State
Update org.apache.hadoop.mapreduce.task.reduce.MapHost org.apache.hadoop.mapreduce.task.reduce.MapHost
Delete org.apache.hadoop.mapreduce.task.reduce.MapHost.markPenalized() org.apache.hadoop.mapreduce.task.reduce.MapHost
Update org.apache.hadoop.mapreduce.task.reduce.MapHost.getNumKnownMapOutputs() org.apache.hadoop.mapreduce.task.reduce.MapHost.getNumKnownMapOutputs()
Update org.apache.hadoop.mapreduce.task.reduce.MapHost.markAvailable() org.apache.hadoop.mapreduce.task.reduce.MapHost.markAvailable()
Update org.apache.hadoop.mapreduce.task.reduce.MapHost.penalize() org.apache.hadoop.mapreduce.task.reduce.MapHost.penalize()
Update org.apache.hadoop.mapreduce.task.reduce.MapOutput.MapOutputComparator org.apache.hadoop.mapreduce.task.reduce.MapOutput.MapOutputComparator
Update org.apache.hadoop.mapreduce.task.reduce.MapOutput org.apache.hadoop.mapreduce.task.reduce.MapOutput
Update org.apache.hadoop.mapreduce.task.reduce.MergeManager org.apache.hadoop.mapreduce.task.reduce.MergeManager
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.1
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.CompressAwarePath org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.CompressAwarePath
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.InMemoryMerger org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.InMemoryMerger
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.InMemoryMerger.merge(List) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.InMemoryMerger.merge(List)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.IntermediateMemoryToMemoryMerger org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.IntermediateMemoryToMemoryMerger
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.OnDiskMerger org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.OnDiskMerger
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.OnDiskMerger.merge(List) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.OnDiskMerger.merge(List)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.RawKVIteratorReader org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.RawKVIteratorReader
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(TaskAttemptID,JobConf,FileSystem,LocalDirAllocator,Reporter,CompressionCodec,Class,Task$CombineOutputCollector,Counters$Counter,Counters$Counter,Counters$Counter,ExceptionReporter,Progress,MapOutputFile) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(TaskAttemptID,JobConf,FileSystem,LocalDirAllocator,Reporter,CompressionCodec,Class,Task$CombineOutputCollector,Counters$Counter,Counters$Counter,Counters$Counter,ExceptionReporter,Progress,MapOutputFile)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.createInMemoryMerger() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.createInMemoryMerger()
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.createOnDiskMerger() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.createOnDiskMerger()
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.waitForResource() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.waitForResource()
Delete org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.canShuffleToMemory(long) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(TaskAttemptID,long,int) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(TaskAttemptID,long,int)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(TaskAttemptID,long,boolean) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(TaskAttemptID,long,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unreserve(long) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unreserve(long)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(InMemoryMapOutput) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(InMemoryMapOutput)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryMergedFile(InMemoryMapOutput) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryMergedFile(InMemoryMapOutput)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeOnDiskFile(MergeManagerImpl$CompressAwarePath) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeOnDiskFile(MergeManagerImpl$CompressAwarePath)
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.close() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.close()
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(JobConf,FileSystem,List,List) org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(JobConf,FileSystem,List,List)
Delete org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.access$300() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl
Update org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<clinit>() org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.LOG : Log org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl
Update org.apache.hadoop.mapreduce.task.reduce.MergeThread org.apache.hadoop.mapreduce.task.reduce.MergeThread
Delete org.apache.hadoop.mapreduce.task.reduce.MergeThread.LOG : Log org.apache.hadoop.mapreduce.task.reduce.MergeThread
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(TaskAttemptID,TaskAttemptID,MergeManagerImpl,long,JobConf,MapOutputFile,int,boolean) org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(TaskAttemptID,TaskAttemptID,MergeManagerImpl,long,JobConf,MapOutputFile,int,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(TaskAttemptID,TaskAttemptID,MergeManagerImpl,long,JobConf,MapOutputFile,int,boolean,FileSystem,Path) org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(TaskAttemptID,TaskAttemptID,MergeManagerImpl,long,JobConf,MapOutputFile,int,boolean,FileSystem,Path)
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.getTempPath(Path,int) org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.getTempPath(Path,int)
Delete org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.shuffle(MapHost,InputStream,long,long,ShuffleClientMetrics,Reporter) org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.commit() org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.commit()
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.abort() org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.abort()
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.getDescription() org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.getDescription()
Update org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<clinit>() org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.LOG : Log org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
Delete org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.merger : MergeManagerImpl org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
Delete org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.conf : Configuration org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput
Update org.apache.hadoop.mapreduce.task.reduce.package-info org.apache.hadoop.mapreduce.task.reduce.package-info
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle.ShuffleError org.apache.hadoop.mapreduce.task.reduce.Shuffle.ShuffleError
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle org.apache.hadoop.mapreduce.task.reduce.Shuffle
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle.init(ShuffleConsumerPlugin$Context) org.apache.hadoop.mapreduce.task.reduce.Shuffle.init(ShuffleConsumerPlugin$Context)
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle.createMergeManager(ShuffleConsumerPlugin$Context) org.apache.hadoop.mapreduce.task.reduce.Shuffle.createMergeManager(ShuffleConsumerPlugin$Context)
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle.run() org.apache.hadoop.mapreduce.task.reduce.Shuffle.run()
Update org.apache.hadoop.mapreduce.task.reduce.Shuffle.reportException(Throwable) org.apache.hadoop.mapreduce.task.reduce.Shuffle.reportException(Throwable)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.<init>(TaskAttemptID,JobConf) org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.inputBytes(long) org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.inputBytes(long)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.failedFetch() org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.failedFetch()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.successFetch() org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.successFetch()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.threadBusy() org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.threadBusy()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.threadFree() org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.threadFree()
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.doUpdates(MetricsContext) org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.shuffleMetrics : MetricsRecord org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.numFailedFetches : int org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.numSuccessFetches : int org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.numBytes : long org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.numThreadsBusy : int org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics.numCopiers : int org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleHeader org.apache.hadoop.mapreduce.task.reduce.ShuffleHeader
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.1
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.2 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.2
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.CopyTimeTracker.Interval org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.CopyTimeTracker.Interval
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.CopyTimeTracker org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.CopyTimeTracker
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.Penalty org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.Penalty
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.Referee org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.Referee
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copySucceeded(TaskAttemptID,MapHost,long,long,long,MapOutput) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copySucceeded(TaskAttemptID,MapHost,long,long,long,MapOutput)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.updateStatus(String) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.updateStatus(String)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.updateStatus() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.updateStatus()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.hostFailed(String) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.hostFailed(String)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(TaskAttemptID,MapHost,boolean,boolean) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(TaskAttemptID,MapHost,boolean,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.reportLocalError(IOException) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.reportLocalError(IOException)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkAndInformMRAppMaster(int,TaskAttemptID,boolean,boolean,boolean) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkAndInformMRAppMaster(int,TaskAttemptID,boolean,boolean,boolean)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkReducerHealth() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkReducerHealth()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.tipFailed(TaskID) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.tipFailed(TaskID)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.addKnownMapOutput(String,String,TaskAttemptID) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.addKnownMapOutput(String,String,TaskAttemptID)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.obsoleteMapOutput(TaskAttemptID) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.obsoleteMapOutput(TaskAttemptID)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.putBackKnownMapOutput(MapHost,TaskAttemptID) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.putBackKnownMapOutput(MapHost,TaskAttemptID)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.getHost() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.getHost()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.getMapsForHost(MapHost) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.getMapsForHost(MapHost)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.freeHost(MapHost) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.freeHost(MapHost)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resetKnownMaps() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resetKnownMaps()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.waitUntilDone(int) org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.waitUntilDone(int)
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.close() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.close()
Update org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.<clinit>() org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.<clinit>()
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.shuffleStart : ThreadLocal org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.LOG : Log org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl
Delete org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.maxDelay : long org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl
Update org.apache.hadoop.mapreduce.task.ReduceContextImpl.ValueIterable org.apache.hadoop.mapreduce.task.ReduceContextImpl.ValueIterable
Update org.apache.hadoop.mapreduce.task.ReduceContextImpl.ValueIterator org.apache.hadoop.mapreduce.task.ReduceContextImpl.ValueIterator
Update org.apache.hadoop.mapreduce.task.ReduceContextImpl org.apache.hadoop.mapreduce.task.ReduceContextImpl
Update org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl.DummyReporter org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl.DummyReporter
Update org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
Update org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl
Update org.apache.hadoop.mapreduce.TaskAttemptContext org.apache.hadoop.mapreduce.TaskAttemptContext
Update org.apache.hadoop.mapreduce.TaskAttemptID org.apache.hadoop.mapreduce.TaskAttemptID
Update org.apache.hadoop.mapreduce.TaskCompletionEvent.Status org.apache.hadoop.mapreduce.TaskCompletionEvent.Status
Update org.apache.hadoop.mapreduce.TaskCompletionEvent org.apache.hadoop.mapreduce.TaskCompletionEvent
Update org.apache.hadoop.mapreduce.TaskCounter org.apache.hadoop.mapreduce.TaskCounter
Update org.apache.hadoop.mapreduce.TaskCounter.<clinit>() org.apache.hadoop.mapreduce.TaskCounter.<clinit>()
Update org.apache.hadoop.mapreduce.TaskID.CharTaskTypeMaps org.apache.hadoop.mapreduce.TaskID.CharTaskTypeMaps
Update org.apache.hadoop.mapreduce.TaskID org.apache.hadoop.mapreduce.TaskID
Update org.apache.hadoop.mapreduce.TaskID.<init>() org.apache.hadoop.mapreduce.TaskID.<init>()
Update org.apache.hadoop.mapreduce.TaskID.equals(Object) org.apache.hadoop.mapreduce.TaskID.equals(Object)
Update org.apache.hadoop.mapreduce.TaskID.compareTo(ID) org.apache.hadoop.mapreduce.TaskID.compareTo(ID)
Update org.apache.hadoop.mapreduce.TaskID.toString() org.apache.hadoop.mapreduce.TaskID.toString()
Update org.apache.hadoop.mapreduce.TaskID.appendTo(StringBuilder) org.apache.hadoop.mapreduce.TaskID.appendTo(StringBuilder)
Update org.apache.hadoop.mapreduce.TaskID.hashCode() org.apache.hadoop.mapreduce.TaskID.hashCode()
Update org.apache.hadoop.mapreduce.TaskID.readFields(DataInput) org.apache.hadoop.mapreduce.TaskID.readFields(DataInput)
Update org.apache.hadoop.mapreduce.TaskID.write(DataOutput) org.apache.hadoop.mapreduce.TaskID.write(DataOutput)
Update org.apache.hadoop.mapreduce.TaskID.forName(String) org.apache.hadoop.mapreduce.TaskID.forName(String)
Update org.apache.hadoop.mapreduce.TaskID.getRepresentingCharacter(TaskType) org.apache.hadoop.mapreduce.TaskID.getRepresentingCharacter(TaskType)
Update org.apache.hadoop.mapreduce.TaskID.getTaskType(char) org.apache.hadoop.mapreduce.TaskID.getTaskType(char)
Update org.apache.hadoop.mapreduce.TaskID.getAllTaskTypes() org.apache.hadoop.mapreduce.TaskID.getAllTaskTypes()
Update org.apache.hadoop.mapreduce.TaskID.compareTo(Object) org.apache.hadoop.mapreduce.TaskID.compareTo(Object)
Update org.apache.hadoop.mapreduce.TaskID.<clinit>() org.apache.hadoop.mapreduce.TaskID.<clinit>()
Update org.apache.hadoop.mapreduce.TaskInputOutputContext org.apache.hadoop.mapreduce.TaskInputOutputContext
Update org.apache.hadoop.mapreduce.TaskReport org.apache.hadoop.mapreduce.TaskReport
Update org.apache.hadoop.mapreduce.TaskTrackerInfo org.apache.hadoop.mapreduce.TaskTrackerInfo
Update org.apache.hadoop.mapreduce.TaskType org.apache.hadoop.mapreduce.TaskType
Update org.apache.hadoop.mapreduce.tools.CLI org.apache.hadoop.mapreduce.tools.CLI
Update org.apache.hadoop.mapreduce.tools.CLI.run(String[]) org.apache.hadoop.mapreduce.tools.CLI.run(String[])
Update org.apache.hadoop.mapreduce.tools.CLI.createCluster() org.apache.hadoop.mapreduce.tools.CLI.createCluster()
Update org.apache.hadoop.mapreduce.tools.CLI.getJobPriorityNames() org.apache.hadoop.mapreduce.tools.CLI.getJobPriorityNames()
Update org.apache.hadoop.mapreduce.tools.CLI.getTaskTypes() org.apache.hadoop.mapreduce.tools.CLI.getTaskTypes()
Update org.apache.hadoop.mapreduce.tools.CLI.displayUsage(String) org.apache.hadoop.mapreduce.tools.CLI.displayUsage(String)
Delete org.apache.hadoop.mapreduce.tools.CLI.viewHistory(String,boolean) org.apache.hadoop.mapreduce.tools.CLI
Update org.apache.hadoop.mapreduce.tools.CLI.getCounter(Counters,String,String) org.apache.hadoop.mapreduce.tools.CLI.getCounter(Counters,String,String)
Update org.apache.hadoop.mapreduce.tools.CLI.listEvents(Job,int,int) org.apache.hadoop.mapreduce.tools.CLI.listEvents(Job,int,int)
Update org.apache.hadoop.mapreduce.tools.CLI.getTaskLogURL(TaskAttemptID,String) org.apache.hadoop.mapreduce.tools.CLI.getTaskLogURL(TaskAttemptID,String)
Update org.apache.hadoop.mapreduce.tools.CLI.listJobs(Cluster) org.apache.hadoop.mapreduce.tools.CLI.listJobs(Cluster)
Update org.apache.hadoop.mapreduce.tools.CLI.listAllJobs(Cluster) org.apache.hadoop.mapreduce.tools.CLI.listAllJobs(Cluster)
Update org.apache.hadoop.mapreduce.tools.CLI.listActiveTrackers(Cluster) org.apache.hadoop.mapreduce.tools.CLI.listActiveTrackers(Cluster)
Update org.apache.hadoop.mapreduce.tools.CLI.listBlacklistedTrackers(Cluster) org.apache.hadoop.mapreduce.tools.CLI.listBlacklistedTrackers(Cluster)
Update org.apache.hadoop.mapreduce.tools.CLI.printTaskAttempts(TaskReport) org.apache.hadoop.mapreduce.tools.CLI.printTaskAttempts(TaskReport)
Update org.apache.hadoop.mapreduce.tools.CLI.displayTasks(Job,String,String) org.apache.hadoop.mapreduce.tools.CLI.displayTasks(Job,String,String)
Update org.apache.hadoop.mapreduce.tools.CLI.displayJobList(JobStatus[]) org.apache.hadoop.mapreduce.tools.CLI.displayJobList(JobStatus[])
Update org.apache.hadoop.mapreduce.tools.CLI.displayJobList(JobStatus[],PrintWriter) org.apache.hadoop.mapreduce.tools.CLI.displayJobList(JobStatus[],PrintWriter)
Update org.apache.hadoop.mapreduce.tools.CLI.main(String[]) org.apache.hadoop.mapreduce.tools.CLI.main(String[])
Update org.apache.hadoop.mapreduce.tools.CLI.<clinit>() org.apache.hadoop.mapreduce.tools.CLI.<clinit>()
Delete org.apache.hadoop.mapreduce.tools.CLI.LOG : Log org.apache.hadoop.mapreduce.tools.CLI
Update org.apache.hadoop.mapreduce.util.ConfigUtil org.apache.hadoop.mapreduce.util.ConfigUtil
Update org.apache.hadoop.mapreduce.util.ConfigUtil.addDeprecatedKeys() org.apache.hadoop.mapreduce.util.ConfigUtil.addDeprecatedKeys()
Update org.apache.hadoop.mapreduce.util.ConfigUtil.main(String[]) org.apache.hadoop.mapreduce.util.ConfigUtil.main(String[])
Update org.apache.hadoop.mapreduce.util.CountersStrings org.apache.hadoop.mapreduce.util.CountersStrings
Update org.apache.hadoop.mapreduce.util.CountersStrings.toEscapedCompactString(AbstractCounters) org.apache.hadoop.mapreduce.util.CountersStrings.toEscapedCompactString(AbstractCounters)
Update org.apache.hadoop.mapreduce.util.CountersStrings.getBlock(String,char,char,IntWritable) org.apache.hadoop.mapreduce.util.CountersStrings.getBlock(String,char,char,IntWritable)
Update org.apache.hadoop.mapreduce.util.CountersStrings.parseEscapedCompactString(String,AbstractCounters) org.apache.hadoop.mapreduce.util.CountersStrings.parseEscapedCompactString(String,AbstractCounters)
Update org.apache.hadoop.mapreduce.util.HostUtil org.apache.hadoop.mapreduce.util.HostUtil
Update org.apache.hadoop.mapreduce.util.package-info org.apache.hadoop.mapreduce.util.package-info
Update org.apache.hadoop.mapreduce.util.ProcessTree.1 org.apache.hadoop.mapreduce.util.ProcessTree.1
Update org.apache.hadoop.mapreduce.util.ProcessTree.SigKillThread org.apache.hadoop.mapreduce.util.ProcessTree.SigKillThread
Update org.apache.hadoop.mapreduce.util.ProcessTree org.apache.hadoop.mapreduce.util.ProcessTree
Delete org.apache.hadoop.mapreduce.util.ProcessTree.LOG : Log org.apache.hadoop.mapreduce.util.ProcessTree
Update org.apache.hadoop.mapreduce.util.ResourceBundles org.apache.hadoop.mapreduce.util.ResourceBundles
Update org.apache.hadoop.mapreduce.v2.LogParams org.apache.hadoop.mapreduce.v2.LogParams
